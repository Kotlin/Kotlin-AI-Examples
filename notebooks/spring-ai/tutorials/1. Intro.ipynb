{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Intro\n",
    "\n",
    "LLMs are becoming increasingly integrated into development workflows,\n",
    "creating demand for frameworks that make AI-based application development accessible.\n",
    "In the JVM and Kotlin ecosystem, Spring is exactly such a framework.\n",
    "Yes, that same Spring that has been around for over 20 years!\n",
    "\n",
    "Spring AI is a new addition that simplifies AI integration into your Kotlin code.\n",
    "Spring AI provides:\n",
    "\n",
    "* A unified API for working with various AI models and LLM providers (OpenAI, Anthropic, Ollama, etc.)\n",
    "* Components for prompt processing and context management\n",
    "* Built-in capabilities for vector stores and RAG applications\n",
    "\n",
    "In this series of posts, we'll explore the core features of Spring AI.\n",
    "Following programming tradition,\n",
    "our first post will be a \"Hello, world!\" of sorts:\n",
    "we'll connect to an LLM provider and ask it to tell us a joke.\n",
    "\n",
    "First, let's add the necessary dependencies.\n",
    "> [!NOTE] We'll be working with Claude models from Anthropic,\n",
    "> but we'll include commented code for OpenAI as well.\n",
    "> This will help you understand the general API approach regardless of which model you choose."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T18:20:23.962206Z",
     "start_time": "2025-05-11T18:20:22.945188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%useLatestDescriptors\n",
    "%use spring-ai-anthropic\n",
    "//%use spring-ai-openai"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "To use the model, we need to provide an API key.\n",
    "\n",
    "You can obtain this API key from\n",
    "[console.anthropic.com](https://console.anthropic.com/settings/keys)\n",
    "for Anthropic models or from\n",
    "[platform.openai.com](https://platform.openai.com/api-keys)\n",
    "for OpenAI models.\n",
    "\n",
    "Then add the generated API key to your environment variables:\n",
    "\n",
    "[MacOS/Linux]\n",
    "```bash\n",
    "export ANTHROPIC_API_KEY=<INSERT KEY HERE> # for Anthropic\n",
    "export OPENAI_API_KEY=<INSERT KEY HERE> # for OpenAI\n",
    "\n",
    "```\n",
    "\n",
    "[Windows]\n",
    "```shell\n",
    "set ANTHROPIC_API_KEY=<INSERT KEY HERE> # for Anthropic\n",
    "set OPENAI_API_KEY=<INSERT KEY HERE> # for OpenAI\n",
    "```\n",
    "\n",
    "Let's retrieve the API key from environment variables:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T18:20:27.159256Z",
     "start_time": "2025-05-11T18:20:27.097816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val apiKey = System.getenv(\"ANTHROPIC_API_KEY\") ?: \"YOUR_ANTHROPIC_API_KEY\"\n",
    "//val apiKey = System.getenv(\"OPENAI_API_KEY\") ?: \"YOUR_OPENAI_API_KEY\""
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "First, let's create a low-level API client for our chosen provider.\n",
    "This only requires the API key:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T18:20:31.997792Z",
     "start_time": "2025-05-11T18:20:31.830652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val anthropicApi = AnthropicApi.builder().apiKey(apiKey).build()\n",
    "//val openAiApi = OpenAiApi.builder().apiKey(apiKey).build()"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now that we have our client, we can make a simple model call:"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T18:20:40.695755Z",
     "start_time": "2025-05-11T18:20:38.591611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val anthropicMessage = AnthropicApi.AnthropicMessage(\n",
    "    listOf(AnthropicApi.ContentBlock(\"Tell me a joke\")), AnthropicApi.Role.USER\n",
    ")\n",
    "//val openAiMessage = OpenAiApi.ChatCompletionMessage(\"Tell me a joke\", OpenAiApi.ChatCompletionMessage.Role.USER)\n",
    "\n",
    "\n",
    "anthropicApi.chatCompletionEntity(\n",
    "    AnthropicApi.ChatCompletionRequest(\n",
    "        AnthropicApi.ChatModel.CLAUDE_3_5_SONNET.value,\n",
    "        listOf(anthropicMessage), null, 100, 0.8, false\n",
    "    )\n",
    ")\n",
    "//openAiApi.chatCompletionEntity(\n",
    "//    OpenAiApi.ChatCompletionRequest(listOf(openAiMessage), OpenAiApi.ChatModel.CHATGPT_4_O_LATEST.value, 0.8, false)\n",
    "//)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<200 OK OK,ChatCompletionResponse[id=msg_01GdysrRajqyi32z5T8T6jvA, type=message, role=ASSISTANT, content=[ContentBlock[type=TEXT, source=null, text=Here's a classic one:\n",
       "\n",
       "Why don't scientists trust atoms?\n",
       "Because they make up everything! ðŸ˜„, index=null, id=null, name=null, input=null, toolUseId=null, content=null, signature=null, thinking=null, data=null]], model=claude-3-5-sonnet-20241022, stopReason=end_turn, stopSequence=null, usage=Usage[inputTokens=11, outputTokens=27]],[:status:\"200\", anthropic-organization-id:\"ea22ac71-22a7-43cc-9c6a-0a6a2c25768f\", anthropic-ratelimit-input-tokens-limit:\"200000\", anthropic-ratelimit-input-tokens-remaining:\"200000\", anthropic-ratelimit-input-tokens-reset:\"2025-05-11T18:20:40Z\", anthropic-ratelimit-output-tokens-limit:\"50000\", anthropic-ratelimit-output-tokens-remaining:\"50000\", anthropic-ratelimit-output-tokens-reset:\"2025-05-11T18:20:40Z\", anthropic-ratelimit-requests-limit:\"500\", anthropic-ratelimit-requests-remaining:\"499\", anthropic-ratelimit-requests-reset:\"2025-05-11T18:20:39Z\", anthropic-ratelimit-tokens-limit:\"250000\", anthropic-ratelimit-tokens-remaining:\"250000\", anthropic-ratelimit-tokens-reset:\"2025-05-11T18:20:40Z\", cf-cache-status:\"DYNAMIC\", cf-ray:\"93e3b1067beee521-TXL\", content-length:\"398\", content-type:\"application/json\", date:\"Sun, 11 May 2025 18:20:40 GMT\", request-id:\"req_011CP2CtyLNnZYZHkPv8YteM\", server:\"cloudflare\", strict-transport-security:\"max-age=31536000; includeSubDomains; preload\", via:\"1.1 google\", x-robots-tag:\"none\"]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Congratulations, that's our first joke!\n",
    "\n",
    "As you've noticed, this API doesn't look very convenient,\n",
    "but that's the nature of low-level APIs.\n",
    "\n",
    "Let's raise the abstraction level.\n",
    "We'll create `*ChatOptions` to help us set and use parameters for our LLM provider requests:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T18:20:45.234463Z",
     "start_time": "2025-05-11T18:20:45.197442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val anthropicOptions = AnthropicChatOptions.builder()\n",
    "    .model(AnthropicApi.ChatModel.CLAUDE_3_5_SONNET)\n",
    "    .temperature(0.7)\n",
    "    .maxTokens(1024)\n",
    "    .build()\n",
    "//val openAiOptions = OpenAiChatOptions.builder()\n",
    "//    .model(OpenAiApi.ChatModel.CHATGPT_4_O_LATEST)\n",
    "//    .temperature(0.7)\n",
    "//    .build()"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now let's create a `*ChatModel`, which will help us get another joke:"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T18:20:49.519186Z",
     "start_time": "2025-05-11T18:20:49.489689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val anthropicChat = AnthropicChatModel.builder()\n",
    "    .anthropicApi(anthropicApi)\n",
    "    .defaultOptions(anthropicOptions)\n",
    "    .build()\n",
    "//val openAiChat = OpenAiChatModel.builder()\n",
    "//    .openAiApi(openAiApi)\n",
    "//    .defaultOptions(openAiOptions)\n",
    "//    .build()"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's ask for a joke about Kotlin:"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T18:20:54.205087Z",
     "start_time": "2025-05-11T18:20:51.059281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "anthropicChat.call(\"Tell me a joke about Kotlin\")\n",
    "//openAiChat.call(\"Tell me a joke about Kotlin\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Here's a Kotlin joke:\n",
       "\n",
       "Why do Kotlin developers never get lost?\n",
       "\n",
       "Because they always have a Nullable compass! (?.compass)\n",
       "\n",
       "*ba dum tss* ðŸ˜„\n",
       "\n",
       "It's a play on Kotlin's safe call operator (?.) which helps prevent null pointer exceptions. Not the most hilarious joke, but it's type-safe! ðŸ˜‰"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "And now we have a joke about Kotlin!\n",
    "\n",
    "This API is still specific to a particular provider.\n",
    "You might need an even higher level of abstraction,\n",
    "where your logic doesn't depend on which model you're using.\n",
    "\n",
    "For this, we'll use the `ChatClient`:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T18:20:58.913641Z",
     "start_time": "2025-05-11T18:20:55.958951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val chatClient = ChatClient.create(anthropicChat)\n",
    "chatClient.prompt(\"Tell me a joke about Kotlin\").call().content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Here's a Kotlin joke:\n",
       "\n",
       "Why do Kotlin developers never get lost?\n",
       "\n",
       "Because they always have a Nullable compass! (They can check if it's null before following its direction) ðŸ˜„\n",
       "\n",
       "*ba dum tss* \n",
       "\n",
       "I know, it's a bit corny, but hey, it's safe to use! ðŸ˜‰"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Congratulations! Now we can write a simple joke and anecdote application.\n",
    "\n",
    "Check out the next notebooks to learn more about Kotlin and Spring AI."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "name": "kotlin",
   "version": "1.9.23",
   "mimetype": "text/x-kotlin",
   "file_extension": ".kt",
   "pygments_lexer": "kotlin",
   "codemirror_mode": "text/x-kotlin",
   "nbconvert_exporter": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
