{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Intro\n",
    "\n",
    "LLMs are becoming increasingly integrated into development workflows,\n",
    "creating demand for frameworks that make AI-based application development accessible.\n",
    "In the JVM and Kotlin ecosystem, Spring is exactly such a framework.\n",
    "Yes, that same Spring that has been around for over 20 years!\n",
    "\n",
    "Spring AI is a new addition that simplifies AI integration into your Kotlin code.\n",
    "Spring AI provides:\n",
    "\n",
    "* A unified API for working with various AI models and LLM providers (OpenAI, Anthropic, Ollama, etc.)\n",
    "* Components for prompt processing and context management\n",
    "* Built-in capabilities for vector stores and RAG applications\n",
    "\n",
    "In this series of posts, we'll explore the core features of Spring AI.\n",
    "Following programming tradition,\n",
    "our first post will be a \"Hello, world!\" of sorts:\n",
    "we'll connect to an LLM provider and ask it to tell us a joke.\n",
    "\n",
    "First, let's add the necessary dependencies.\n",
    "> [!NOTE] We'll be working with Claude models from Anthropic,\n",
    "> but we'll include commented code for OpenAI as well.\n",
    "> This will help you understand the general API approach regardless of which model you choose."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T10:53:37.661325Z",
     "start_time": "2025-03-24T10:53:37.303017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@file:DependsOn(\"org.springframework.ai:spring-ai-anthropic-spring-boot-starter:1.0.0-M6\")\n",
    "//@file:DependsOn(\"org.springframework.ai:spring-ai-openai-spring-boot-starter:1.0.0-M6\")\n",
    "@file:DependsOn(\"com.fasterxml.jackson.module:jackson-module-kotlin:2.18.2\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "To use the model, we need to provide an API key.\n",
    "\n",
    "You can obtain this API key from\n",
    "[console.anthropic.com](https://console.anthropic.com/settings/keys)\n",
    "for Anthropic models or from\n",
    "[platform.openai.com](https://platform.openai.com/api-keys)\n",
    "for OpenAI models.\n",
    "\n",
    "Then add the generated API key to your environment variables:\n",
    "\n",
    "[MacOS/Linux]\n",
    "```bash\n",
    "export ANTHROPIC_API_KEY=<INSERT KEY HERE> # for Anthropic\n",
    "export OPENAI_API_KEY=<INSERT KEY HERE> # for OpenAI\n",
    "\n",
    "```\n",
    "\n",
    "[Windows]\n",
    "```shell\n",
    "set ANTHROPIC_API_KEY=<INSERT KEY HERE> # for Anthropic\n",
    "set OPENAI_API_KEY=<INSERT KEY HERE> # for OpenAI\n",
    "```\n",
    "\n",
    "Let's retrieve the API key from environment variables:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T10:55:14.362116Z",
     "start_time": "2025-03-24T10:55:14.281052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val apiKey = System.getenv(\"ANTHROPIC_API_KEY\") ?: \"YOUR_ANTHROPIC_API_KEY\"\n",
    "//val apiKey = System.getenv(\"OPENAI_API_KEY\") ?: \"YOUR_OPENAI_API_KEY\""
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "First, let's create a low-level API client for our chosen provider.\n",
    "This only requires the API key:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T10:55:28.006552Z",
     "start_time": "2025-03-24T10:55:27.741602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import org.springframework.ai.anthropic.api.AnthropicApi\n",
    "//import org.springframework.ai.openai.api.OpenAiApi\n",
    "\n",
    "val anthropicApi = AnthropicApi(apiKey)\n",
    "//val openAiApi = OpenAiApi.builder().apiKey(apiKey).build()"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now that we have our client, we can make a simple model call:"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T10:55:49.094817Z",
     "start_time": "2025-03-24T10:55:47.556878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val anthropicMessage = AnthropicApi.AnthropicMessage(\n",
    "    listOf(AnthropicApi.ContentBlock(\"Tell me a joke\")), AnthropicApi.Role.USER\n",
    ")\n",
    "//val openAiMessage = OpenAiApi.ChatCompletionMessage(\"Tell me a joke\", OpenAiApi.ChatCompletionMessage.Role.USER)\n",
    "\n",
    "\n",
    "anthropicApi.chatCompletionEntity(\n",
    "    AnthropicApi.ChatCompletionRequest(\n",
    "        AnthropicApi.ChatModel.CLAUDE_3_5_SONNET.value,\n",
    "        listOf(anthropicMessage), null, 100, 0.8, false\n",
    "    )\n",
    ")\n",
    "//openAiApi.chatCompletionEntity(\n",
    "//    OpenAiApi.ChatCompletionRequest(listOf(openAiMessage), OpenAiApi.ChatModel.CHATGPT_4_O_LATEST.value, 0.8, false)\n",
    "//)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<200 OK OK,ChatCompletionResponse[id=msg_015hgKST86nP1Spu1Mc9BtJu, type=message, role=ASSISTANT, content=[ContentBlock[type=TEXT, source=null, text=Here's a classic one:\n",
       "\n",
       "Why don't scientists trust atoms?\n",
       "Because they make up everything! ðŸ˜„, index=null, id=null, name=null, input=null, toolUseId=null, content=null]], model=claude-3-5-sonnet-20241022, stopReason=end_turn, stopSequence=null, usage=Usage[inputTokens=11, outputTokens=27]],[:status:\"200\", anthropic-organization-id:\"ea22ac71-22a7-43cc-9c6a-0a6a2c25768f\", anthropic-ratelimit-input-tokens-limit:\"1000000\", anthropic-ratelimit-input-tokens-remaining:\"1000000\", anthropic-ratelimit-input-tokens-reset:\"2025-03-24T10:55:48Z\", anthropic-ratelimit-output-tokens-limit:\"2000000\", anthropic-ratelimit-output-tokens-remaining:\"2000000\", anthropic-ratelimit-output-tokens-reset:\"2025-03-24T10:55:48Z\", anthropic-ratelimit-requests-limit:\"7000\", anthropic-ratelimit-requests-remaining:\"6999\", anthropic-ratelimit-requests-reset:\"2025-03-24T10:55:48Z\", anthropic-ratelimit-tokens-limit:\"3000000\", anthropic-ratelimit-tokens-remaining:\"3000000\", anthropic-ratelimit-tokens-reset:\"2025-03-24T10:55:48Z\", cf-cache-status:\"DYNAMIC\", cf-ray:\"9255a365bd9483ca-IST\", content-length:\"398\", content-type:\"application/json\", date:\"Mon, 24 Mar 2025 10:55:49 GMT\", request-id:\"req_01Nhp49fjD8GrATXN5qLbcYY\", server:\"cloudflare\", via:\"1.1 google\", x-robots-tag:\"none\"]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Congratulations, that's our first joke!\n",
    "\n",
    "As you've noticed, this API doesn't look very convenient,\n",
    "but that's the nature of low-level APIs.\n",
    "\n",
    "Let's raise the abstraction level.\n",
    "We'll create `*ChatOptions` to help us set and use parameters for our LLM provider requests:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T10:56:42.725655Z",
     "start_time": "2025-03-24T10:56:42.679059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import org.springframework.ai.anthropic.AnthropicChatOptions\n",
    "//import org.springframework.ai.openai.OpenAiChatOptions\n",
    "\n",
    "val anthropicOptions = AnthropicChatOptions.builder()\n",
    "    .model(AnthropicApi.ChatModel.CLAUDE_3_5_SONNET)\n",
    "    .temperature(0.7)\n",
    "    .maxTokens(1024)\n",
    "    .build()\n",
    "//val openAiOptions = OpenAiChatOptions.builder()\n",
    "//    .model(OpenAiApi.ChatModel.CHATGPT_4_O_LATEST)\n",
    "//    .temperature(0.7)\n",
    "//    .build()"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now let's create a `*ChatModel`, which will help us get another joke:"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T10:56:45.963989Z",
     "start_time": "2025-03-24T10:56:45.919268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import org.springframework.ai.anthropic.AnthropicChatModel\n",
    "//import org.springframework.ai.openai.OpenAiChatModel\n",
    "\n",
    "val anthropicChat = AnthropicChatModel.builder()\n",
    "    .anthropicApi(anthropicApi)\n",
    "    .defaultOptions(anthropicOptions)\n",
    "    .build()\n",
    "//val openAiChat = OpenAiChatModel.builder()\n",
    "//    .openAiApi(openAiApi)\n",
    "//    .defaultOptions(openAiOptions)\n",
    "//    .build()"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's ask for a joke about Kotlin:"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T10:56:57.964584Z",
     "start_time": "2025-03-24T10:56:56.255065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "anthropicChat.call(\"Tell me a joke about Kotlin\")\n",
    "//openAiChat.call(\"Tell me a joke about Kotlin\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Here's a Kotlin joke:\n",
       "\n",
       "Why did the Kotlin developer quit their job?\n",
       "\n",
       "Because they couldn't handle all the null pressure! \n",
       "\n",
       "(A reference to Kotlin's null safety features, which help prevent the dreaded NullPointerException that Java developers often face) ðŸ˜„"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "And now we have a joke about Kotlin!\n",
    "\n",
    "This API is still specific to a particular provider.\n",
    "You might need an even higher level of abstraction,\n",
    "where your logic doesn't depend on which model you're using.\n",
    "\n",
    "For this, we'll use the `ChatClient`:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T10:57:46.394781Z",
     "start_time": "2025-03-24T10:57:44.043487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import org.springframework.ai.chat.client.ChatClient\n",
    "\n",
    "val chatClient = ChatClient.create(anthropicChat)\n",
    "chatClient.prompt(\"Tell me a joke about Kotlin\").call().content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Here's a Kotlin joke:\n",
       "\n",
       "Why do Kotlin developers never get lost?\n",
       "\n",
       "Because they always have a Nullable compass! (They can check if it's null before following its direction ðŸ˜‰)\n",
       "\n",
       "...I know, it's pretty bad, but hey, at least it's not as null-safe as Java jokes! ðŸ˜„"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Congratulations! Now we can write a simple joke and anecdote application.\n",
    "\n",
    "Check out the next notebooks to learn more about Kotlin and Spring AI."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "name": "kotlin",
   "version": "1.9.23",
   "mimetype": "text/x-kotlin",
   "file_extension": ".kt",
   "pygments_lexer": "kotlin",
   "codemirror_mode": "text/x-kotlin",
   "nbconvert_exporter": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
