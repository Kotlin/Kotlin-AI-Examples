{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Prompts\n",
    "\n",
    "Prompts are essentially the instructions or questions you give to AI models to get them to generate specific responses.\\\n",
    "Think of them as the conversation starter that guides what the AI will say back to you.\n",
    "\n",
    "This has even given rise to a field called \"Prompt Engineering\" — a discipline focused on developing and optimizing prompts for effective use of language models.\n",
    "\n",
    "In this notebook, we'll explore prompts in Spring AI:\n",
    "* Basic prompts\n",
    "* Message types\n",
    "* Prompting techniques\n",
    "\n",
    "Let's add the necessary dependencies:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:18:23.515443Z",
     "start_time": "2025-03-24T12:18:23.160457Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@file:DependsOn(\"org.springframework.ai:spring-ai-anthropic-spring-boot-starter:1.0.0-M6\")\n",
    "@file:DependsOn(\"com.fasterxml.jackson.module:jackson-module-kotlin:2.18.2\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "To use the model, we need to provide an API key.\n",
    "\n",
    "You can obtain this API key from\n",
    "[console.anthropic.com](https://console.anthropic.com/settings/keys)\n",
    "for Anthropic models or from\n",
    "[platform.openai.com](https://platform.openai.com/api-keys)\n",
    "for OpenAI models.\n",
    "\n",
    "Then add the generated API key to your environment variables:\n",
    "\n",
    "[MacOS/Linux]\n",
    "```bash\n",
    "export ANTHROPIC_API_KEY=<INSERT KEY HERE> # for Anthropic\n",
    "export OPENAI_API_KEY=<INSERT KEY HERE> # for OpenAI\n",
    "\n",
    "```\n",
    "\n",
    "[Windows]\n",
    "```shell\n",
    "set ANTHROPIC_API_KEY=<INSERT KEY HERE> # for Anthropic\n",
    "set OPENAI_API_KEY=<INSERT KEY HERE> # for OpenAI\n",
    "```\n",
    "\n",
    "Let's retrieve the API key from environment variables:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:18:23.586068Z",
     "start_time": "2025-03-24T12:18:23.520312Z"
    }
   },
   "cell_type": "code",
   "source": "val apiKey = System.getenv(\"ANTHROPIC_API_KEY\") ?: \"YOUR_ANTHROPIC_API_KEY\"",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Just like in the **`Intro`** notebook, let's create `ChatOptions` and a `ChatModel`."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:18:24.039870Z",
     "start_time": "2025-03-24T12:18:23.589973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import org.springframework.ai.anthropic.AnthropicChatModel\n",
    "import org.springframework.ai.anthropic.AnthropicChatOptions\n",
    "import org.springframework.ai.anthropic.api.AnthropicApi\n",
    "\n",
    "val anthropicApi = AnthropicApi(apiKey)\n",
    "val anthropicOptions = AnthropicChatOptions.builder()\n",
    "    .model(AnthropicApi.ChatModel.CLAUDE_3_5_SONNET)\n",
    "    .temperature(0.7)\n",
    "    .maxTokens(1024)\n",
    "    .build()\n",
    "\n",
    "val chatCompletion = AnthropicChatModel.builder()\n",
    "    .anthropicApi(anthropicApi)\n",
    "    .defaultOptions(anthropicOptions)\n",
    "    .build()"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## What makes a prompt?\n",
    "\n",
    "A prompt is simply a text request: \"tell me a joke\" or \"write a poem about mountains\"\n",
    "\n",
    "Let's ask our LLM to generate a haiku:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:18:26.052088Z",
     "start_time": "2025-03-24T12:18:24.046064Z"
    }
   },
   "cell_type": "code",
   "source": "chatCompletion.call(\"Generate a hokku\")",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Here's a hokku (also known as haiku):\n",
       "\n",
       "autumn twilight falls\n",
       "maple leaves dance with the wind\n",
       "red and gold raindrops"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If we're using `ChatClient` and the `Prompt` class, the request would look like this:"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:18:27.282801Z",
     "start_time": "2025-03-24T12:18:26.058266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import org.springframework.ai.chat.client.ChatClient\n",
    "import org.springframework.ai.chat.prompt.Prompt\n",
    "\n",
    "val chatClient = ChatClient.create(chatCompletion)\n",
    "\n",
    "val prompt = Prompt(\"Generate a hokku\")\n",
    "chatClient.prompt(prompt).call().content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Here's a hokku (also known as haiku):\n",
       "\n",
       "autumn twilight falls\n",
       "maple leaves dance with the wind\n",
       "crimson memories"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Type of messages\n",
    "\n",
    "In AI interactions, there are several message types (roles):\n",
    "* User — message from the user\n",
    "* Assistant — message from the AI\n",
    "* System — instructions that guide the AI's behavior\n",
    "* Tool — used for function calling"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### User messages\n",
    "\n",
    "We've been writing user messages all along.\n",
    "\n",
    "Let's explicitly define them now:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:18:30.295838Z",
     "start_time": "2025-03-24T12:18:27.288811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import org.springframework.ai.chat.messages.UserMessage\n",
    "\n",
    "val messages = Prompt(UserMessage(\"Generate a hokku\"), UserMessage(\"what's name of this hokku?\"))\n",
    "chatClient.prompt(messages).call().content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Here's a hokku (also known as haiku):\n",
       "\n",
       "Autumn leaves falling\n",
       "Dance with the evening breeze now\n",
       "Nature's last waltz ends\n",
       "\n",
       "We could call this hokku \"Autumn's Dance\" or \"Nature's Last Waltz\" as it captures the movement of falling leaves in autumn and compares it to a final dance.\n",
       "\n",
       "In traditional Japanese poetry, hokku/haiku weren't typically given titles, but in modern practice, especially in Western traditions, titles are sometimes added to provide additional context or enhance the meaning of the poem."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### System messages\n",
    "\n",
    "A system message tells the LLM how it should behave.\n",
    "In Spring-AI, you can send a system message in several ways.\n",
    "\n",
    "For instance, you can use a special function for `ChatClient` or create an instance of a system message and pass it to the LLM directly."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:18:32.115422Z",
     "start_time": "2025-03-24T12:18:30.301883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chatClient\n",
    "    .prompt()\n",
    "    .system(\"You are a financial expert. Answer briefly.\")\n",
    "    .user(\"If I had a time machine, should I buy Bitcoin in 2011?\")\n",
    "    .call()\n",
    "    .content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yes, absolutely. Bitcoin's price in 2011 was around $1, and it later reached an all-time high of nearly $69,000 in 2021. Even with market volatility, buying Bitcoin in 2011 would have yielded extraordinary returns."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:18:33.817084Z",
     "start_time": "2025-03-24T12:18:32.121500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import org.springframework.ai.chat.messages.Message\n",
    "import org.springframework.ai.chat.messages.SystemMessage\n",
    "\n",
    "val messages = listOf(\n",
    "    SystemMessage(\"You are a financial expert. Answer briefly.\"),\n",
    "    UserMessage(\"If I had a time machine, should I buy Bitcoin in 2011?\")\n",
    ")\n",
    "\n",
    "chatClient.prompt(Prompt(messages)).call().content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yes, absolutely. Bitcoin was worth less than $1 in early 2011 and reached nearly $69,000 at its peak in 2021. Even with price fluctuations, buying and holding Bitcoin from 2011 would have yielded extraordinary returns."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Assistant messages\n",
    "\n",
    "As mentioned earlier, an assistant message is essentially a message from the LLM.\n",
    "\n",
    "Let's create a simple conversation example:\n",
    "we'll give the LLM a system instruction,\n",
    "send a request,\n",
    "and after receiving a response,\n",
    "ask for clarification on a specific point."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:18:34.788372Z",
     "start_time": "2025-03-24T12:18:33.822816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val messages = mutableListOf(\n",
    "    SystemMessage(\"You are an assistant who always answers very briefly, using no more than 10 words.\"),\n",
    "    UserMessage(\"Tell me about the capital of France and its landmarks\")\n",
    ")\n",
    "val assistantMessage = chatClient.prompt(Prompt(messages.toList())).call().chatResponse()!!.result.output\n",
    "assistantMessage"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AssistantMessage [messageType=ASSISTANT, toolCalls=[], textContent=Paris: Eiffel Tower, Louvre, Notre-Dame Cathedral, Arc de Triomphe., metadata={messageType=ASSISTANT}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:18:36.014243Z",
     "start_time": "2025-03-24T12:18:34.800901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "messages.add(assistantMessage)\n",
    "messages.add(UserMessage(\"Tell me about the third landmark\"))\n",
    "\n",
    "chatClient.prompt(Prompt(messages.toList())).call().content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Notre-Dame Cathedral: historic Gothic church damaged by fire."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We've essentially created a simple dialogue between human and machine.\n",
    "\n",
    "Notice that in the last message,\n",
    "we deliberately formulated the request as:\n",
    "`\"Tell me about the third landmark\"`.\n",
    "If we hadn't sent this request along with the LLM's response about French landmarks,\n",
    "we wouldn't have received a meaningful answer."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Prompt templates\n",
    "\n",
    "Spring AI provides PromptTemplate for working with prompts. This class uses the OSS\n",
    "[String Template](https://www.stringtemplate.org/)\n",
    "engine developed by Terence Parr for constructing and managing prompts.\n",
    "\n",
    "This class allows you to use resources for prompts, making them easier to manage and localize in different languages.\n",
    "It also lets you insert your data into the prompt,\n",
    "which is especially useful when developing RAG applications (which we'll learn more about in future notebooks).\n",
    "\n",
    "Let's write a simple example using PromptTemplate:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:18:37.453200Z",
     "start_time": "2025-03-24T12:18:36.022969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import org.springframework.ai.chat.prompt.PromptTemplate\n",
    "\n",
    "fun capital(): PromptTemplate {\n",
    "    val message = \"The two largest cities in {country}\"\n",
    "    return PromptTemplate(message)\n",
    "}\n",
    "\n",
    "val prompt = capital().create(mapOf(\"country\" to \"France\"))\n",
    "chatClient.prompt(prompt).call().content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The two largest cities in France are:\n",
       "\n",
       "1. Paris (population approximately 2.2 million in the city proper, over 12 million in the metropolitan area)\n",
       "2. Marseille (population approximately 870,000 in the city proper, over 1.7 million in the metropolitan area)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Prompting techniques\n",
    "\n",
    "There are various techniques for crafting effective prompts that help us get better results from language models.\n",
    "These techniques range from simple to complex and can dramatically improve the quality of AI responses.\n",
    "\n",
    "We will consider techniques such as:\n",
    "* Zero-Shot Prompting\n",
    "* Few-Shot Prompting\n",
    "* Chain-of-Thought (CoT) Prompting\n",
    "* Meta Prompting\n",
    "* Generate Knowledge Prompting\n",
    "* Prompt Chaining\n",
    "\n",
    "These are far from all the techniques. There are many more."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Zero-Shot Prompting\n",
    "\n",
    "Zero-shot prompting is a technique where the model performs a task based on direct instruction without being provided examples or demonstrations.\n",
    "The model relies solely on its pre-training knowledge."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:18:38.411644Z",
     "start_time": "2025-03-24T12:18:37.459088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chatClient\n",
    "    .prompt(\"\"\"\n",
    "    Classify the text as neutral, negative, or positive.\n",
    "    Text: In my opinion, this restaurant is quite ordinary.\n",
    "    Tonality:\n",
    "    \"\"\")\n",
    "    .call()\n",
    "    .content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Few-Shot Prompting\n",
    "\n",
    "Few-shot prompting is a technique where several examples (demonstrations) of task performance are included in the prompt to help the model understand exactly how to perform a similar task.\n",
    "Instead of training the model from scratch, we provide context through examples directly in the prompt."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:18:40.109434Z",
     "start_time": "2025-03-24T12:18:38.416909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chatClient\n",
    "    .prompt(\"\"\"\n",
    "    \"Zumbrik\" is a small fluffy animal inhabiting the Altai Mountains. Example sentence with the word zumbrik:\n",
    "    During our expedition to the Altai Mountains we met a family of cute zumbriks.\n",
    "\n",
    "    \"Fyrkotat\" means to quickly rotate in one place. Example sentence with the word fyrkotat:\n",
    "    \"\"\")\n",
    "    .call()\n",
    "    .content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Here's a sentence using \"fyrkotat\":\n",
       "\n",
       "The excited puppy fyrkotat on the kitchen floor when it saw its owner preparing dinner."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In this example, we provided the model with one example (1-shot) of using a made-up word in a sentence.\n",
    "Based on this,\n",
    "the model understood the task and was able to create a similar sentence with another made-up word,\n",
    "following the demonstrated pattern."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Chain-of-Thought (CoT) Prompting\n",
    "\n",
    "Chain-of-Thought is a prompting technique that encourages the model to show intermediate steps of reasoning before providing the final answer.\n",
    "This is especially useful for complex tasks requiring mathematical calculations,\n",
    "logical analysis, or multi-step reasoning."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:18:42.358017Z",
     "start_time": "2025-03-24T12:18:40.115402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chatClient\n",
    "    .prompt(\"\"\"\n",
    "    In the group of numbers 15, 8, 3, 22, 7, 14, 26, do the odd numbers sum to an even number?\n",
    "    Let's reason step by step.\n",
    "    \"\"\")\n",
    "    .call()\n",
    "    .content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Let me solve this step by step.\n",
       "\n",
       "1) First, let's identify the odd numbers in the group:\n",
       "   * 15 is odd\n",
       "   * 3 is odd\n",
       "   * 7 is odd\n",
       "\n",
       "2) Now, let's add the odd numbers:\n",
       "   * 15 + 3 + 7 = 25\n",
       "\n",
       "3) Is 25 an even number?\n",
       "   * No, 25 is odd\n",
       "\n",
       "Therefore, the sum of the odd numbers in the group is NOT an even number.\n",
       "\n",
       "The answer is no."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Meta Prompting\n",
    "\n",
    "Meta prompting is an advanced technique that focuses on the structural and syntactic aspects of tasks rather than specific content details.\n",
    "It creates an abstract, structured way of interacting with the LLM,\n",
    "where the form and pattern of information are more important than the content itself."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:18:47.047132Z",
     "start_time": "2025-03-24T12:18:42.363883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chatClient\n",
    "    .prompt(\"\"\"\n",
    "    In problems of the format [problem P → solution S], follow this structure:\n",
    "    1. Define the variables from P\n",
    "    2. Construct an equation based on P\n",
    "    3. Solve the equation to find S\n",
    "    4. Verify the solution by substitution\n",
    "\n",
    "    Problem: A store had x apples. After selling 15 apples and then another 1/3 of the remaining apples, the store had 20 apples left. How many apples were there initially?\n",
    "    \"\"\")\n",
    "    .call()\n",
    "    .content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Let me solve this step by step.\n",
       "\n",
       "1. Define variables:\n",
       "   * Let x = initial number of apples\n",
       "   * 15 apples were sold first\n",
       "   * 1/3 of remaining apples were sold second\n",
       "   * 20 apples remained at the end\n",
       "\n",
       "2. Construct equation:\n",
       "   * After selling 15 apples: (x - 15) apples remain\n",
       "   * Then selling 1/3 of remaining: (x - 15) - (1/3)(x - 15) = 20\n",
       "   * Simplify: (x - 15)(1 - 1/3) = 20\n",
       "   * Simplify: (x - 15)(2/3) = 20\n",
       "\n",
       "3. Solve:\n",
       "   * (x - 15)(2/3) = 20\n",
       "   * x - 15 = 30\n",
       "   * x = 45\n",
       "\n",
       "4. Verify:\n",
       "   * Initial apples: 45\n",
       "   * After selling 15: 45 - 15 = 30\n",
       "   * After selling 1/3 of 30: 30 - (1/3)(30) = 30 - 10 = 20\n",
       "   * Final amount matches the given 20 apples\n",
       "\n",
       "Therefore, the store initially had 45 apples."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In this example, the meta prompt sets a general structure for approaching problem-solving,\n",
    "not focusing on specific content but offering a universal template for analysis and solution.\n",
    "The model follows this structure, applying it to the specific problem."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Generate Knowledge Prompting\n",
    "\n",
    "Generate Knowledge Prompting is a technique where the model first generates factual knowledge about a topic and then uses this knowledge to form a more accurate and well-founded answer.\n",
    "This technique is especially useful for tasks requiring common sense or factual accuracy."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:18:52.797767Z",
     "start_time": "2025-03-24T12:18:47.054557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chatClient\n",
    "    .prompt(\"\"\"\n",
    "    Request: Are lichens harmful to trees?\n",
    "    Generate knowledge:\n",
    "    \"\"\")\n",
    "    .call()\n",
    "    .content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Here's what you should know about lichens and their relationship with trees:\n",
       "\n",
       "1. General Impact\n",
       "- Lichens are typically harmless to trees\n",
       "- They are not parasitic and don't extract nutrients from trees\n",
       "- Lichens only use trees as a surface to grow on (substrate)\n",
       "\n",
       "2. Benefits\n",
       "- Can indicate good air quality (lichens are sensitive to pollution)\n",
       "- Provide habitat for small insects\n",
       "- Some lichens can fix nitrogen, benefiting the ecosystem\n",
       "- Add biodiversity to the environment\n",
       "\n",
       "3. Misconceptions\n",
       "- People often mistakenly blame lichens for tree decline\n",
       "- Lichens growing on trees is natural and normal\n",
       "- Their presence doesn't indicate tree disease\n",
       "\n",
       "4. Important Notes\n",
       "- Lichens tend to grow more on slow-growing or stressed trees\n",
       "- They appear more visible on declining trees because of reduced foliage\n",
       "- The tree's condition isn't caused by lichens, but other factors\n",
       "\n",
       "5. When to Be Concerned\n",
       "- If a tree has excessive lichen growth, it might indicate:\n",
       "  - Poor tree health from other causes\n",
       "  - Need for better growing conditions\n",
       "  - Possible underlying issues requiring investigation"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This technique allows the model to first gather relevant knowledge and then use it to form a more accurate and informative response."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Prompt Chaining\n",
    "\n",
    "Prompt Chaining is a technique where a complex task is broken down into several sequential subtasks.\n",
    "The answer from one prompt becomes the input data for the next, creating a chain of operations.\n",
    "This allows solving complex tasks, increases transparency, controllability, and reliability when working with LLMs."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:18:53.772861Z",
     "start_time": "2025-03-24T12:18:52.804178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val ctryCap = chatClient\n",
    "    .prompt(\"\"\"\n",
    "    Extract all mentions of countries and their capitals from the following text.  The answer should be a list in the format \"Country: Capital\".\n",
    "\n",
    "    Text:\n",
    "    France is famous for the Eiffel Tower in Paris, and Germany is known for its automotive industry with headquarters in Berlin.  Meanwhile, tourists enjoy the picturesque views of Rome in Italy and the castles near Madrid in Spain.\n",
    "    \"\"\")\n",
    "    .call()\n",
    "    .content()"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:18:59.022559Z",
     "start_time": "2025-03-24T12:18:53.777556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chatClient\n",
    "    .prompt(\"\"\"\n",
    "    Based on the following list of countries and their capitals, create a short guide to the three most interesting sights in each capital city:\n",
    "\n",
    "    $ctryCap\n",
    "    \"\"\")\n",
    "    .call()\n",
    "    .content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Here's a guide to three notable sights in each capital city:\n",
       "\n",
       "PARIS, FRANCE:\n",
       "1. Eiffel Tower - The iconic 324-meter iron lattice tower, offering spectacular city views and featuring restaurants and observation decks\n",
       "2. Louvre Museum - World's largest art museum, home to the Mona Lisa and thousands of priceless artworks and artifacts\n",
       "3. Notre-Dame Cathedral - Historic Gothic cathedral (currently under restoration) known for its architecture, gargoyles, and rich history\n",
       "\n",
       "BERLIN, GERMANY:\n",
       "1. Brandenburg Gate - 18th-century neoclassical monument symbolizing German unity and peace\n",
       "2. East Side Gallery - The longest remaining section of the Berlin Wall, covered in artistic murals\n",
       "3. Museum Island - UNESCO World Heritage site featuring five world-renowned museums in one location\n",
       "\n",
       "ROME, ITALY:\n",
       "1. Colosseum - Ancient amphitheater and iconic symbol of Imperial Rome\n",
       "2. Vatican Museums & Sistine Chapel - Home to masterpieces including Michelangelo's famous ceiling frescoes\n",
       "3. Trevi Fountain - Baroque fountain known for its stunning sculptures and coin-tossing tradition\n",
       "\n",
       "MADRID, SPAIN:\n",
       "1. Prado Museum - One of the world's finest art museums, featuring European masterpieces\n",
       "2. Royal Palace - Europe's largest royal palace by floor area, with stunning architecture and royal collections\n",
       "3. Plaza Mayor - Historic central square surrounded by traditional architecture and outdoor cafes"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Working with prompts is fundamental for both AI application users and developers.\n",
    "Spring AI and Kotlin provide a convenient and powerful API for this purpose.\n",
    "\n",
    "Check out the next notebook to learn more about Kotlin and Spring AI!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "name": "kotlin",
   "version": "1.9.23",
   "mimetype": "text/x-kotlin",
   "file_extension": ".kt",
   "pygments_lexer": "kotlin",
   "codemirror_mode": "text/x-kotlin",
   "nbconvert_exporter": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
