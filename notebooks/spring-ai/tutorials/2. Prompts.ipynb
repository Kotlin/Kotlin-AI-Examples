{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Prompts\n",
    "\n",
    "Prompts are essentially the instructions or questions you give to AI models to get them to generate specific responses.\\\n",
    "Think of them as the conversation starter that guides what the AI will say back to you.\n",
    "\n",
    "This has even given rise to a field called \"Prompt Engineering\" — a discipline focused on developing and optimizing prompts for effective use of language models.\n",
    "\n",
    "In this notebook, we'll explore prompts in Spring AI:\n",
    "* Basic prompts\n",
    "* Message types\n",
    "* Prompting techniques\n",
    "\n",
    "Let's add the necessary dependencies:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T18:21:22.364837Z",
     "start_time": "2025-05-11T18:21:21.380834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%useLatestDescriptors\n",
    "%use spring-ai-anthropic"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "To use the model, we need to provide an API key.\n",
    "\n",
    "You can obtain this API key from\n",
    "[console.anthropic.com](https://console.anthropic.com/settings/keys)\n",
    "for Anthropic models or from\n",
    "[platform.openai.com](https://platform.openai.com/api-keys)\n",
    "for OpenAI models.\n",
    "\n",
    "Then add the generated API key to your environment variables:\n",
    "\n",
    "[MacOS/Linux]\n",
    "```bash\n",
    "export ANTHROPIC_API_KEY=<INSERT KEY HERE> # for Anthropic\n",
    "export OPENAI_API_KEY=<INSERT KEY HERE> # for OpenAI\n",
    "\n",
    "```\n",
    "\n",
    "[Windows]\n",
    "```shell\n",
    "set ANTHROPIC_API_KEY=<INSERT KEY HERE> # for Anthropic\n",
    "set OPENAI_API_KEY=<INSERT KEY HERE> # for OpenAI\n",
    "```\n",
    "\n",
    "Let's retrieve the API key from environment variables:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T18:21:22.953678Z",
     "start_time": "2025-05-11T18:21:22.890736Z"
    }
   },
   "cell_type": "code",
   "source": "val apiKey = System.getenv(\"ANTHROPIC_API_KEY\") ?: \"YOUR_ANTHROPIC_API_KEY\"",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Just like in the **`Intro`** notebook, let's create `ChatOptions` and a `ChatModel`."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T18:21:30.039092Z",
     "start_time": "2025-05-11T18:21:29.787175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val anthropicApi = AnthropicApi.builder().apiKey(apiKey).build()\n",
    "val anthropicOptions = AnthropicChatOptions.builder()\n",
    "    .model(AnthropicApi.ChatModel.CLAUDE_3_5_SONNET)\n",
    "    .temperature(0.7)\n",
    "    .maxTokens(1024)\n",
    "    .build()\n",
    "\n",
    "val chatCompletion = AnthropicChatModel.builder()\n",
    "    .anthropicApi(anthropicApi)\n",
    "    .defaultOptions(anthropicOptions)\n",
    "    .build()"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## What makes a prompt?\n",
    "\n",
    "A prompt is simply a text request: \"tell me a joke\" or \"write a poem about mountains\"\n",
    "\n",
    "Let's ask our LLM to generate a haiku:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T18:21:33.985242Z",
     "start_time": "2025-05-11T18:21:32.039136Z"
    }
   },
   "cell_type": "code",
   "source": "chatCompletion.call(\"Generate a hokku\")",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Here's a hokku (also known as haiku):\n",
       "\n",
       "autumn leaves falling\n",
       "a lone crow takes to the sky\n",
       "shadows dance below"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If we're using `ChatClient` and the `Prompt` class, the request would look like this:"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T18:21:38.721627Z",
     "start_time": "2025-05-11T18:21:36.629388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val chatClient = ChatClient.create(chatCompletion)\n",
    "\n",
    "val prompt = Prompt(\"Generate a hokku\")\n",
    "chatClient.prompt(prompt).call().content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Here's a hokku (also known as haiku):\n",
       "\n",
       "autumn leaves falling\n",
       "a crow takes sudden flight while\n",
       "shadows cross the moon"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Type of messages\n",
    "\n",
    "In AI interactions, there are several message types (roles):\n",
    "* User — message from the user\n",
    "* Assistant — message from the AI\n",
    "* System — instructions that guide the AI's behavior\n",
    "* Tool — used for function calling"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### User messages\n",
    "\n",
    "We've been writing user messages all along.\n",
    "\n",
    "Let's explicitly define them now:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T18:21:46.602579Z",
     "start_time": "2025-05-11T18:21:42.491516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val messages = Prompt(UserMessage(\"Generate a hokku\"), UserMessage(\"what's name of this hokku?\"))\n",
    "chatClient.prompt(messages).call().content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Here's a hokku (also known as haiku):\n",
       "\n",
       "Morning dew sparkles\n",
       "On spider's silken threads while\n",
       "Autumn leaves flutter\n",
       "\n",
       "We could call this hokku \"Autumn Morning\" as it captures a moment in nature during the autumn season, featuring morning dew and falling leaves.\n",
       "\n",
       "Note: Traditional hokku follows a 5-7-5 syllable pattern and typically includes a seasonal reference (kigo) and a cutting word (kireji). This example maintains the syllable pattern and includes autumn as the seasonal reference."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### System messages\n",
    "\n",
    "A system message tells the LLM how it should behave.\n",
    "In Spring-AI, you can send a system message in several ways.\n",
    "\n",
    "For instance, you can use a special function for `ChatClient` or create an instance of a system message and pass it to the LLM directly."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T18:21:50.437289Z",
     "start_time": "2025-05-11T18:21:46.665265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chatClient\n",
    "    .prompt()\n",
    "    .system(\"You are a financial expert. Answer briefly.\")\n",
    "    .user(\"If I had a time machine, should I buy Bitcoin in 2011?\")\n",
    "    .call()\n",
    "    .content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yes, absolutely. Bitcoin was worth less than $1 in early 2011 and reached nearly $69,000 at its peak in 2021. Even with price fluctuations, buying and holding Bitcoin from 2011 would have yielded extraordinary returns on investment."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T18:21:53.518636Z",
     "start_time": "2025-05-11T18:21:50.496638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val messages = listOf(\n",
    "    SystemMessage(\"You are a financial expert. Answer briefly.\"),\n",
    "    UserMessage(\"If I had a time machine, should I buy Bitcoin in 2011?\")\n",
    ")\n",
    "\n",
    "chatClient.prompt(Prompt(messages)).call().content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yes, absolutely. Bitcoin was worth less than $1 in early 2011 and reached nearly $69,000 at its peak in 2021. Even with price fluctuations, buying and holding Bitcoin from 2011 would have yielded astronomical returns."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Assistant messages\n",
    "\n",
    "As mentioned earlier, an assistant message is essentially a message from the LLM.\n",
    "\n",
    "Let's create a simple conversation example:\n",
    "we'll give the LLM a system instruction,\n",
    "send a request,\n",
    "and after receiving a response,\n",
    "ask for clarification on a specific point."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T18:21:55.723548Z",
     "start_time": "2025-05-11T18:21:53.579486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val messages = mutableListOf(\n",
    "    SystemMessage(\"You are an assistant who always answers very briefly, using no more than 10 words.\"),\n",
    "    UserMessage(\"Tell me about the capital of France and its landmarks\")\n",
    ")\n",
    "val assistantMessage = chatClient.prompt(Prompt(messages.toList())).call().chatResponse()!!.result.output\n",
    "assistantMessage"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AssistantMessage [messageType=ASSISTANT, toolCalls=[], textContent=Paris has Eiffel Tower, Notre-Dame, and Louvre Museum., metadata={messageType=ASSISTANT}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T18:21:58.143681Z",
     "start_time": "2025-05-11T18:21:56.728470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "messages.add(assistantMessage)\n",
    "messages.add(UserMessage(\"Tell me about the third landmark\"))\n",
    "\n",
    "chatClient.prompt(Prompt(messages.toList())).call().content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Louvre Museum displays famous art, including Mona Lisa."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We've essentially created a simple dialogue between human and machine.\n",
    "\n",
    "Notice that in the last message,\n",
    "we deliberately formulated the request as:\n",
    "`\"Tell me about the third landmark\"`.\n",
    "If we hadn't sent this request along with the LLM's response about French landmarks,\n",
    "we wouldn't have received a meaningful answer."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Prompt templates\n",
    "\n",
    "Spring AI provides PromptTemplate for working with prompts. This class uses the OSS\n",
    "[String Template](https://www.stringtemplate.org/)\n",
    "engine developed by Terence Parr for constructing and managing prompts.\n",
    "\n",
    "This class allows you to use resources for prompts, making them easier to manage and localize in different languages.\n",
    "It also lets you insert your data into the prompt,\n",
    "which is especially useful when developing RAG applications (which we'll learn more about in future notebooks).\n",
    "\n",
    "Let's write a simple example using PromptTemplate:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T18:22:07.414730Z",
     "start_time": "2025-05-11T18:22:02.446668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fun capital(): PromptTemplate {\n",
    "    val message = \"The two largest cities in {country}\"\n",
    "    return PromptTemplate(message)\n",
    "}\n",
    "\n",
    "val prompt = capital().create(mapOf(\"country\" to \"France\"))\n",
    "chatClient.prompt(prompt).call().content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The two largest cities in France are:\n",
       "\n",
       "1. Paris (population approximately 2.2 million in the city proper, over 12 million in the metropolitan area)\n",
       "2. Marseille (population approximately 870,000 in the city proper, over 1.7 million in the metropolitan area)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Prompting techniques\n",
    "\n",
    "There are various techniques for crafting effective prompts that help us get better results from language models.\n",
    "These techniques range from simple to complex and can dramatically improve the quality of AI responses.\n",
    "\n",
    "We will consider techniques such as:\n",
    "* Zero-Shot Prompting\n",
    "* Few-Shot Prompting\n",
    "* Chain-of-Thought (CoT) Prompting\n",
    "* Meta Prompting\n",
    "* Generate Knowledge Prompting\n",
    "* Prompt Chaining\n",
    "\n",
    "These are far from all the techniques. There are many more."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Zero-Shot Prompting\n",
    "\n",
    "Zero-shot prompting is a technique where the model performs a task based on direct instruction without being provided examples or demonstrations.\n",
    "The model relies solely on its pre-training knowledge."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T18:22:09.902454Z",
     "start_time": "2025-05-11T18:22:07.421985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chatClient\n",
    "    .prompt(\"\"\"\n",
    "    Classify the text as neutral, negative, or positive.\n",
    "    Text: In my opinion, this restaurant is quite ordinary.\n",
    "    Tonality:\n",
    "    \"\"\")\n",
    "    .call()\n",
    "    .content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral\n",
       "\n",
       "The text \"In my opinion, this restaurant is quite ordinary\" expresses a neutral sentiment. The word \"ordinary\" suggests neither particularly good nor bad qualities, just average or standard, making this a neutral statement."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Few-Shot Prompting\n",
    "\n",
    "Few-shot prompting is a technique where several examples (demonstrations) of task performance are included in the prompt to help the model understand exactly how to perform a similar task.\n",
    "Instead of training the model from scratch, we provide context through examples directly in the prompt."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T18:22:12.805651Z",
     "start_time": "2025-05-11T18:22:09.908237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chatClient\n",
    "    .prompt(\"\"\"\n",
    "    \"Zumbrik\" is a small fluffy animal inhabiting the Altai Mountains. Example sentence with the word zumbrik:\n",
    "    During our expedition to the Altai Mountains we met a family of cute zumbriks.\n",
    "\n",
    "    \"Fyrkotat\" means to quickly rotate in one place. Example sentence with the word fyrkotat:\n",
    "    \"\"\")\n",
    "    .call()\n",
    "    .content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Here's an example sentence using \"fyrkotat\":\n",
       "\n",
       "The excited puppy fyrkotat on the carpet when it saw its owner coming home with treats.\n",
       "\n",
       "(Note: I understand both \"zumbrik\" and \"fyrkotat\" are made-up words being used for this exercise, and I've created a sentence that demonstrates the given meaning of \"fyrkotat\" - to quickly rotate in one place.)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In this example, we provided the model with one example (1-shot) of using a made-up word in a sentence.\n",
    "Based on this,\n",
    "the model understood the task and was able to create a similar sentence with another made-up word,\n",
    "following the demonstrated pattern."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Chain-of-Thought (CoT) Prompting\n",
    "\n",
    "Chain-of-Thought is a prompting technique that encourages the model to show intermediate steps of reasoning before providing the final answer.\n",
    "This is especially useful for complex tasks requiring mathematical calculations,\n",
    "logical analysis, or multi-step reasoning."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T18:22:16.321916Z",
     "start_time": "2025-05-11T18:22:12.867612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chatClient\n",
    "    .prompt(\"\"\"\n",
    "    In the group of numbers 15, 8, 3, 22, 7, 14, 26, do the odd numbers sum to an even number?\n",
    "    Let's reason step by step.\n",
    "    \"\"\")\n",
    "    .call()\n",
    "    .content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Let me solve this step by step.\n",
       "\n",
       "1) First, let's identify the odd numbers in the group:\n",
       "   * 15 is odd\n",
       "   * 3 is odd\n",
       "   * 7 is odd\n",
       "\n",
       "2) Now, let's add these odd numbers:\n",
       "   * 15 + 3 + 7 = 25\n",
       "\n",
       "3) Is 25 an even number?\n",
       "   * No, 25 is odd\n",
       "\n",
       "Therefore, the sum of the odd numbers in this group is not an even number.\n",
       "\n",
       "The answer is no."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Meta Prompting\n",
    "\n",
    "Meta prompting is an advanced technique that focuses on the structural and syntactic aspects of tasks rather than specific content details.\n",
    "It creates an abstract, structured way of interacting with the LLM,\n",
    "where the form and pattern of information are more important than the content itself."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T18:22:22.796191Z",
     "start_time": "2025-05-11T18:22:17.559101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chatClient\n",
    "    .prompt(\"\"\"\n",
    "    In problems of the format [problem P → solution S], follow this structure:\n",
    "    1. Define the variables from P\n",
    "    2. Construct an equation based on P\n",
    "    3. Solve the equation to find S\n",
    "    4. Verify the solution by substitution\n",
    "\n",
    "    Problem: A store had x apples. After selling 15 apples and then another 1/3 of the remaining apples, the store had 20 apples left. How many apples were there initially?\n",
    "    \"\"\")\n",
    "    .call()\n",
    "    .content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Let me solve this step by step.\n",
       "\n",
       "1. Define variables:\n",
       "   * Let x = initial number of apples\n",
       "   * 15 apples were sold first\n",
       "   * 1/3 of remaining apples were sold second\n",
       "   * 20 apples remained at the end\n",
       "\n",
       "2. Construct equation:\n",
       "   * After selling 15 apples: (x - 15) apples remained\n",
       "   * After selling 1/3 of remaining: (x - 15) - (1/3)(x - 15) = 20\n",
       "   * Simplify: (x - 15)(1 - 1/3) = 20\n",
       "   * Simplify: (x - 15)(2/3) = 20\n",
       "\n",
       "3. Solve equation:\n",
       "   * (x - 15)(2/3) = 20\n",
       "   * x - 15 = 20 × (3/2)\n",
       "   * x - 15 = 30\n",
       "   * x = 45\n",
       "\n",
       "4. Verify solution:\n",
       "   * Initial apples: 45\n",
       "   * After selling 15: 45 - 15 = 30\n",
       "   * After selling 1/3 of 30: 30 - (1/3 × 30) = 30 - 10 = 20\n",
       "   * Final amount matches given: 20 apples\n",
       "\n",
       "Therefore, there were 45 apples initially."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In this example, the meta prompt sets a general structure for approaching problem-solving,\n",
    "not focusing on specific content but offering a universal template for analysis and solution.\n",
    "The model follows this structure, applying it to the specific problem."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Generate Knowledge Prompting\n",
    "\n",
    "Generate Knowledge Prompting is a technique where the model first generates factual knowledge about a topic and then uses this knowledge to form a more accurate and well-founded answer.\n",
    "This technique is especially useful for tasks requiring common sense or factual accuracy."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T18:22:29.433580Z",
     "start_time": "2025-05-11T18:22:22.804037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val knowledge = chatClient\n",
    "    .prompt(\"\"\"\n",
    "    Request: Are lichens harmful to trees?\n",
    "    Generate knowledge:\n",
    "    \"\"\")\n",
    "    .call()\n",
    "    .content()\n",
    "\n",
    "knowledge"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Here's what you should know about lichens and their relationship with trees:\n",
       "\n",
       "Key Facts:\n",
       "1. Lichens are generally harmless to trees\n",
       "- They are not parasitic\n",
       "- Don't extract nutrients from trees\n",
       "- Don't damage bark or wood\n",
       "- Serve as indicators of good air quality\n",
       "\n",
       "2. Benefits of lichens:\n",
       "- Provide habitat for small insects\n",
       "- Some birds use them for nesting material\n",
       "- Can help with nitrogen fixation\n",
       "- Part of healthy forest ecosystems\n",
       "\n",
       "3. Common misconceptions:\n",
       "- People often mistake lichens for tree diseases\n",
       "- Presence of lichens doesn't indicate tree decline\n",
       "- Lichens grow more visibly on slower-growing trees\n",
       "\n",
       "4. When to be concerned:\n",
       "- Heavy lichen growth might indicate:\n",
       "  * Slow tree growth\n",
       "  * Poor tree vigor\n",
       "  * Need for improved growing conditions\n",
       "- But lichens themselves aren't causing these issues\n",
       "\n",
       "5. Lichen growth patterns:\n",
       "- More common on older trees\n",
       "- Thrive in moist environments\n",
       "- Often grow on north-facing sides\n",
       "- Can appear on both healthy and unhealthy trees"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T18:22:32.029227Z",
     "start_time": "2025-05-11T18:22:29.441884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chatClient\n",
    "    .prompt(\"\"\"\n",
    "    Answer briefly: Are lichens harmful to trees?\n",
    "\n",
    "    knowledge: $knowledge\n",
    "    \"\"\")\n",
    "    .call()\n",
    "    .content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No, lichens are not harmful to trees. They are non-parasitic organisms that simply use trees as a surface to grow on, without extracting nutrients or damaging the bark or wood. While heavy lichen growth might indicate a slow-growing tree, the lichens themselves aren't causing any problems - they're actually a sign of good air quality and are part of a healthy forest ecosystem."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This technique allows the model to first gather relevant knowledge and then use it to form a more accurate and informative response."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Prompt Chaining\n",
    "\n",
    "Prompt Chaining is a technique where a complex task is broken down into several sequential subtasks.\n",
    "The answer from one prompt becomes the input data for the next, creating a chain of operations.\n",
    "This allows solving complex tasks, increases transparency, controllability, and reliability when working with LLMs."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T18:22:33.589423Z",
     "start_time": "2025-05-11T18:22:32.033803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val ctryCap = chatClient\n",
    "    .prompt(\"\"\"\n",
    "    Extract all mentions of countries and their capitals from the following text.  The answer should be a list in the format \"Country: Capital\".\n",
    "\n",
    "    Text:\n",
    "    France is famous for the Eiffel Tower in Paris, and Germany is known for its automotive industry with headquarters in Berlin.  Meanwhile, tourists enjoy the picturesque views of Rome in Italy and the castles near Madrid in Spain.\n",
    "    \"\"\")\n",
    "    .call()\n",
    "    .content()"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T18:22:39.750970Z",
     "start_time": "2025-05-11T18:22:33.598514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chatClient\n",
    "    .prompt(\"\"\"\n",
    "    Based on the following list of countries and their capitals, create a short guide to the three most interesting sights in each capital city:\n",
    "\n",
    "    $ctryCap\n",
    "    \"\"\")\n",
    "    .call()\n",
    "    .content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Here's a guide to three fascinating sights in each capital city:\n",
       "\n",
       "PARIS, FRANCE:\n",
       "1. Eiffel Tower - The iconic 324-meter iron lattice tower offering spectacular city views from three observation levels\n",
       "2. Louvre Museum - Home to thousands of artworks including the Mona Lisa, housed in a historic palace\n",
       "3. Notre-Dame Cathedral - Magnificent Gothic cathedral (currently under restoration) known for its architecture and gargoyles\n",
       "\n",
       "BERLIN, GERMANY:\n",
       "1. Brandenburg Gate - 18th-century neoclassical monument symbolizing German unity and peace\n",
       "2. East Side Gallery - The longest remaining section of the Berlin Wall, covered in historic murals\n",
       "3. Museum Island - UNESCO World Heritage site hosting five world-renowned museums\n",
       "\n",
       "ROME, ITALY:\n",
       "1. Colosseum - Ancient amphitheater showcasing Roman engineering and gladiatorial history\n",
       "2. Vatican Museums & Sistine Chapel - Home to masterpieces including Michelangelo's famous ceiling frescoes\n",
       "3. Trevi Fountain - Baroque fountain known for its stunning sculptures and coin-tossing tradition\n",
       "\n",
       "MADRID, SPAIN:\n",
       "1. Prado Museum - One of the world's finest art museums, featuring European masterpieces\n",
       "2. Royal Palace - Europe's largest royal palace by floor area, with stunning architecture and royal collections\n",
       "3. Plaza Mayor - Historic central square surrounded by traditional architecture and outdoor cafes"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Working with prompts is fundamental for both AI application users and developers.\n",
    "Spring AI and Kotlin provide a convenient and powerful API for this purpose.\n",
    "\n",
    "Check out the next notebook to learn more about Kotlin and Spring AI!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "name": "kotlin",
   "version": "1.9.23",
   "mimetype": "text/x-kotlin",
   "file_extension": ".kt",
   "pygments_lexer": "kotlin",
   "codemirror_mode": "text/x-kotlin",
   "nbconvert_exporter": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
