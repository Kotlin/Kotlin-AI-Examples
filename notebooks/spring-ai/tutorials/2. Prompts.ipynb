{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Prompts\n",
    "\n",
    "Prompts are essentially the instructions or questions you give to AI models to get them to generate specific responses.\\\n",
    "Think of them as the conversation starter that guides what the AI will say back to you.\n",
    "\n",
    "This has even given rise to a field called \"Prompt Engineering\" — a discipline focused on developing and optimizing prompts for effective use of language models.\n",
    "\n",
    "In this notebook, we'll explore prompts in Spring AI:\n",
    "* Basic prompts\n",
    "* Message types\n",
    "* Prompting techniques\n",
    "\n",
    "Let's add the necessary dependencies:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:24:33.229012Z",
     "start_time": "2025-03-24T12:24:32.873776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@file:DependsOn(\"org.springframework.ai:spring-ai-anthropic-spring-boot-starter:1.0.0-M6\")\n",
    "@file:DependsOn(\"com.fasterxml.jackson.module:jackson-module-kotlin:2.18.2\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "To use the model, we need to provide an API key.\n",
    "\n",
    "You can obtain this API key from\n",
    "[console.anthropic.com](https://console.anthropic.com/settings/keys)\n",
    "for Anthropic models or from\n",
    "[platform.openai.com](https://platform.openai.com/api-keys)\n",
    "for OpenAI models.\n",
    "\n",
    "Then add the generated API key to your environment variables:\n",
    "\n",
    "[MacOS/Linux]\n",
    "```bash\n",
    "export ANTHROPIC_API_KEY=<INSERT KEY HERE> # for Anthropic\n",
    "export OPENAI_API_KEY=<INSERT KEY HERE> # for OpenAI\n",
    "\n",
    "```\n",
    "\n",
    "[Windows]\n",
    "```shell\n",
    "set ANTHROPIC_API_KEY=<INSERT KEY HERE> # for Anthropic\n",
    "set OPENAI_API_KEY=<INSERT KEY HERE> # for OpenAI\n",
    "```\n",
    "\n",
    "Let's retrieve the API key from environment variables:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:24:33.299855Z",
     "start_time": "2025-03-24T12:24:33.233175Z"
    }
   },
   "cell_type": "code",
   "source": "val apiKey = System.getenv(\"ANTHROPIC_API_KEY\") ?: \"YOUR_ANTHROPIC_API_KEY\"",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Just like in the **`Intro`** notebook, let's create `ChatOptions` and a `ChatModel`."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:24:33.720235Z",
     "start_time": "2025-03-24T12:24:33.303412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import org.springframework.ai.anthropic.AnthropicChatModel\n",
    "import org.springframework.ai.anthropic.AnthropicChatOptions\n",
    "import org.springframework.ai.anthropic.api.AnthropicApi\n",
    "\n",
    "val anthropicApi = AnthropicApi(apiKey)\n",
    "val anthropicOptions = AnthropicChatOptions.builder()\n",
    "    .model(AnthropicApi.ChatModel.CLAUDE_3_5_SONNET)\n",
    "    .temperature(0.7)\n",
    "    .maxTokens(1024)\n",
    "    .build()\n",
    "\n",
    "val chatCompletion = AnthropicChatModel.builder()\n",
    "    .anthropicApi(anthropicApi)\n",
    "    .defaultOptions(anthropicOptions)\n",
    "    .build()"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## What makes a prompt?\n",
    "\n",
    "A prompt is simply a text request: \"tell me a joke\" or \"write a poem about mountains\"\n",
    "\n",
    "Let's ask our LLM to generate a haiku:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:24:36.987206Z",
     "start_time": "2025-03-24T12:24:33.737381Z"
    }
   },
   "cell_type": "code",
   "source": "chatCompletion.call(\"Generate a hokku\")",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Here's a hokku (also known as haiku):\n",
       "\n",
       "autumn wind whispers\n",
       "through golden maple branches -\n",
       "one leaf lets go now\n",
       "\n",
       "This follows the traditional Japanese format with nature imagery and a seasonal reference (kigo), though I've written it in English. The rhythm roughly follows the 5-7-5 syllable pattern."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If we're using `ChatClient` and the `Prompt` class, the request would look like this:"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:24:38.610435Z",
     "start_time": "2025-03-24T12:24:36.994942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import org.springframework.ai.chat.client.ChatClient\n",
    "import org.springframework.ai.chat.prompt.Prompt\n",
    "\n",
    "val chatClient = ChatClient.create(chatCompletion)\n",
    "\n",
    "val prompt = Prompt(\"Generate a hokku\")\n",
    "chatClient.prompt(prompt).call().content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Here's a hokku (also known as haiku):\n",
       "\n",
       "autumn twilight falls\n",
       "maple leaves dance with the wind\n",
       "red stars in motion"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Type of messages\n",
    "\n",
    "In AI interactions, there are several message types (roles):\n",
    "* User — message from the user\n",
    "* Assistant — message from the AI\n",
    "* System — instructions that guide the AI's behavior\n",
    "* Tool — used for function calling"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### User messages\n",
    "\n",
    "We've been writing user messages all along.\n",
    "\n",
    "Let's explicitly define them now:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:24:43.333145Z",
     "start_time": "2025-03-24T12:24:38.617847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import org.springframework.ai.chat.messages.UserMessage\n",
    "\n",
    "val messages = Prompt(UserMessage(\"Generate a hokku\"), UserMessage(\"what's name of this hokku?\"))\n",
    "chatClient.prompt(messages).call().content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Here's a hokku (also known as haiku):\n",
       "\n",
       "Autumn leaves falling\n",
       "Dancing on gentle breezes\n",
       "Nature's last waltz ends\n",
       "\n",
       "We could call this hokku \"Autumn's Dance\" or \"Nature's Last Waltz\" as it captures the movement of falling leaves in autumn and compares it to a final dance before winter arrives.\n",
       "\n",
       "The traditional Japanese hokku didn't typically have titles, but in modern haiku practice, especially in Western traditions, titles are sometimes used."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### System messages\n",
    "\n",
    "A system message tells the LLM how it should behave.\n",
    "In Spring-AI, you can send a system message in several ways.\n",
    "\n",
    "For instance, you can use a special function for `ChatClient` or create an instance of a system message and pass it to the LLM directly."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:24:45.439272Z",
     "start_time": "2025-03-24T12:24:43.340688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chatClient\n",
    "    .prompt()\n",
    "    .system(\"You are a financial expert. Answer briefly.\")\n",
    "    .user(\"If I had a time machine, should I buy Bitcoin in 2011?\")\n",
    "    .call()\n",
    "    .content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yes, absolutely. Bitcoin was worth less than $1 in early 2011 and reached nearly $69,000 at its peak in 2021. Even with price fluctuations, buying and holding Bitcoin from 2011 would have yielded extraordinary returns on investment."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:24:48.144857Z",
     "start_time": "2025-03-24T12:24:45.448509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import org.springframework.ai.chat.messages.Message\n",
    "import org.springframework.ai.chat.messages.SystemMessage\n",
    "\n",
    "val messages = listOf(\n",
    "    SystemMessage(\"You are a financial expert. Answer briefly.\"),\n",
    "    UserMessage(\"If I had a time machine, should I buy Bitcoin in 2011?\")\n",
    ")\n",
    "\n",
    "chatClient.prompt(Prompt(messages)).call().content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yes, absolutely. Bitcoin was worth less than $1 in early 2011 and reached nearly $69,000 at its peak in 2021. Even with the later price drops, buying Bitcoin in 2011 would have been an incredibly profitable investment, yielding returns of over 20,000%."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Assistant messages\n",
    "\n",
    "As mentioned earlier, an assistant message is essentially a message from the LLM.\n",
    "\n",
    "Let's create a simple conversation example:\n",
    "we'll give the LLM a system instruction,\n",
    "send a request,\n",
    "and after receiving a response,\n",
    "ask for clarification on a specific point."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:24:49.774903Z",
     "start_time": "2025-03-24T12:24:48.152919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val messages = mutableListOf(\n",
    "    SystemMessage(\"You are an assistant who always answers very briefly, using no more than 10 words.\"),\n",
    "    UserMessage(\"Tell me about the capital of France and its landmarks\")\n",
    ")\n",
    "val assistantMessage = chatClient.prompt(Prompt(messages.toList())).call().chatResponse()!!.result.output\n",
    "assistantMessage"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AssistantMessage [messageType=ASSISTANT, toolCalls=[], textContent=Paris has Eiffel Tower, Notre-Dame, and Louvre Museum., metadata={messageType=ASSISTANT}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:24:50.999789Z",
     "start_time": "2025-03-24T12:24:49.785153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "messages.add(assistantMessage)\n",
    "messages.add(UserMessage(\"Tell me about the third landmark\"))\n",
    "\n",
    "chatClient.prompt(Prompt(messages.toList())).call().content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Louvre is world's largest art museum, home to Mona Lisa."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We've essentially created a simple dialogue between human and machine.\n",
    "\n",
    "Notice that in the last message,\n",
    "we deliberately formulated the request as:\n",
    "`\"Tell me about the third landmark\"`.\n",
    "If we hadn't sent this request along with the LLM's response about French landmarks,\n",
    "we wouldn't have received a meaningful answer."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Prompt templates\n",
    "\n",
    "Spring AI provides PromptTemplate for working with prompts. This class uses the OSS\n",
    "[String Template](https://www.stringtemplate.org/)\n",
    "engine developed by Terence Parr for constructing and managing prompts.\n",
    "\n",
    "This class allows you to use resources for prompts, making them easier to manage and localize in different languages.\n",
    "It also lets you insert your data into the prompt,\n",
    "which is especially useful when developing RAG applications (which we'll learn more about in future notebooks).\n",
    "\n",
    "Let's write a simple example using PromptTemplate:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:24:52.996699Z",
     "start_time": "2025-03-24T12:24:51.009897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import org.springframework.ai.chat.prompt.PromptTemplate\n",
    "\n",
    "fun capital(): PromptTemplate {\n",
    "    val message = \"The two largest cities in {country}\"\n",
    "    return PromptTemplate(message)\n",
    "}\n",
    "\n",
    "val prompt = capital().create(mapOf(\"country\" to \"France\"))\n",
    "chatClient.prompt(prompt).call().content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The two largest cities in France are:\n",
       "\n",
       "1. Paris (population approximately 2.2 million in the city proper, over 12 million in the metropolitan area)\n",
       "2. Marseille (population approximately 870,000 in the city proper, over 1.7 million in the metropolitan area)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Prompting techniques\n",
    "\n",
    "There are various techniques for crafting effective prompts that help us get better results from language models.\n",
    "These techniques range from simple to complex and can dramatically improve the quality of AI responses.\n",
    "\n",
    "We will consider techniques such as:\n",
    "* Zero-Shot Prompting\n",
    "* Few-Shot Prompting\n",
    "* Chain-of-Thought (CoT) Prompting\n",
    "* Meta Prompting\n",
    "* Generate Knowledge Prompting\n",
    "* Prompt Chaining\n",
    "\n",
    "These are far from all the techniques. There are many more."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Zero-Shot Prompting\n",
    "\n",
    "Zero-shot prompting is a technique where the model performs a task based on direct instruction without being provided examples or demonstrations.\n",
    "The model relies solely on its pre-training knowledge."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:24:54.307455Z",
     "start_time": "2025-03-24T12:24:53.002748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chatClient\n",
    "    .prompt(\"\"\"\n",
    "    Classify the text as neutral, negative, or positive.\n",
    "    Text: In my opinion, this restaurant is quite ordinary.\n",
    "    Tonality:\n",
    "    \"\"\")\n",
    "    .call()\n",
    "    .content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Few-Shot Prompting\n",
    "\n",
    "Few-shot prompting is a technique where several examples (demonstrations) of task performance are included in the prompt to help the model understand exactly how to perform a similar task.\n",
    "Instead of training the model from scratch, we provide context through examples directly in the prompt."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:24:56.279418Z",
     "start_time": "2025-03-24T12:24:54.315822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chatClient\n",
    "    .prompt(\"\"\"\n",
    "    \"Zumbrik\" is a small fluffy animal inhabiting the Altai Mountains. Example sentence with the word zumbrik:\n",
    "    During our expedition to the Altai Mountains we met a family of cute zumbriks.\n",
    "\n",
    "    \"Fyrkotat\" means to quickly rotate in one place. Example sentence with the word fyrkotat:\n",
    "    \"\"\")\n",
    "    .call()\n",
    "    .content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Here's an example sentence using \"fyrkotat\":\n",
       "\n",
       "The excited puppy fyrkotatted on the kitchen floor when it saw its owner preparing dinner."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In this example, we provided the model with one example (1-shot) of using a made-up word in a sentence.\n",
    "Based on this,\n",
    "the model understood the task and was able to create a similar sentence with another made-up word,\n",
    "following the demonstrated pattern."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Chain-of-Thought (CoT) Prompting\n",
    "\n",
    "Chain-of-Thought is a prompting technique that encourages the model to show intermediate steps of reasoning before providing the final answer.\n",
    "This is especially useful for complex tasks requiring mathematical calculations,\n",
    "logical analysis, or multi-step reasoning."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:24:58.809625Z",
     "start_time": "2025-03-24T12:24:56.288466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chatClient\n",
    "    .prompt(\"\"\"\n",
    "    In the group of numbers 15, 8, 3, 22, 7, 14, 26, do the odd numbers sum to an even number?\n",
    "    Let's reason step by step.\n",
    "    \"\"\")\n",
    "    .call()\n",
    "    .content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Let me solve this step by step.\n",
       "\n",
       "1) First, let's identify the odd numbers in the group:\n",
       "   * 15 is odd\n",
       "   * 3 is odd\n",
       "   * 7 is odd\n",
       "\n",
       "2) Now, let's add these odd numbers:\n",
       "   * 15 + 3 + 7 = 25\n",
       "\n",
       "3) Is 25 an even number?\n",
       "   * No, 25 is an odd number\n",
       "\n",
       "Therefore, the sum of odd numbers in this group is not an even number.\n",
       "\n",
       "The answer is no."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Meta Prompting\n",
    "\n",
    "Meta prompting is an advanced technique that focuses on the structural and syntactic aspects of tasks rather than specific content details.\n",
    "It creates an abstract, structured way of interacting with the LLM,\n",
    "where the form and pattern of information are more important than the content itself."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:25:03.477525Z",
     "start_time": "2025-03-24T12:24:58.818421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chatClient\n",
    "    .prompt(\"\"\"\n",
    "    In problems of the format [problem P → solution S], follow this structure:\n",
    "    1. Define the variables from P\n",
    "    2. Construct an equation based on P\n",
    "    3. Solve the equation to find S\n",
    "    4. Verify the solution by substitution\n",
    "\n",
    "    Problem: A store had x apples. After selling 15 apples and then another 1/3 of the remaining apples, the store had 20 apples left. How many apples were there initially?\n",
    "    \"\"\")\n",
    "    .call()\n",
    "    .content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Let me solve this step by step.\n",
       "\n",
       "1. Define variables:\n",
       "   * Let x = initial number of apples\n",
       "   * 15 apples were sold first\n",
       "   * 1/3 of remaining apples were sold second\n",
       "   * 20 apples remained at the end\n",
       "\n",
       "2. Construct equation:\n",
       "   * After selling 15 apples: x - 15 apples remain\n",
       "   * After selling 1/3 of remaining: (x - 15) - (1/3)(x - 15) = 20\n",
       "   * Simplify: (2/3)(x - 15) = 20\n",
       "\n",
       "3. Solve the equation:\n",
       "   * (2/3)(x - 15) = 20\n",
       "   * x - 15 = 20 × (3/2)\n",
       "   * x - 15 = 30\n",
       "   * x = 45\n",
       "\n",
       "4. Verify the solution:\n",
       "   * Initial apples: 45\n",
       "   * After selling 15: 45 - 15 = 30\n",
       "   * After selling 1/3 of 30: 30 - (1/3 × 30) = 30 - 10 = 20\n",
       "   * Final amount matches given: 20 apples\n",
       "\n",
       "Therefore, there were 45 apples initially."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In this example, the meta prompt sets a general structure for approaching problem-solving,\n",
    "not focusing on specific content but offering a universal template for analysis and solution.\n",
    "The model follows this structure, applying it to the specific problem."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Generate Knowledge Prompting\n",
    "\n",
    "Generate Knowledge Prompting is a technique where the model first generates factual knowledge about a topic and then uses this knowledge to form a more accurate and well-founded answer.\n",
    "This technique is especially useful for tasks requiring common sense or factual accuracy."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:25:09.362832Z",
     "start_time": "2025-03-24T12:25:03.488705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val knowledge = chatClient\n",
    "    .prompt(\"\"\"\n",
    "    Request: Are lichens harmful to trees?\n",
    "    Generate knowledge:\n",
    "    \"\"\")\n",
    "    .call()\n",
    "    .content()\n",
    "\n",
    "knowledge"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Here's what you should know about lichens and their relationship with trees:\n",
       "\n",
       "Key Facts:\n",
       "1. Lichens are generally harmless to trees\n",
       "- They are not parasitic\n",
       "- They don't extract nutrients from trees\n",
       "- They don't penetrate tree bark\n",
       "\n",
       "2. What lichens actually are:\n",
       "- Symbiotic organisms (fungi + algae)\n",
       "- Self-sustaining\n",
       "- Get nutrients from air and rainwater\n",
       "- Use trees only as a surface to grow on\n",
       "\n",
       "3. Potential Benefits:\n",
       "- Can indicate good air quality\n",
       "- Provide habitat for small insects\n",
       "- Some species fix nitrogen\n",
       "- Add biodiversity to ecosystems\n",
       "\n",
       "4. Common Misconceptions:\n",
       "- People often mistake them for tree diseases\n",
       "- Their presence doesn't indicate tree decline\n",
       "- They don't cause bark damage\n",
       "\n",
       "5. Important Notes:\n",
       "- Heavy lichen growth might indicate a slow-growing tree\n",
       "- Excessive growth can sometimes block sunlight to leaves\n",
       "- Removal isn't usually necessary\n",
       "- They're more visible on stressed trees but aren't the cause\n",
       "\n",
       "In summary, lichens are generally harmless companions to trees and their presence is often a sign of clean air and a healthy ecosystem."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:25:12.195012Z",
     "start_time": "2025-03-24T12:25:09.371581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chatClient\n",
    "    .prompt(\"\"\"\n",
    "    Answer briefly: Are lichens harmful to trees?\n",
    "\n",
    "    knowledge: $knowledge\n",
    "    \"\"\")\n",
    "    .call()\n",
    "    .content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No, lichens are not harmful to trees. They are non-parasitic organisms that simply use trees as a surface to grow on, without extracting nutrients from them or damaging the bark. While they may be more visible on stressed trees, they don't cause tree problems and are actually often indicators of good air quality."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This technique allows the model to first gather relevant knowledge and then use it to form a more accurate and informative response."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Prompt Chaining\n",
    "\n",
    "Prompt Chaining is a technique where a complex task is broken down into several sequential subtasks.\n",
    "The answer from one prompt becomes the input data for the next, creating a chain of operations.\n",
    "This allows solving complex tasks, increases transparency, controllability, and reliability when working with LLMs."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:25:13.574855Z",
     "start_time": "2025-03-24T12:25:12.215174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val ctryCap = chatClient\n",
    "    .prompt(\"\"\"\n",
    "    Extract all mentions of countries and their capitals from the following text.  The answer should be a list in the format \"Country: Capital\".\n",
    "\n",
    "    Text:\n",
    "    France is famous for the Eiffel Tower in Paris, and Germany is known for its automotive industry with headquarters in Berlin.  Meanwhile, tourists enjoy the picturesque views of Rome in Italy and the castles near Madrid in Spain.\n",
    "    \"\"\")\n",
    "    .call()\n",
    "    .content()"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:25:19.550577Z",
     "start_time": "2025-03-24T12:25:13.578332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chatClient\n",
    "    .prompt(\"\"\"\n",
    "    Based on the following list of countries and their capitals, create a short guide to the three most interesting sights in each capital city:\n",
    "\n",
    "    $ctryCap\n",
    "    \"\"\")\n",
    "    .call()\n",
    "    .content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Here's a guide to three notable sights in each capital city:\n",
       "\n",
       "PARIS, FRANCE:\n",
       "1. Eiffel Tower - The iconic 324-meter iron lattice tower, offering spectacular city views and a famous nightly light show\n",
       "2. The Louvre Museum - Home to thousands of artworks including the Mona Lisa, housed in a historic palace\n",
       "3. Notre-Dame Cathedral - The magnificent Gothic cathedral (currently under restoration) known for its architecture and gargoyles\n",
       "\n",
       "BERLIN, GERMANY:\n",
       "1. Brandenburg Gate - An 18th-century neoclassical monument symbolizing German unity and peace\n",
       "2. East Side Gallery - The longest remaining section of the Berlin Wall, covered in historic murals\n",
       "3. Museum Island - A UNESCO World Heritage site hosting five world-renowned museums\n",
       "\n",
       "ROME, ITALY:\n",
       "1. Colosseum - The iconic ancient amphitheater where gladiatorial contests were held\n",
       "2. Vatican Museums & Sistine Chapel - Home to masterpieces including Michelangelo's famous ceiling frescoes\n",
       "3. Trevi Fountain - The baroque fountain famous for its wish-granting legend and stunning architecture\n",
       "\n",
       "MADRID, SPAIN:\n",
       "1. Prado Museum - One of the world's finest art museums, featuring European masterpieces\n",
       "2. Royal Palace - Europe's largest royal palace by floor area, with stunning state rooms\n",
       "3. Plaza Mayor - A grand 17th-century square perfect for people-watching and experiencing Spanish culture"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Working with prompts is fundamental for both AI application users and developers.\n",
    "Spring AI and Kotlin provide a convenient and powerful API for this purpose.\n",
    "\n",
    "Check out the next notebook to learn more about Kotlin and Spring AI!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "name": "kotlin",
   "version": "1.9.23",
   "mimetype": "text/x-kotlin",
   "file_extension": ".kt",
   "pygments_lexer": "kotlin",
   "codemirror_mode": "text/x-kotlin",
   "nbconvert_exporter": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
