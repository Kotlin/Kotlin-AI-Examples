{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Advisors\n",
    "\n",
    "Advisors are an interesting feature in Spring-AI that allows you to flexibly intercept,\n",
    "modify, and enhance AI interactions.\n",
    "\n",
    "With `Advisors`, you can:\n",
    "- Add necessary context to user requests\n",
    "- Filter out harmful or sensitive content in AI requests\n",
    "- Track custom metrics\n",
    "- Ensure consistent output structure\n",
    "- And more\n",
    "\n",
    "Let's add dependencies and create a `ChatModel`"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T20:04:43.368939Z",
     "start_time": "2025-03-28T20:04:42.902444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@file:DependsOn(\"org.springframework.ai:spring-ai-openai-spring-boot-starter:1.0.0-M6\")\n",
    "@file:DependsOn(\"com.fasterxml.jackson.module:jackson-module-kotlin:2.18.2\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T20:04:45.251133Z",
     "start_time": "2025-03-28T20:04:44.807812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import org.springframework.ai.chat.client.ChatClient\n",
    "import org.springframework.ai.openai.OpenAiChatModel\n",
    "import org.springframework.ai.openai.OpenAiChatOptions\n",
    "import org.springframework.ai.openai.api.OpenAiApi\n",
    "\n",
    "val apiKey = System.getenv(\"OPENAI_API_KEY\") ?: \"YOUR_OPENAI_API_KEY\"\n",
    "\n",
    "val openAiApi = OpenAiApi.builder().apiKey(apiKey).build()\n",
    "val openAiOptions = OpenAiChatOptions.builder()\n",
    "    .model(OpenAiApi.ChatModel.GPT_4_O_MINI)\n",
    "    .temperature(0.7)\n",
    "    .build()\n",
    "\n",
    "\n",
    "val chatModel = OpenAiChatModel.builder()\n",
    "    .openAiApi(openAiApi)\n",
    "    .defaultOptions(openAiOptions)\n",
    "    .build()"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Let's add the `MessageChatMemory` advisor.\n",
    "As the name suggests, this advisor will implement message history,\n",
    "preserving the conversation context.\n",
    "For this Advisor, we'll need a `ChatMemory` instance\n",
    "where messages will be stored."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T20:04:46.235626Z",
     "start_time": "2025-03-28T20:04:46.085320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import org.springframework.ai.chat.client.advisor.MessageChatMemoryAdvisor\n",
    "import org.springframework.ai.chat.memory.ChatMemory\n",
    "import org.springframework.ai.chat.memory.InMemoryChatMemory\n",
    "\n",
    "val chatMemory = InMemoryChatMemory()\n",
    "\n",
    "val chatClient = ChatClient\n",
    "    .builder(chatModel)\n",
    "    .defaultAdvisors(MessageChatMemoryAdvisor(chatMemory))\n",
    "    .build()\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's test how this works"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T20:04:49.815623Z",
     "start_time": "2025-03-28T20:04:48.358708Z"
    }
   },
   "cell_type": "code",
   "source": "chatClient.prompt(\"Hi, tell me a joke\").call().content()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sure! Why did the scarecrow win an award?\n",
       "\n",
       "Because he was outstanding in his field!"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T20:04:52.494639Z",
     "start_time": "2025-03-28T20:04:51.326806Z"
    }
   },
   "cell_type": "code",
   "source": "chatClient.prompt(\"What is previous message in our chat history?\").call().content()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The previous message in our chat history was a joke: \"Why did the scarecrow win an award? Because he was outstanding in his field!\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "As we can see, the LLM now has access to our message history.\n",
    "\n",
    "Spring-AI includes several predefined Advisors:\n",
    "- `MessageChatMemoryAdvisor`\n",
    "- `PromptChatMemoryAdvisor`\n",
    "- `QuestionAnswerAdvisor`\n",
    "- `RetrievalAugmentationAdvisor`\n",
    "- `SafeGuardAdvisor`\n",
    "- `SimpleLoggerAdvisor`\n",
    "- `VectorStoreChatMemoryAdvisor`\n",
    "\n",
    "And you can create your own custom Advisor as well.\n",
    "\n",
    "Let's do that now.\n",
    "We'll create an Advisor that logs requests and responses by outputting them to our console.\n",
    "To do this, we'll extend `CallAroundAdvisor` and implement the `aroundCall` method"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T20:05:29.599111Z",
     "start_time": "2025-03-28T20:05:29.455960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import org.springframework.ai.chat.client.advisor.api.AdvisedRequest\n",
    "import org.springframework.ai.chat.client.advisor.api.AdvisedResponse\n",
    "import org.springframework.ai.chat.client.advisor.api.CallAroundAdvisor\n",
    "import org.springframework.ai.chat.client.advisor.api.CallAroundAdvisorChain\n",
    "\n",
    "class CustomLogger: CallAroundAdvisor {\n",
    "    override fun getName(): String {\n",
    "        return \"CustomLogger\"\n",
    "    }\n",
    "\n",
    "    override fun getOrder(): Int = 0\n",
    "\n",
    "    override fun aroundCall(advisedRequest: AdvisedRequest, chain: CallAroundAdvisorChain): AdvisedResponse {\n",
    "        println(\"CustomLogger.Before: ${advisedRequest}\")\n",
    "        val advisedResponse = chain.nextAroundCall(advisedRequest)\n",
    "        println(\"CustomLogger.After: ${advisedResponse}\")\n",
    "        return advisedResponse\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now let's see our `CustomAdvisor` in action"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T20:05:44.661267Z",
     "start_time": "2025-03-28T20:05:42.926917Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chatClient\n",
    "    .prompt(\"Generate HelloWorld in Kotlin\")\n",
    "    .advisors(CustomLogger())\n",
    "    .call()\n",
    "    .content()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomLogger.Before: AdvisedRequest[chatModel=OpenAiChatModel [defaultOptions=OpenAiChatOptions: {\"streamUsage\":false,\"model\":\"gpt-4o-mini\",\"temperature\":0.7}], userText=Generate HelloWorld in Kotlin, systemText=null, chatOptions=OpenAiChatOptions: {\"streamUsage\":false,\"model\":\"gpt-4o-mini\",\"temperature\":0.7}, media=[], functionNames=[], functionCallbacks=[], messages=[UserMessage{content='Hi, tell me a joke', properties={messageType=USER}, messageType=USER}, AssistantMessage [messageType=ASSISTANT, toolCalls=[], textContent=Sure! Why did the scarecrow win an award?\n",
      "\n",
      "Because he was outstanding in his field!, metadata={finishReason=STOP, refusal=, index=0, role=ASSISTANT, id=chatcmpl-BGAEb420M9SFn16wamX1DVRevyAS6, messageType=ASSISTANT}], UserMessage{content='What is previous message in our chat history?', properties={messageType=USER}, messageType=USER}, AssistantMessage [messageType=ASSISTANT, toolCalls=[], textContent=The previous message in our chat history was a joke: \"Why did the scarecrow win an award? Because he was outstanding in his field!\", metadata={finishReason=STOP, refusal=, index=0, role=ASSISTANT, id=chatcmpl-BGAEdB82V96dv0fQj2ULASyhcpoWK, messageType=ASSISTANT}]], userParams={}, systemParams={}, advisors=[org.springframework.ai.chat.client.DefaultChatClient$DefaultChatClientRequestSpec$1@61e0c0ac, org.springframework.ai.chat.client.DefaultChatClient$DefaultChatClientRequestSpec$2@608bb672, org.springframework.ai.chat.client.advisor.MessageChatMemoryAdvisor@23f756a0, org.springframework.ai.chat.client.DefaultChatClient$DefaultChatClientRequestSpec$1@2dc63c58, org.springframework.ai.chat.client.DefaultChatClient$DefaultChatClientRequestSpec$2@4a446cec, Line_11_jupyter$CustomLogger@77416bf0], advisorParams={}, adviseContext={}, toolContext={}]\n",
      "CustomLogger.After: AdvisedResponse[response=ChatResponse [metadata={ id: chatcmpl-BGAFTX1LAa1TuZNmZ8ORZEdANo2bH, usage: DefaultUsage{promptTokens=91, completionTokens=58, totalTokens=149}, rateLimit: { @type: org.springframework.ai.openai.metadata.OpenAiRateLimit, requestsLimit: 30000, requestsRemaining: 29999, requestsReset: PT0.002S, tokensLimit: 150000000; tokensRemaining: 149999916; tokensReset: PT0S } }, generations=[Generation[assistantMessage=AssistantMessage [messageType=ASSISTANT, toolCalls=[], textContent=Sure! Here's a simple \"Hello, World!\" program in Kotlin:\n",
      "\n",
      "```kotlin\n",
      "fun main() {\n",
      "    println(\"Hello, World!\")\n",
      "}\n",
      "```\n",
      "\n",
      "You can run this code in any Kotlin environment or IDE, and it will print \"Hello, World!\" to the console., metadata={finishReason=STOP, refusal=, index=0, role=ASSISTANT, id=chatcmpl-BGAFTX1LAa1TuZNmZ8ORZEdANo2bH, messageType=ASSISTANT}], chatGenerationMetadata=DefaultChatGenerationMetadata[finishReason='STOP', filters=0, metadata=0]]]], adviseContext={}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sure! Here's a simple \"Hello, World!\" program in Kotlin:\n",
       "\n",
       "```kotlin\n",
       "fun main() {\n",
       "    println(\"Hello, World!\")\n",
       "}\n",
       "```\n",
       "\n",
       "You can run this code in any Kotlin environment or IDE, and it will print \"Hello, World!\" to the console."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "name": "kotlin",
   "version": "1.9.23",
   "mimetype": "text/x-kotlin",
   "file_extension": ".kt",
   "pygments_lexer": "kotlin",
   "codemirror_mode": "text/x-kotlin",
   "nbconvert_exporter": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
