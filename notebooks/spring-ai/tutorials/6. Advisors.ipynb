{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Advisors\n",
    "\n",
    "Advisors are an interesting feature in Spring-AI that allows you to flexibly intercept,\n",
    "modify, and enhance AI interactions.\n",
    "\n",
    "With `Advisors`, you can:\n",
    "- Add necessary context to user requests\n",
    "- Filter out harmful or sensitive content in AI requests\n",
    "- Track custom metrics\n",
    "- Ensure consistent output structure\n",
    "- And more\n",
    "\n",
    "Let's add dependencies and create a `ChatModel`"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T18:36:14.795200Z",
     "start_time": "2025-05-11T18:36:13.823923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%useLatestDescriptors\n",
    "%use spring-ai-openai"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T18:36:15.083140Z",
     "start_time": "2025-05-11T18:36:14.798769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val apiKey = System.getenv(\"OPENAI_API_KEY\") ?: \"YOUR_OPENAI_API_KEY\"\n",
    "\n",
    "val openAiApi = OpenAiApi.builder().apiKey(apiKey).build()\n",
    "val openAiOptions = OpenAiChatOptions.builder()\n",
    "    .model(OpenAiApi.ChatModel.GPT_4_O_MINI)\n",
    "    .temperature(0.7)\n",
    "    .build()\n",
    "\n",
    "\n",
    "val chatModel = OpenAiChatModel.builder()\n",
    "    .openAiApi(openAiApi)\n",
    "    .defaultOptions(openAiOptions)\n",
    "    .build()"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Let's add the `MessageChatMemory` advisor.\n",
    "As the name suggests, this advisor will implement message history,\n",
    "preserving the conversation context.\n",
    "For this Advisor, we'll need a `ChatMemory` instance\n",
    "where messages will be stored."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T18:36:15.173726Z",
     "start_time": "2025-05-11T18:36:15.087172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val chatMemory = MessageWindowChatMemory.builder().build()\n",
    "\n",
    "val chatClient = ChatClient\n",
    "    .builder(chatModel)\n",
    "    .defaultAdvisors(MessageChatMemoryAdvisor(chatMemory))\n",
    "    .build()\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's test how this works"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T18:36:16.342903Z",
     "start_time": "2025-05-11T18:36:15.177608Z"
    }
   },
   "cell_type": "code",
   "source": "chatClient.prompt(\"Hi, tell me a joke\").call().content()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sure! Why did the scarecrow win an award? \n",
       "\n",
       "Because he was outstanding in his field!"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T18:36:17.286268Z",
     "start_time": "2025-05-11T18:36:16.347106Z"
    }
   },
   "cell_type": "code",
   "source": "chatClient.prompt(\"What is previous message in our chat history?\").call().content()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The previous message in our chat history was a joke: \"Why did the scarecrow win an award? Because he was outstanding in his field!\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "As we can see, the LLM now has access to our message history.\n",
    "\n",
    "Spring-AI includes several predefined Advisors:\n",
    "- `MessageChatMemoryAdvisor`\n",
    "- `PromptChatMemoryAdvisor`\n",
    "- `QuestionAnswerAdvisor`\n",
    "- `RetrievalAugmentationAdvisor`\n",
    "- `SafeGuardAdvisor`\n",
    "- `SimpleLoggerAdvisor`\n",
    "- `VectorStoreChatMemoryAdvisor`\n",
    "\n",
    "And you can create your own custom Advisor as well.\n",
    "\n",
    "Let's do that now.\n",
    "We'll create an Advisor that logs requests and responses by outputting them to our console.\n",
    "To do this, we'll extend `CallAroundAdvisor` and implement the `aroundCall` method"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T18:36:17.442802Z",
     "start_time": "2025-05-11T18:36:17.291557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import org.springframework.ai.chat.client.advisor.api.AdvisedRequest\n",
    "import org.springframework.ai.chat.client.advisor.api.AdvisedResponse\n",
    "import org.springframework.ai.chat.client.advisor.api.CallAroundAdvisor\n",
    "import org.springframework.ai.chat.client.advisor.api.CallAroundAdvisorChain\n",
    "\n",
    "\n",
    "class CustomLogger: CallAroundAdvisor {\n",
    "    override fun getName(): String {\n",
    "        return \"CustomLogger\"\n",
    "    }\n",
    "\n",
    "    override fun getOrder(): Int = 0\n",
    "\n",
    "    override fun aroundCall(advisedRequest: AdvisedRequest, chain: CallAroundAdvisorChain): AdvisedResponse {\n",
    "        println(\"CustomLogger.Before: ${advisedRequest}\")\n",
    "        val advisedResponse = chain.nextAroundCall(advisedRequest)\n",
    "        println(\"CustomLogger.After: ${advisedResponse}\")\n",
    "        return advisedResponse\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now let's see our `CustomAdvisor` in action"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T18:36:19.319693Z",
     "start_time": "2025-05-11T18:36:17.448459Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chatClient\n",
    "    .prompt(\"Generate HelloWorld in Kotlin\")\n",
    "    .advisors(CustomLogger())\n",
    "    .call()\n",
    "    .content()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomLogger.Before: AdvisedRequest[chatModel=OpenAiChatModel [defaultOptions=OpenAiChatOptions: {\"streamUsage\":false,\"model\":\"gpt-4o-mini\",\"temperature\":0.7}], userText=Generate HelloWorld in Kotlin, systemText=null, chatOptions=OpenAiChatOptions: {\"streamUsage\":false,\"model\":\"gpt-4o-mini\",\"temperature\":0.7}, media=[], toolNames=[], toolCallbacks=[], messages=[UserMessage{content='Hi, tell me a joke', properties={messageType=USER}, messageType=USER}, AssistantMessage [messageType=ASSISTANT, toolCalls=[], textContent=Sure! Why did the scarecrow win an award? \n",
      "\n",
      "Because he was outstanding in his field!, metadata={finishReason=STOP, refusal=, index=0, role=ASSISTANT, id=chatcmpl-BW5p1J0I5H63bmJysjT4KnsGhVSTJ, messageType=ASSISTANT}], UserMessage{content='What is previous message in our chat history?', properties={messageType=USER}, messageType=USER}, AssistantMessage [messageType=ASSISTANT, toolCalls=[], textContent=The previous message in our chat history was a joke: \"Why did the scarecrow win an award? Because he was outstanding in his field!\", metadata={finishReason=STOP, refusal=, index=0, role=ASSISTANT, id=chatcmpl-BW5p2XtUfyKu7J2lDAj51WV7sKd1n, messageType=ASSISTANT}]], userParams={}, systemParams={}, advisors=[org.springframework.ai.chat.client.advisor.MessageChatMemoryAdvisor@6f20c8da, Line_7_jupyter$CustomLogger@53b8129e, org.springframework.ai.chat.client.advisor.ChatModelCallAdvisor@33668eae, org.springframework.ai.chat.client.advisor.ChatModelStreamAdvisor@5830fd62], advisorParams={}, adviseContext={spring.ai.chat.client.advisors=[org.springframework.ai.chat.client.advisor.MessageChatMemoryAdvisor@6f20c8da, Line_7_jupyter$CustomLogger@53b8129e, org.springframework.ai.chat.client.advisor.ChatModelCallAdvisor@33668eae, org.springframework.ai.chat.client.advisor.ChatModelStreamAdvisor@5830fd62], spring.ai.chat.client.model=OpenAiChatModel [defaultOptions=OpenAiChatOptions: {\"streamUsage\":false,\"model\":\"gpt-4o-mini\",\"temperature\":0.7}], spring.ai.chat.client.user.params={}, spring.ai.chat.client.system.params={}}, toolContext={}]\n",
      "CustomLogger.After: AdvisedResponse[response=ChatResponse [metadata={ id: chatcmpl-BW5p3rRgS1T9vr91wDI0XoxscPSez, usage: DefaultUsage{promptTokens=92, completionTokens=78, totalTokens=170}, rateLimit: { @type: org.springframework.ai.openai.metadata.OpenAiRateLimit, requestsLimit: 30000, requestsRemaining: 29999, requestsReset: PT0.002S, tokensLimit: 150000000; tokensRemaining: 149999916; tokensReset: PT0S } }, generations=[Generation[assistantMessage=AssistantMessage [messageType=ASSISTANT, toolCalls=[], textContent=Certainly! Hereâ€™s a simple \"Hello, World!\" program written in Kotlin:\n",
      "\n",
      "```kotlin\n",
      "fun main() {\n",
      "    println(\"Hello, World!\")\n",
      "}\n",
      "```\n",
      "\n",
      "To run this code, you can use an IDE like IntelliJ IDEA or an online Kotlin compiler. Just copy and paste this code into the editor, and it will print \"Hello, World!\" to the console., metadata={finishReason=STOP, refusal=, index=0, role=ASSISTANT, id=chatcmpl-BW5p3rRgS1T9vr91wDI0XoxscPSez, messageType=ASSISTANT}], chatGenerationMetadata=DefaultChatGenerationMetadata[finishReason='STOP', filters=0, metadata=0]]]], adviseContext={spring.ai.chat.client.model=OpenAiChatModel [defaultOptions=OpenAiChatOptions: {\"streamUsage\":false,\"model\":\"gpt-4o-mini\",\"temperature\":0.7}], spring.ai.chat.client.advisors=[org.springframework.ai.chat.client.advisor.MessageChatMemoryAdvisor@6f20c8da, Line_7_jupyter$CustomLogger@53b8129e, org.springframework.ai.chat.client.advisor.ChatModelCallAdvisor@33668eae, org.springframework.ai.chat.client.advisor.ChatModelStreamAdvisor@5830fd62], spring.ai.chat.client.user.params={}, spring.ai.chat.client.system.params={}}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Certainly! Hereâ€™s a simple \"Hello, World!\" program written in Kotlin:\n",
       "\n",
       "```kotlin\n",
       "fun main() {\n",
       "    println(\"Hello, World!\")\n",
       "}\n",
       "```\n",
       "\n",
       "To run this code, you can use an IDE like IntelliJ IDEA or an online Kotlin compiler. Just copy and paste this code into the editor, and it will print \"Hello, World!\" to the console."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "name": "kotlin",
   "version": "1.9.23",
   "mimetype": "text/x-kotlin",
   "file_extension": ".kt",
   "pygments_lexer": "kotlin",
   "codemirror_mode": "text/x-kotlin",
   "nbconvert_exporter": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
