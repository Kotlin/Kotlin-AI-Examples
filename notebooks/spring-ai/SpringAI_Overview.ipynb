{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Introduction to Using Spring AI with Kotlin\n",
    "\n",
    "This notebook provides an introductory tutorial on using Spring AI in Kotlin to interact with large language models through an OpenAI example. We'll walk through the process step by step, covering configuration, using prompts, handling streaming responses, obtaining structured data, and utilizing tools.\n",
    "\n",
    "### Setting Up Your Project\n",
    "\n",
    "Ensure that your project includes the necessary Spring AI dependencies:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T22:12:33.587990Z",
     "start_time": "2026-02-19T22:12:33.127752Z"
    },
    "executionRelatedData": {
     "compiledClasses": [
      "Line_3_jupyter"
     ]
    }
   },
   "cell_type": "code",
   "source": [
    "%useLatestDescriptors\n",
    "%use spring-ai-openai"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Provide your OpenAI API key by setting up the `OPENAI_API_KEY` environmental variable. Alternatively, you can copy it here:"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T22:12:33.654465Z",
     "start_time": "2026-02-19T22:12:33.588499Z"
    },
    "executionRelatedData": {
     "compiledClasses": [
      "Line_4_jupyter"
     ]
    }
   },
   "cell_type": "code",
   "source": "val apiKey = System.getenv(\"OPENAI_API_KEY\") ?: \"YOUR_OPENAI_API_KEY\"",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Set up the OpenAI chat model with your API key and configure the desired settings, such as temperature and model type:"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T22:12:34.143584Z",
     "start_time": "2026-02-19T22:12:33.656265Z"
    },
    "executionRelatedData": {
     "compiledClasses": [
      "Line_5_jupyter"
     ]
    }
   },
   "cell_type": "code",
   "source": [
    "val openAiApi = OpenAiApi.builder().apiKey(apiKey).build()\n",
    "val openAiChatOptions = OpenAiChatOptions.builder()\n",
    "    .model(OpenAiApi.ChatModel.GPT_5_CHAT_LATEST)\n",
    "    .temperature(0.7)\n",
    "    .build()\n",
    "val chatModel = OpenAiChatModel.builder().openAiApi(openAiApi).defaultOptions(openAiChatOptions).build()"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Sending Prompts\n",
    "\n",
    "Interact with the API by sending a prompt to the chat model and receiving a response:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T22:12:35.353379Z",
     "start_time": "2026-02-19T22:12:34.144624Z"
    },
    "executionRelatedData": {
     "compiledClasses": [
      "Line_6_jupyter"
     ]
    }
   },
   "cell_type": "code",
   "source": "chatModel.call(\"Generate a hokku about Kotlin\")",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Code flows like a stream,  \n",
       "Soft syntax hums through the night‚Äî  \n",
       "Logic blooms in spring."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Use Spring AI's `ChatClient` to create more complex prompts, such as providing system instructions:"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T22:12:35.416605Z",
     "start_time": "2026-02-19T22:12:35.361585Z"
    },
    "executionRelatedData": {
     "compiledClasses": [
      "Line_7_jupyter"
     ]
    }
   },
   "cell_type": "code",
   "source": [
    "val chatClient = ChatClient.builder(chatModel).defaultSystem(\n",
    "    \"\"\"\n",
    "    You are a Lord of the Rings expert and a trusted advisor.\n",
    "    Offer wise, concise guidance in the style of Middle-earth,\n",
    "    drawing from its lore, characters, and philosophy.\n",
    "    \"\"\".trimIndent()\n",
    ").build()"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now you can send a user-defined prompt to the chat model and retrieve the response content as a `String`:"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T22:12:37.053828Z",
     "start_time": "2026-02-19T22:12:35.417639Z"
    },
    "executionRelatedData": {
     "compiledClasses": [
      "Line_8_jupyter"
     ]
    }
   },
   "cell_type": "code",
   "source": [
    "chatClient\n",
    "    .prompt()\n",
    "    .user(\"What awaits us?\")\n",
    "    .call()\n",
    "    .content()\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Much that is hidden, and much that depends on the road you choose.  \n",
       "As the wise in Rivendell would say, *‚ÄúEven the smallest hand may shape the course of the future.‚Äù*  \n",
       "\n",
       "What awaits is not set in stone‚Äîit changes with courage, with fellowship, and with the choices made in both light and shadow.  \n",
       "Walk with purpose, keep your heart open, and the path will reveal itself when the time is ripe."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Try replacing the `content()` call with `chatResponse()` to gain deeper insight into the response. `ChatResponse` represents the AI model's reply and includes metadata on how it was generated, such as the number of tokens used."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Handling Streaming Responses\n",
    "\n",
    "Using the `stream()` method, you receive partial chunks of the response as soon as they're ready. This approach allows you to avoid waiting for the AI to generate the entire response and enables you to display real-time progress to users."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Include the coroutine dependency to work with the result as a Kotlin `Flow`:"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T22:12:37.200707Z",
     "start_time": "2026-02-19T22:12:37.055834Z"
    },
    "executionRelatedData": {
     "compiledClasses": [
      "Line_9_jupyter",
      "Line_10_jupyter"
     ]
    }
   },
   "cell_type": "code",
   "source": [
    "%useLatestDescriptors\n",
    "%use coroutines\n",
    "@file:DependsOn(\"org.jetbrains.kotlinx:kotlinx-coroutines-reactive:1.10.2\")\n",
    "@file:DependsOn(\"org.jetbrains.kotlinx:kotlinx-coroutines-reactor:1.10.2\")"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In a reactive UI, you can show the incoming response in real time. To keep this example simple, we display each chunk of the response on a separate line (although they are printed simultaneously):"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T22:12:38.544403Z",
     "start_time": "2026-02-19T22:12:37.206252Z"
    },
    "executionRelatedData": {
     "compiledClasses": [
      "Line_11_jupyter"
     ]
    }
   },
   "cell_type": "code",
   "source": [
    "import kotlinx.coroutines.reactive.asFlow\n",
    "\n",
    "val streamingResponse: Flow<String> = chatModel\n",
    "    .stream(\"Generate a hokku about Kotlin\")\n",
    "    .asFlow()\n",
    "\n",
    "runBlocking {\n",
    "    streamingResponse.collect {\n",
    "        print(it)\n",
    "    }\n",
    "}\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swift code dreams in gray,  \n",
      "Kotlin whispers soft and clean‚Äî  \n",
      "Logic hums in spring."
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " Since `collect` is a suspend function, we wrap it inside a `runBlocking` call to use it within a notebook."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Structured Output\n",
    "\n",
    "Spring AI can automatically deserialize responses into Kotlin data classes, making it easy to handle structured outputs.\n",
    "\n",
    "Let's retrieve the response from the LLM about the movie in our desired format:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T22:12:38.622619Z",
     "start_time": "2026-02-19T22:12:38.544953Z"
    },
    "executionRelatedData": {
     "compiledClasses": [
      "Line_12_jupyter"
     ]
    }
   },
   "cell_type": "code",
   "source": [
    "import com.fasterxml.jackson.annotation.JsonCreator\n",
    "import com.fasterxml.jackson.annotation.JsonProperty\n",
    "\n",
    "data class Movie @JsonCreator constructor(\n",
    "    @JsonProperty(\"title\") val title: String,\n",
    "    @JsonProperty(\"year\") val year: Int,\n",
    "    @JsonProperty(\"director\") val director: String,\n",
    "    @JsonProperty(\"genre\") val genre: String\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Specify the `ResponseFormat` as `JSON_OBJECT` to instruct the LLM to return the output strictly in JSON, enabling Spring AI to automatically convert it into a `data` class:"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T22:12:38.661431Z",
     "start_time": "2026-02-19T22:12:38.623180Z"
    },
    "executionRelatedData": {
     "compiledClasses": [
      "Line_13_jupyter"
     ]
    }
   },
   "cell_type": "code",
   "source": [
    "val structuredOutputOptions = OpenAiChatOptions.builder()\n",
    "    .model(OpenAiApi.ChatModel.GPT_5_CHAT_LATEST)\n",
    "    .responseFormat(ResponseFormat.builder().type(ResponseFormat.Type.JSON_OBJECT).build())\n",
    "    .build()\n",
    "val chatModelWithStructuredOutput = OpenAiChatModel.builder().openAiApi(openAiApi).defaultOptions(structuredOutputOptions).build()"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In the following example, OpenAI returns the requested JSON, which is automatically converted into a `Movie`:"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T22:12:39.313598Z",
     "start_time": "2026-02-19T22:12:38.661915Z"
    },
    "executionRelatedData": {
     "compiledClasses": [
      "Line_14_jupyter"
     ]
    }
   },
   "cell_type": "code",
   "source": [
    "ChatClient.create(chatModelWithStructuredOutput)\n",
    "    .prompt()\n",
    "    .user(\"Movie that won the Oscar for Best Picture in 1990\")\n",
    "    .call()\n",
    "    .entity<Movie>()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Movie(title=Dances with Wolves, year=1990, director=Kevin Costner, genre=Western)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "AI models often hallucinate and aren't guaranteed to return correct answers. As a result, they may sometimes fail to produce the structured output as requested, instead returning something different‚Äîsuch as JSON with additional comments. Larger models tend to produce the expected output more consistently. In this example, selecting `GPT_4_O` rather than `GPT_4_O_MINI` yields both the correct movie choice ('Driving Miss Daisy') and properly formatted JSON. For real-life applications, consider implementing a validation mechanism to ensure the model's output matches the desired format."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Using Tools"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Tools allow LLMs to access your custom services in a powerful and flexible way. Let's use tools to work with OpenAI's function-calling feature and implement a weather service query.\n",
    "\n",
    "Without additional tools, the model won't provide information about the current weather, responding instead that it's unable to offer real-time weather updates:\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T22:12:40.621258Z",
     "start_time": "2026-02-19T22:12:39.322205Z"
    },
    "executionRelatedData": {
     "compiledClasses": [
      "Line_15_jupyter"
     ]
    }
   },
   "cell_type": "code",
   "source": "chatModel.call(\"What's the weather like in Paris today?\")",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I don‚Äôt have access to real-time data, including current weather. For the most accurate and up-to-date weather in Paris, I recommend checking a reliable weather service such as **M√©t√©o-France**, **BBC Weather**, or a weather app like **Weather.com** or **AccuWeather**.  \n",
       "\n",
       "If you want, I can tell you what the typical weather in Paris is like around this time of year ‚Äî would you like that?"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's imagine we have a weather service providing weather information for different locations. By using tools, we can give OpenAI access to this service. In this tutorial, we'll use `mockWeatherService` to simulate such a service:"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T22:12:40.714769Z",
     "start_time": "2026-02-19T22:12:40.625372Z"
    },
    "executionRelatedData": {
     "compiledClasses": [
      "Line_16_jupyter"
     ]
    }
   },
   "cell_type": "code",
   "source": [
    "fun mockWeatherService(location: String): Double? = when {\n",
    "    \"Paris\" in location -> 15.0\n",
    "    \"Tokyo\" in location -> 10.0\n",
    "    \"San Francisco\" in location -> 30.0\n",
    "    else -> null\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We need to grant the model access to the weather tool. First, we define a `FunctionTool` named `\"getCurrentWeather\"` with the description `\"Get the current temperature for a given location.\"` It includes one required property, `\"location\"`, of type `string`:"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T22:12:40.753610Z",
     "start_time": "2026-02-19T22:12:40.715234Z"
    },
    "executionRelatedData": {
     "compiledClasses": [
      "Line_17_jupyter"
     ]
    }
   },
   "cell_type": "code",
   "source": [
    "import org.springframework.ai.model.ModelOptionsUtils\n",
    "\n",
    "val functionTool = OpenAiApi.FunctionTool(\n",
    "    OpenAiApi.FunctionTool.Type.FUNCTION,\n",
    "    OpenAiApi.FunctionTool.Function(\n",
    "        \"Get current temperature for a given location.\",\n",
    "        \"getCurrentWeather\", ModelOptionsUtils.jsonToMap(\n",
    "            \"\"\"\n",
    "                {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"location\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"City and country e.g. Bogot√°, Colombia\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"location\"],\n",
    "                    \"additionalProperties\": false\n",
    "                }\n",
    "                \"\"\".trimIndent()\n",
    "        ),\n",
    "        true\n",
    "    )\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now, we send the user's question along with the list of available tools."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T22:12:40.815500Z",
     "start_time": "2026-02-19T22:12:40.756354Z"
    },
    "executionRelatedData": {
     "compiledClasses": [
      "Line_18_jupyter"
     ]
    }
   },
   "cell_type": "code",
   "source": [
    "import org.springframework.ai.openai.api.OpenAiApi.ChatCompletionMessage\n",
    "import org.springframework.ai.openai.api.OpenAiApi.ChatCompletionRequest\n",
    "import org.springframework.ai.openai.api.OpenAiApi.ChatCompletionRequest.ToolChoiceBuilder\n",
    "\n",
    "val initialUserMessage = ChatCompletionMessage(\n",
    "    \"What's the weather like in Paris today?\",\n",
    "    ChatCompletionMessage.Role.USER\n",
    ")\n",
    "val chatCompletionRequest = ChatCompletionRequest(\n",
    "    listOf(initialUserMessage), \"gpt-5.1\",\n",
    "    listOf(functionTool), ToolChoiceBuilder.AUTO\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Depending on the user's question, the model can now return a response containing information about the tools it chooses to use and the arguments required for those tools. If the user asks about the weather, the model selects our weather tool. If the user asks an unrelated question, the model behaves as usual. We can display the entire response to see which tools were chosen:"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T22:12:41.817286Z",
     "start_time": "2026-02-19T22:12:40.816065Z"
    },
    "executionRelatedData": {
     "compiledClasses": [
      "Line_19_jupyter"
     ]
    }
   },
   "cell_type": "code",
   "source": [
    "val chatCompletion = openAiApi.chatCompletionEntity(chatCompletionRequest)\n",
    "val responseFromLLM = chatCompletion.body!!.choices().first().message()\n",
    "responseFromLLM"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage[rawContent=null, role=ASSISTANT, name=null, toolCallId=null, toolCalls=[ToolCall[index=null, id=call_yIZFmh84CTukHABnUj3f6Fif, type=function, function=ChatCompletionFunction[name=getCurrentWeather, arguments={\"location\":\"Paris, France\"}]]], refusal=null, audioOutput=null, annotations=[], reasoningContent=null]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The response specifies the tool the LLM intends to call and its arguments:\n",
    "\n",
    "```function=ChatCompletionFunction[name=getCurrentWeather, arguments={\"location\":\"Paris, France\"}]```"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We invoke the tool and send the result back to the model so that it can generate the final response for the user‚Äîor possibly decide to call other tools based on the conversation."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T22:12:41.907147Z",
     "start_time": "2026-02-19T22:12:41.826321Z"
    },
    "executionRelatedData": {
     "compiledClasses": [
      "Line_20_jupyter"
     ]
    }
   },
   "cell_type": "code",
   "source": [
    "lateinit var messageWithToolInvocation: ChatCompletionMessage\n",
    "for (toolCall in responseFromLLM.toolCalls()) {\n",
    "    when (val functionName = toolCall.function().name()) {\n",
    "        \"getCurrentWeather\" -> {\n",
    "            val location = toolCall.function().arguments()\n",
    "            val temperature = mockWeatherService(location)\n",
    "            messageWithToolInvocation = ChatCompletionMessage(\n",
    "                if (temperature != null) \"$temperature C\" else \"Unable to get the weather\",\n",
    "                ChatCompletionMessage.Role.TOOL,\n",
    "                functionName, toolCall.id(), null, null, null, null, null\n",
    "            )\n",
    "        }\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now, we send all the messages to the LLM to provide the full context: the initial message, the response with the tool choice, and the tool invocation result. With this information, the LLM can now answer the user's initial question about the current weather in Paris:"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T22:12:42.993349Z",
     "start_time": "2026-02-19T22:12:41.907625Z"
    },
    "executionRelatedData": {
     "compiledClasses": [
      "Line_21_jupyter"
     ]
    }
   },
   "cell_type": "code",
   "source": [
    "val messages = mutableListOf(initialUserMessage, responseFromLLM, messageWithToolInvocation)\n",
    "val functionResponseRequest = ChatCompletionRequest(messages, \"gpt-5.1\", 0.2)\n",
    "val resultingCompletion = openAiApi.chatCompletionEntity(functionResponseRequest)\n",
    "resultingCompletion.body!!.choices().first().message().content()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In Paris today it‚Äôs about 15¬∞C, likely cool and mild. You‚Äôll probably want a light jacket if you‚Äôre going out."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The LLM successfully used the provided tool to respond to the user. Enhancing LLMs with external tools can automate tasks such as data retrieval, customer support, and IoT control."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This notebook serves as an overview of how to integrate Spring AI into your Kotlin projects, enabling you to build powerful AI-driven applications. Experiment further with prompts and tailored implementations for your specific needs! üöÄ"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "name": "kotlin",
   "version": "1.9.23",
   "mimetype": "text/x-kotlin",
   "file_extension": ".kt",
   "pygments_lexer": "kotlin",
   "codemirror_mode": "text/x-kotlin",
   "nbconvert_exporter": ""
  },
  "ktnbPluginMetadata": {
   "projectLibraries": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
