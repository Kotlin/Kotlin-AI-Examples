{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-06T22:21:20.852641Z",
     "start_time": "2025-02-06T22:21:20.556155Z"
    }
   },
   "source": [
    "%useLatestDescriptors\n",
    "\n",
    "@file:DependsOn(\"dev.langchain4j:langchain4j:1.0.0-beta1\")\n",
    "@file:DependsOn(\"dev.langchain4j:langchain4j-open-ai:1.0.0-beta1\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T22:23:37.732078Z",
     "start_time": "2025-02-06T22:23:37.643544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val openAiApiKey = System.getenv(\"OPENAI_API_KEY\") ?: \"YOUR-OPENAI-API-KEY\"\n",
    "\n",
    "/**\n",
    " * A function to split text into chunks.\n",
    " * For simplicity, this example splits the text by sentences ('.')\n",
    " * and then re-joins them into chunks if the chunk size is under a limit.\n",
    " */\n",
    "fun splitIntoChunks(text: String, maxTokensPerChunk: Int = 300): List<String> {\n",
    "    // Very simplified approach:\n",
    "    val sentences = text.split(\".\")\n",
    "    val chunks = mutableListOf<String>()\n",
    "    val currentChunk = StringBuilder()\n",
    "\n",
    "    for (sentence in sentences) {\n",
    "        val potentialChunk = if (currentChunk.isEmpty()) sentence else \"${currentChunk.trim()}. $sentence\"\n",
    "        // Here you would estimate token count; for simplicity, we use character length.\n",
    "        // For robust token-based splits, you could integrate a tokenizer class from the library.\n",
    "        if (potentialChunk.length < maxTokensPerChunk) {\n",
    "            if (currentChunk.isNotEmpty()) {\n",
    "                currentChunk.append(\". \")\n",
    "            }\n",
    "            currentChunk.append(sentence)\n",
    "        } else {\n",
    "            // Add the current chunk and start a new one\n",
    "            chunks.add(currentChunk.toString())\n",
    "            currentChunk.clear()\n",
    "            currentChunk.append(sentence)\n",
    "        }\n",
    "    }\n",
    "    // Add the last chunk if it’s not empty\n",
    "    if (currentChunk.isNotEmpty()) {\n",
    "        chunks.add(currentChunk.toString())\n",
    "    }\n",
    "    return chunks\n",
    "}\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T22:23:39.130609Z",
     "start_time": "2025-02-06T22:23:39.049086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dev.langchain4j.data.message.UserMessage.userMessage\n",
    "import dev.langchain4j.model.chat.request.ChatRequest\n",
    "import dev.langchain4j.model.chat.request.chatRequest\n",
    "import dev.langchain4j.model.openai.OpenAiChatModel\n",
    "\n",
    "/**\n",
    " * A pseudo function that sends the prompt to an OpenAI LLM and returns the completion.\n",
    " * In a real scenario, you’d use something like:\n",
    " * OpenAiService.builder()\n",
    " *   .openAiApiKey(openAiApiKey)\n",
    " *   .build()\n",
    " * and then create an LLM chain. This is just a placeholder for demonstration.\n",
    " */\n",
    "fun summarizeChunkWithOpenAI(chunk: String, openAiApiKey: String): String {\n",
    "    val openAi = OpenAiChatModel.builder()\n",
    "        .apiKey(openAiApiKey)\n",
    "        .modelName(\"gpt-4\")\n",
    "        .temperature(0.7)\n",
    "        .build()\n",
    "\n",
    "    val prompt = \"Please summarize the following text:\\n\\n$chunk\"\n",
    "\n",
    "    // Construct a chat request (if you’re using chat models)\n",
    "    val request = chatRequest {\n",
    "        messages += userMessage(prompt)\n",
    "    }\n",
    "\n",
    "    // Send the request to get the actual summary\n",
    "    val response = openAi.chat(request)\n",
    "\n",
    "    // Extract the content from the response\n",
    "    return response.aiMessage().text()\n",
    "}\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T22:23:39.622529Z",
     "start_time": "2025-02-06T22:23:39.537825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "/**\n",
    " * Summarizes a large document by splitting it into chunks, summarizing each chunk,\n",
    " * and combining the results.\n",
    " */\n",
    "fun summarizeDocument(\n",
    "    text: String,\n",
    "    detail: Double = 0.0,\n",
    "    maxTokensPerChunk: Int = 500\n",
    "): String {\n",
    "    require(detail in 0.0..1.0) { \"Detail must be between 0.0 and 1.0\" }\n",
    "\n",
    "    // Split the text into an initial set of chunks\n",
    "    val initialChunks = splitIntoChunks(text, maxTokensPerChunk)\n",
    "    // Interpolate number of chunks based on the detail desired\n",
    "    val maxChunks = initialChunks.size\n",
    "    val minChunks = 1\n",
    "    val targetChunksCount = (minChunks + detail * (maxChunks - minChunks)).toInt().coerceAtLeast(1)\n",
    "\n",
    "    // Recalculate chunk size to approximate the target number of chunks\n",
    "    // (For a real application, you might do more advanced splitting)\n",
    "    val totalLength = text.length\n",
    "    val adjustedChunkSize = (totalLength / targetChunksCount).coerceAtLeast(200)\n",
    "    val finalChunks = splitIntoChunks(text, adjustedChunkSize)\n",
    "\n",
    "    // Summarize each chunk individually\n",
    "    val chunkSummaries = finalChunks.map { chunk ->\n",
    "        summarizeChunkWithOpenAI(chunk, openAiApiKey)\n",
    "    }\n",
    "\n",
    "    // Combine all chunk summaries into a final summary\n",
    "    return chunkSummaries.joinToString(separator = \"\\n\\n\")\n",
    "}\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T22:23:40.252392Z",
     "start_time": "2025-02-06T22:23:40.221984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import java.io.File\n",
    "\n",
    "val artificialIntelligenceWikipediaText = File(\"data/artificial_intelligence_wikipedia.txt\").readText(Charsets.UTF_8)\n"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T22:38:16.233483Z",
     "start_time": "2025-02-06T22:26:01.380505Z"
    }
   },
   "cell_type": "code",
   "source": "val summaryDetail1 = summarizeDocument(artificialIntelligenceWikipediaText, detail = 1.0)\n",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T22:39:33.662187Z",
     "start_time": "2025-02-06T22:39:33.592313Z"
    }
   },
   "cell_type": "code",
   "source": "println(\"Summary with detail=1.0:\\n$summaryDetail1\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary with detail=1.0:\n",
      "Artificial intelligence (AI) refers to the intelligence displayed by machines, specifically computer systems. It's a field of computer science research that focuses on creating and studying methods and software that allow machines to understand their environment. These machines use learning and intelligence to perform actions that increase their likelihood of reaching set objectives.\n",
      "\n",
      ", Google's self-driving cars); and scientific research. AI, or artificial intelligence, refers to machines that are capable of performing tasks that normally require human intelligence. These machines, also known as AIs, are utilized in various sectors including industry, government, and science. Their applications range from advanced web search engines like Google Search, to recommendation systems used by YouTube, Amazon, and Netflix, to speech interaction systems like Google Assistant, Siri, and Alexa, to autonomous vehicles like Google's self-driving cars.\n",
      "\n",
      "The text discusses the various applications of Artificial Intelligence (AI), including autonomous vehicles, generative tools, and game analysis. However, the text also points out that many AI applications are not recognized as such because once they become commonplace and useful, they are no longer labeled as AI.\n",
      "\n",
      "Alan Turing is credited as the pioneer of substantial research in machine intelligence, which later became known as artificial intelligence (AI). The academic discipline of AI was established in 1956. The field has experienced several cycles of optimism and disappointment, resulting in varying levels of funding. The periods of reduced funding are referred to as AI winters.\n",
      "\n",
      "The funding and interest in artificial intelligence (AI) greatly increased after 2012 when deep learning outperformed all other AI techniques. This surge was further propelled after 2017 with the advent of the transformer architecture. Consequently, the early 2020s saw an AI boom, with companies, universities, and laboratories primarily based in the United States leading substantial advancements in the field.\n",
      "\n",
      "The rise of artificial intelligence (AI) in the 21st century is leading to a societal and economic shift towards more automation and data-driven decision-making. The integration of AI into different economic sectors is affecting job markets, healthcare, government, industry, and education.\n",
      "\n",
      "This text highlights concerns about the long-term impacts, ethics, and risks of artificial intelligence (AI), leading to talks about regulatory policies for its safe and beneficial use. It also notes that different sub-fields of AI research focus on specific goals and tools.\n",
      "\n",
      "Traditional AI research focuses on areas such as reasoning, knowledge representation, planning, learning, natural language processing, perception, and robotics support. One of the long-term objectives is to develop general intelligence, which is the capability to perform any human task at an equal or higher level.\n",
      "\n",
      "AI researchers utilize various techniques to achieve their objectives, such as search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also incorporates knowledge from psychology, linguistics, philosophy, neuroscience, and other disciplines.\n",
      "\n",
      "The overall goal of simulating or creating intelligence has been divided into sub-problems, which are specific traits or capabilities that an intelligent system is expected to exhibit. These traits have been the main focus of AI research.\n",
      "\n",
      "The text discusses the development of algorithms in the field of reasoning and problem-solving. Early researchers created algorithms that mimicked the step-by-step logical deductions humans use to solve puzzles. By the late '80s and '90s, methods were developed to handle uncertain or incomplete information, using concepts from probability and economics.\n",
      "\n",
      "Many existing algorithms struggle to solve large reasoning problems due to a \"combinatorial explosion\", causing them to become exponentially slower as problems increase in size. Additionally, humans often use quick, intuitive judgments to solve problems, rather than the detailed step-by-step deduction that early AI research could replicate.\n",
      "\n",
      "The text discusses the unsolved problem of accurate and efficient reasoning. It explains that an ontology, in terms of knowledge representation, represents knowledge as a set of concepts within a domain and the relationships between those concepts. Knowledge representation and knowledge engineering enable AI programs to intelligently answer questions and make deductions about real-world facts.\n",
      "\n",
      "Formal knowledge representations are used in multiple areas such as content-based indexing, scene interpretation, clinical decision support, and knowledge discovery. A knowledge base is a body of knowledge that is represented in a form that can be utilized by a program.\n",
      "\n",
      "An ontology refers to the collection of objects, relationships, concepts, and properties utilized by a specific knowledge domain.\n",
      "\n",
      "\n",
      "Knowledge bases require representations of various aspects including objects, properties, categories, and relations between objects, situations, events, states, time, causes and effects, and knowledge about knowledge. They also need to account for default reasoning, which refers to human assumptions that remain true despite changes in other facts, as well as numerous other domains and aspects of knowledge.\n",
      "\n",
      "The text discusses the challenges in knowledge representation, focusing on two main issues. The first is the vastness of common sense knowledge that an average person possesses. The second is the sub-symbolic nature of most common sense knowledge, which means a significant portion of what people know isn't conveyed as verbal facts or statements.\n",
      "\n",
      "The text discusses challenges in artificial intelligence (AI), specifically the difficulty of knowledge acquisition for AI applications. It explains the concept of a \"rational agent\", which is something that perceives and takes actions in the world, with specific goals or preferences. In automated planning, this rational agent has a specific goal to achieve.\n",
      "\n",
      "In automated decision making, the agent assigns a utility number to each situation based on its preferences. This number indicates how much the agent prefers the situation, helping it to seek out preferred situations and avoid those it does not want.\n",
      "\n",
      "The text describes a decision-making process where an action is chosen based on its \"expected utility,\" which is the anticipated value of all possible outcomes, each weighted by their likelihood of occurrence. This is common in classical planning, where the agent is fully aware of the potential effects of any given action.\n",
      "\n",
      "In real-world scenarios, the agent often faces uncertainty about its current situation and the outcome of its possible actions. Therefore, the agent must make a decision based on a probabilistic guess and then reevaluate the situation to determine the effectiveness of the action taken.\n",
      "\n",
      "The text discusses how an agent's preferences can sometimes be unclear, particularly when other agents or humans are involved. These preferences can be learned, for example, through inverse reinforcement learning, or the agent can seek additional information to refine its preferences. The text also mentions the use of information value theory to assess the worth of exploratory or experimental actions.\n",
      "\n",
      "The text discusses the complexity of predicting future actions and situations, which is usually overwhelming. Therefore, agents are required to make decisions and assess situations despite the uncertainty of the outcomes.\n",
      "\n",
      "A Markov decision process has a transition model to predict the likelihood of a state change due to a particular action, and a reward function to provide the utility of each state and action cost. A policy, which can be computed, heuristic, or learned, links a decision to each possible state.\n",
      "\n",
      "Game theory is used in AI programs to describe the rational behavior of interacting agents. Machine learning, which has always been a part of AI, is the study of programs that can automatically enhance their performance on a specific task. There are multiple types of machine learning.\n",
      "\n",
      "Unsupervised learning is a type of machine learning that identifies patterns and makes predictions from data without any guidance. On the other hand, supervised learning needs human-labeled data and comes in two types: classification, where the software predicts which category the input falls into, and regression, where it determines a numeric function from numerical input.\n",
      "\n",
      "Reinforcement learning involves an agent being rewarded for positive responses and penalized for negative ones, thus learning to choose \"good\" responses. Transfer learning, on the other hand, is the application of knowledge acquired from one issue to a new problem.\n",
      "\n",
      "Deep learning is a form of machine learning that utilizes artificial neural networks inspired by biological processes to carry out various types of learning. Computational learning theory evaluates learners based on computational complexity, sample complexity (the amount of data needed), and other optimization concepts.\n",
      "\n",
      "Natural language processing (NLP) is a technology that enables programs to interact in human languages like English. It tackles issues such as speech recognition and synthesis, machine translation, information retrieval and extraction, and question answering.\n",
      "\n",
      "Initial research, influenced by Noam Chomsky's generative grammar and semantic networks, struggled with word-sense disambiguation unless it was limited to narrow fields known as \"micro-worlds\". This was primarily due to the issue of common sense knowledge.\n",
      "\n",
      "Margaret Masterman argued that the comprehension of languages relies more on understanding meaning rather than grammar. She suggested that thesauri should be the foundation of computational language structure, rather than dictionaries.\n",
      "\n",
      "The text describes modern deep learning techniques used in Natural Language Processing (NLP). These include word embedding, which represents words as vectors to encode their meaning, and transformers, a deep learning architecture that uses an attention mechanism.\n",
      "\n",
      "In 2019, generative pre-trained transformer (GPT) language models began producing coherent text. By 2023, these models had advanced to the point where they could achieve human-level scores on various examinations and tests such as the bar exam, SAT test, GRE test, amongst other real-world applications.\n",
      "\n",
      "Machine perception is the ability of a machine to interpret the world using sensor input such as cameras, microphones, wireless signals, lidar, sonar, radar, and tactile sensors. This includes computer vision, which is the analysis of visual input. The field encompasses speech recognition, image classification, facial recognition, object recognition, and robotic perception.\n",
      "\n",
      "Social intelligence refers to systems like Kismet, a robot head developed in the 1990s, that can recognize and mimic human emotions. This falls under the field of affective computing, an interdisciplinary area that includes systems capable of recognizing, interpreting, processing, or simulating human feelings, emotions, and moods.\n",
      "\n",
      "The text explains that some virtual assistants are designed to interact conversationally or humorously to make them seem more emotionally in tune with human interaction and to enhance human-computer interaction. However, this may lead less experienced users to overestimate the intelligence of current computer agents.\n",
      "\n",
      "The text discusses moderate successes in affective computing, such as textual sentiment analysis and multimodal sentiment analysis. This latter approach allows AI to classify emotions shown by a subject in a video. The text also mentions artificial general intelligence, suggesting that a machine with such intelligence should be able to solve a diverse range of problems in a manner similar to human intelligence.\n",
      "\n",
      "AI research employs numerous techniques to achieve its objectives, including search and optimization. AI can resolve many issues by smartly searching through numerous potential solutions. Two distinct types of search used in AI are state space search and local search.\n",
      "\n",
      "State space search involves scanning through a tree of potential states to identify a specific goal state. This method is used in planning algorithms where a path to a desired goal is sought by exploring trees of goals and subgoals, a process known as means-ends analysis.\n",
      "\n",
      "Exhaustive searches often fall short in solving real-world problems due to the vast search space, resulting in slow or incomplete searches. Utilizing heuristics or rules of thumb can aid in prioritizing choices that are more likely to achieve the desired goal.\n",
      "\n",
      "Adversarial search is a technique used by game-playing programs like chess or Go. It involves searching through a tree of possible moves and counter-moves to find a winning position. Local search, represented by the illustration of gradient descent, involves adjusting two parameters, represented by the plan coordinates, in order to minimize the loss function or the height.\n",
      "\n",
      "Local search is a process that uses mathematical optimization to solve a problem, starting with a guess that is refined over time. One type of local search is gradient descent, which optimizes numerical parameters by making incremental adjustments to minimize a loss function. This method is often used to train neural networks.\n",
      "\n",
      "The text describes two types of local search methods. Evolutionary computation aims to continually enhance a set of potential solutions via mutation and recombination, only allowing the most suitable to persist. Distributed search processes can be coordinated through the use of swarm intelligence algorithms.\n",
      "\n",
      "The text describes two popular swarm algorithms used in search: particle swarm optimization, which is inspired by bird flocking, and ant colony optimization, which is inspired by ant trails. It also mentions that formal logic is used for reasoning and knowledge representation.\n",
      "\n",
      "The text discusses two main forms of formal logic: propositional logic and predicate logic. Propositional logic works with statements that are true or false and employs logical connectives like \"and\", \"or\", \"not\", and \"implies\". Predicate logic, on the other hand, operates on objects, predicates, and relations, using quantifiers such as \"Every X is a Y\" and \"There are some Xs that are Ys\".\n",
      "\n",
      "Deductive reasoning in logic involves validating a new statement (conclusion) based on other statements that are considered true (the premises). This can be visualized through proof trees where nodes represent sentences and the connection between parent and child nodes demonstrate inference rules.\n",
      "\n",
      "Problem-solving involves looking for a proof tree where the root node is the problem's solution and the leaf nodes are premises or axioms. In the context of Horn clauses, problem-solving can be done by reasoning forwards from the premises or backwards from the problem.\n",
      "\n",
      "The text discusses the concept of resolution in first-order logic, explaining that it is a singular, axiom-free rule of inference used to solve problems by proving a contradiction from premises including the problem's negation. It also states that inference in both Horn clause logic and first-order logic is undecidable and intractable.\n",
      "\n",
      "Backward reasoning with Horn clauses, a fundamental aspect of the logic programming language Prolog, is Turing complete, implying it has the ability to solve any computational problem. Its efficiency rivals that of other symbolic programming languages. On the other hand, fuzzy logic, which assigns a \"degree of truth\" between 0 and 1, can manage propositions that are vague and only partially true.\n",
      "\n",
      "Non-monotonic logics, which encompass logic programming with negation as failure, are intended for managing default reasoning. There are also other specialized versions of logic that are created to delineate numerous complex domains.\n",
      "\n",
      "The text discusses the use of probabilistic methods in Artificial Intelligence (AI) for uncertain reasoning. These methods, derived from probability theory and economics, are used to solve problems in various areas of AI such as reasoning, planning, learning, perception, and robotics, especially when the agent has incomplete or uncertain information. The text also mentions the use of simple Bayesian networks and associated conditional probability tables.\n",
      "\n",
      "The text discusses the development of precise mathematical tools to analyze how an agent can make choices and plan. These tools use decision theory, decision analysis, and information value theory. They include models such as Markov decision processes, dynamic decision networks, game theory, and mechanism design.\n",
      "\n",
      "Bayesian networks are a versatile tool utilized in various areas including reasoning through the Bayesian inference algorithm, learning through the expectation-maximization algorithm, planning through decision networks, and perception through dynamic Bayesian networks.\n",
      "\n",
      "Probabilistic algorithms are useful in filtering, predicting, smoothing and interpreting streams of data. They assist perception systems in analyzing processes that take place over time, such as hidden Markov models or Kalman filters.\n",
      "\n",
      "The text discusses how expectation-maximization clustering can accurately analyze Old Faithful eruption data after starting with a random guess. It also mentions that the simplest AI applications can be categorized into two types: classifiers, which categorize data based on certain characteristics, and controllers.\n",
      "\n",
      "The text discusses classifiers, which are functions that use pattern matching to determine the closest match. These classifiers can be refined using supervised learning based on chosen examples. Each pattern, also known as an observation, is associated with a predefined class. The combination of all observations and their respective class labels forms a data set.\n",
      "\n",
      "The text discusses the process of classifying new observations based on previous experiences. It mentions that there are various types of classifiers used for this purpose, with the decision tree being the simplest and most commonly used machine learning algorithm.\n",
      "\n",
      "The K-nearest neighbor algorithm was the most popular analogical AI until the mid-1990s, when it was replaced by Kernel methods like the support vector machine (SVM). The naive Bayes classifier is the \"most widely used learner\" at Google because of its scalability. Neural networks are also used as classifiers.\n",
      "\n",
      "An artificial neural network is a system of interconnected nodes, or artificial neurons, that are designed to loosely resemble the neurons in a biological brain. This network is trained to recognize specific patterns, and once trained, it can identify these patterns in new data.\n",
      "\n",
      "A deep neural network consists of an input, at least two hidden layers of nodes, and an output. Each node applies a function and transmits the data to the next layer once its weight crosses a specified threshold.\n",
      "\n",
      "Neural network learning algorithms utilize local search to select appropriate weights for correct output during training, with the backpropagation algorithm being the most commonly used technique. Neural networks can learn to model complex relationships between inputs and outputs and discover patterns in data. Hypothetically, they can learn any function.\n",
      "\n",
      "Feedforward neural networks pass signals in one direction only. Recurrent neural networks, on the other hand, feed the output signal back into the input, allowing for short-term memory of previous inputs. The most successful architecture for recurrent networks is long short term memory. Perceptrons use a single layer of neurons, while deep learning employs multiple layers.\n",
      "\n",
      "Convolutional neural networks enhance the link between neurons that are in close proximity, which is crucial in image processing. Here, a local group of neurons needs to identify an edge before the entire network can recognize an object. On the other hand, deep learning uses multiple layers of neurons between the inputs and outputs of the network.\n",
      "\n",
      "The text explains the functionality of multiple layers in data processing, particularly in image processing. Lower layers identify basic features like edges, while higher layers identify more complex concepts relevant to human understanding, such as digits, letters, or faces.\n",
      "\n",
      "Deep learning has significantly enhanced the performance of programs in several key areas of artificial intelligence, such as computer vision, speech recognition, natural language processing, and image classification. However, the exact reason for deep learning's high performance in these applications remains unknown as of 2023.\n",
      "\n",
      "The sudden success of deep learning between 2012 and 2015 wasn't due to a new discovery or theoretical breakthrough, as deep neural networks and backpropagation had been described since the 1950s. Instead, it was due to two factors: a significant increase in computer power, particularly the hundred-fold speed increase from switching to GPUs, and the availability of large amounts of training data, including huge curated datasets like ImageNet used for benchmark testing.\n",
      "\n",
      "Generative pre-trained transformers (GPT) are large language models used for natural language processing, focusing on semantic relationships between words in sentences. These models are pre-trained using a large amount of text, often sourced from the internet, with pre-training involving the prediction of the next token, which might be a word, subword, or punctuation.\n",
      "\n",
      "During pre-training, GPT models gather world knowledge and can create human-like text by predicting the next token. A following training stage, typically using a method known as reinforcement learning from human feedback (RLHF), further enhances the model's accuracy, usefulness, and safety.\n",
      "\n",
      "Current GPT models, used in chatbots, still have a tendency to generate false information known as \"hallucinations\". However, this can be mitigated with RLHF and high-quality data. Current models and services include Gemini (formerly Bard), ChatGPT, Grok, Claude, Copilot, and LLaMA.\n",
      "\n",
      "Multimodal GPT models are capable of processing various types of data, including images, videos, sound, and text.\n",
      "\n",
      "In the late 2010s, graphics processing units (GPUs) enhanced with AI-specific features and used with specialized TensorFlow software became the main method for training large-scale machine learning models, replacing the previously used central processing units (CPUs). This development is significant in both commercial and academic settings.\n",
      "\n",
      "The text talks about the historical usage of specialized languages like Lisp, Prolog, Python and others.\n",
      "\n",
      "Artificial Intelligence (AI) and machine learning technologies are widely used in many essential applications in the 2020s. These include search engines like Google Search, online ad targeting, recommendation systems used by platforms like Netflix, YouTube, and Amazon, driving internet traffic, targeted advertising like AdSense and Facebook, virtual assistants like Siri and Alexa, autonomous vehicles including drones and self-driving cars, automatic language translation tools like Microsoft Translator and Google Translate, facial recognition technologies like Apple's Face ID, Microsoft's DeepFace and Google's FaceNet, and image labeling used by Facebook, Apple's iPhoto, and TikTok.\n",
      "\n",
      "The use of artificial intelligence (AI) in medicine and medical research can improve patient care and quality of life. From an ethical perspective, medical professionals are obligated to use AI if it can provide more accurate diagnoses and treatments for patients.\n",
      "\n",
      "AI is a crucial tool in medical research for processing and integrating large amounts of data. This is especially vital in the fields of organoid and tissue engineering development, where microscopy imaging is a key technique. AI can also potentially address imbalances in funding allocation across different research areas.\n",
      "\n",
      "New AI tools are enhancing our knowledge of biomedically relevant pathways. For instance, AlphaFold 2 (2021) showed the capacity to estimate the 3D structure of a protein in hours, not months. Moreover, in 2023, AI-guided drug discovery contributed to the identification of a new class of antibiotics that can eliminate two types of drug-resistant bacteria.\n",
      "\n",
      "The text discusses the use of game playing programs in demonstrating and testing AI techniques since the 1950s. It highlights the achievement of Deep Blue, which was the first computer chess-playing system to defeat a reigning world chess champion, Garry Kasparov, on 11 May 1997.\n",
      "\n",
      "In 2011, IBM's question answering system, Watson, won a Jeopardy! exhibition match against the show's top champions, Brad Rutter and Ken Jennings. Then, in March 2016, AlphaGo, a computer Go-playing system, became the first of its kind to defeat a professional Go player, Lee Sedol, without any handicaps, winning 4 out of 5 games.\n",
      "\n",
      "In 2017, an AI program defeated Ke Jie, the world's best Go player. Other programs like Pluribus have been developed to play imperfect-information games like poker. DeepMind has also developed more general reinforcement learning models like MuZero, which can be trained to play various games like chess, Go, or Atari games.\n",
      "\n",
      "In 2019, DeepMind's AI program, AlphaStar, achieved grandmaster level in the complex real-time strategy game StarCraft II. Then in 2021, an AI agent competed in a PlayStation Gran Turismo competition and won against four of the world's top drivers using deep reinforcement learning.\n",
      "\n",
      "Different countries are using AI in military applications to improve command and control, communication, sensors, integration and interoperability. The research focuses on intelligence collection and analysis, logistics, cyber operations, information operations, and semi-autonomous and autonomous vehicles.\n",
      "\n",
      "AI technologies facilitate sensor and effector coordination, threat detection and identification, enemy position marking, target acquisition, and coordination of Joint Fires between manned and unmanned combat vehicles. AI has also been integrated into military operations in Iraq and Syria.\n",
      "\n",
      "In November 2023, US Vice President Kamala Harris announced a declaration signed by 31 countries to regulate the military use of Artificial Intelligence (AI). The commitments include legal reviews to ensure military AI complies with international laws, and a promise to be cautious and transparent in the development of such technology.\n",
      "\n",
      "Generative AI grew in popularity in the early 2020s. As of March 2023, 58% of US adults were aware of ChatGPT, a generative AI software, and 14% had used it.\n",
      "\n",
      "AI-based text-to-image generators like Midjourney, DALL-E, and Stable Diffusion are becoming increasingly realistic and easy to use, leading to a trend of viral AI-generated photos. These include a fake photo of Pope Francis in a white puffer coat, a fictional arrest of Donald Trump, and a hoax attack on the Pentagon. They have also been used in professional creative arts.\n",
      "\n",
      "The text discusses the widespread application of AI across various industries. Thousands of successful AI applications are used to address industry-specific challenges. A 2017 survey revealed that 20% of companies incorporated AI in their offerings or processes.\n",
      "\n",
      "The text provides examples of areas where artificial intelligence (AI) is used, such as energy storage, medical diagnosis, military logistics, predicting judicial decisions, foreign policy, and supply chain management. In agriculture, AI aids in identifying areas needing irrigation, fertilization, pesticide treatments, or yield increase, and agronomists use AI in research and development.\n",
      "\n",
      "The text discusses various uses of Artificial Intelligence (AI) in agriculture. These include predicting crop ripening times, monitoring soil moisture, operating agricultural robots, conducting predictive analytics, classifying livestock emotions, automating greenhouses, detecting diseases and pests, and conserving water.\n",
      "\n",
      "Artificial intelligence is utilized in the field of astronomy to process and analyze large volumes of data. Its applications are mainly for classification, regression, clustering, forecasting, generation, discovery, and developing new scientific insights. Examples of its use include discovering exoplanets, predicting solar activity, and differentiating between signals and instrumental effects in gravitational wave astronomy.\n",
      "\n",
      "The text discusses the potential uses of artificial intelligence (AI) in space activities, including space exploration, data analysis from space missions, real-time decisions of spacecraft, space debris avoidance, and more autonomous operations. It also mentions that AI has both potential benefits and risks, hinting at ethical considerations.\n",
      "\n",
      "AI has the potential to significantly advance science and solve serious problems, according to Demis Hassabis of Deep Mind, whose goal is to \"solve intelligence\" and apply it to other solutions. Despite this, the widespread use of AI has led to the identification of several unintended consequences and risks.\n",
      "\n",
      "The text discusses some issues related to AI training processes. It mentions that in-production systems may not always consider ethics and bias during their training, particularly when the AI algorithms used are complex and unexplainable like in deep learning. The text also touches upon the topics of privacy and copyright, suggesting that machine-learning algorithms require a significant amount of data.\n",
      "\n",
      "The methods used to gather data such as online activity, geolocation, video, and audio by technology companies have sparked worries over privacy, surveillance, and copyright issues.\n",
      "\n",
      "Amazon has recorded millions of private conversations for building speech recognition algorithms and has allowed temporary workers to transcribe some of these. The practice has sparked differing opinions, with some viewing it as a necessary evil and others considering it unethical and an infringement of privacy rights.\n",
      "\n",
      "AI developers believe that valuable applications can only be delivered by obtaining necessary data while maintaining privacy. They use various techniques like data aggregation, de-identification, and differential privacy for this purpose. Since 2016, privacy experts like Cynthia Dwork have started considering privacy in terms of fairness.\n",
      "\n",
      "Brian Christian discusses a shift in focus among experts from what artificial intelligence (AI) knows to what it does with that knowledge. Generative AI, which is often trained using unlicensed copyrighted materials like images or code, uses the produced output under the idea of \"fair use\".\n",
      "\n",
      "Website owners can prevent their copyrighted content from being AI-indexed or 'scraped' by adding specific code to their site. Services like OpenAI offer this feature to those who do not want their websites to be indexed by search engines.\n",
      "\n",
      "Experts have differing opinions on the application and effectiveness of copyright law in cases involving the use of copyrighted material to train generative AI. Factors that could influence court decisions include the purpose and nature of the copyrighted work's use, and its impact on the potential market for the work. This debate was brought to the forefront in 2023 when renowned authors such as John Grisham and Jonathan Franzen sued AI companies for using their work in AI training.\n",
      "\n",
      "YouTube, Facebook, and other platforms use AI recommender systems to guide users towards more content. The main goal of these AI programs is to maximize user engagement, aiming to keep people watching.\n",
      "\n",
      "The AI system learned that users often selected misinformation, conspiracy theories, and highly partisan content. To maintain users' engagement, it recommended more of such content. It also observed that users typically viewed more content on the same topic, leading the AI to create filter bubbles, where users were exposed to various versions of the same misinformation.\n",
      "\n",
      "The text discusses the negative effects of misinformation spread by an AI program, which successfully achieved its goal but inadvertently damaged societal trust in institutions, media, and the government. This was particularly evident after the 2016 U.S. election, prompting major tech companies to take measures to address the issue.\n",
      "\n",
      "In 2022, generative AI started producing images, audio, video and text that mirror real-life counterparts, raising concerns about potential misuse by malicious entities to spread misinformation or propaganda.\n",
      "\n",
      "AI pioneer Geoffrey Hinton warned about the risk of AI being used by authoritarian leaders to manipulate their electorates. He also highlighted issues of algorithmic bias, explaining that machine learning applications can be biased if they are trained with biased data, even if developers are unaware of the bias.\n",
      "\n",
      "The text discusses how bias can be introduced in machine learning due to the selection of training data and the deployment of models. If biased algorithms are used in fields like medicine, finance, recruitment, housing, or policing, they can cause discrimination and harm. Therefore, fairness in machine learning involves studying ways to prevent such harm caused by algorithmic bias.\n",
      "\n",
      "The issue of fairness in AI has become a significant area of academic study, as researchers have found it challenging to define \"fairness\" that satisfies everyone. An example of this is a 2015 incident where Google Photos's image labeling feature incorrectly labeled Jacky Alcine and a friend as \"gorillas\" due to their skin color.\n",
      "\n",
      "The system was trained with a dataset that had a lack of images of black people, a problem known as \"sample size disparity\". Google addressed this by stopping the system from labeling anything as a \"gorilla\". However, in 2023, Google Photos and similar products from Apple, Facebook, Microsoft, and Amazon still couldn't identify a gorilla.\n",
      "\n",
      "COMPAS, a program used by U.S courts to predict the likelihood of a defendant reoffending, was found to exhibit racial bias in 2016 by Julia Angwin at ProPublica. This occurred even though the program was not provided with the races of the defendants.\n",
      "\n",
      "The text discusses an error rate in a system that was equally set at 61% for both white and black individuals. However, the nature of these errors varied by race, with the system regularly overestimating the likelihood of black individuals re-offending, while simultaneously underestimating the probability of white individuals not re-offending.\n",
      "\n",
      "In 2017, researchers revealed that the COMPAS program could not achieve complete fairness due to differing re-offense rates among white and black individuals in the data. This shows that a program can still make biased decisions even if it doesn't explicitly consider problematic features like race or gender.\n",
      "\n",
      "The feature in a program will associate with other features such as address, shopping history, or first name, and make decisions based on these features as it would on race or gender. However, Moritz Hardt argues that achieving fairness through ignoring these sensitive features doesn't work.\n",
      "\n",
      "The critique of COMPAS, a machine learning model, suggests that these models make predictions based on the assumption that future scenarios will mirror past ones. If these models are trained using data that includes past racist decisions, they will predict future occurrences of racist decisions.\n",
      "\n",
      "The text suggests that machine learning, which makes predictions based on past data, might generate biased or discriminatory recommendations if such biases exist in the historical data. It implies that machine learning is not ideal for areas where there's hope for improvement or change in future, as it is descriptive of the past, not prescriptive for the future.\n",
      "\n",
      "The text suggests that bias and unfairness in AI development might go unnoticed due to the lack of diversity among AI engineers, with only 4% being black and 20% being women, implying a predominance of white, male developers.\n",
      "\n",
      "\n",
      "At the 2022 Conference on Fairness, Accountability, and Transparency, the Association for Computing Machinery in Seoul, South Korea, recommended that the use of AI and robotics systems should be limited until they are proven to be free of bias mistakes. The association also suggested that the use of self-learning neural networks trained on large, unregulated sources of flawed internet data should be curtailed.\n",
      "\n",
      "The text discusses the issue of lack of transparency in artificial intelligence (AI) systems. Many of these systems, especially those using deep neural networks, are so intricate that even their creators cannot fully explain the process used to reach decisions. This complexity is due to the numerous non-linear relationships between inputs and outputs.\n",
      "\n",
      "The text discusses the importance of understanding how a machine learning program operates to ensure its correctness. It mentions that there have been instances where programs passed tests but still learned differently than what was intended. Some popular techniques for explainability exist that can help understand these programs better.\n",
      "\n",
      "A system designed to identify skin diseases was discovered to often misclassify images with a ruler as \"cancerous\". This occurred because typical images of malignancies include a ruler for scale, causing the system to associate rulers with cancerous skin conditions.\n",
      "\n",
      "A machine learning system designed to allocate medical resources inaccurately classified asthma patients as \"low risk\" for pneumonia-related death. This is due to the training data, which showed asthma patients receiving more medical care and therefore being less likely to die, despite asthma being a severe risk factor for pneumonia.\n",
      "\n",
      "The text highlights the correlation between asthma and a lower risk of dying from pneumonia, however, it asserts this correlation may be misleading. It also emphasizes that individuals negatively impacted by an algorithm's decision are entitled to an explanation. This is compared to doctors, who are expected to thoroughly explain their decision-making processes to their peers.\n",
      "\n",
      "Early drafts of the European Union's General Data Protection Regulation in 2016 acknowledged the existence of a certain right, but industry experts pointed out that it's a problem without a solution. Despite this, regulators insisted that the issue is a real harm and if there's no solution, the tools causing the problem should not be used.\n",
      "\n",
      "DARPA established the Explainable Artificial Intelligence (XAI) program in 2014 to address issues related to transparency in AI. Potential solutions include SHAP, which visualizes the contribution of each feature to the output, and LIME, which approximates a model locally with a simpler, more interpretable model.\n",
      "\n",
      "Multitask learning offers several outputs beyond the target classification, aiding developers in understanding what the network has learned. Techniques like Deconvolution, DeepDream, and other generative methods aid developers in visualizing the learnings of different layers of a deep network and infer what the network is learning.\n",
      "\n",
      "The text discusses the dangers of artificial intelligence (AI) in the wrong hands. Authoritarian governments, terrorists, criminals, or rogue states could use AI as a tool for harmful activities. A lethal autonomous weapon, for instance, is an AI machine that can locate, select, and target humans without any human supervision.\n",
      "\n",
      "The text warns about the misuse of widely available AI tools by malicious entities to develop inexpensive autonomous weapons. If mass-produced, these could potentially become weapons of mass destruction. Furthermore, their use in conventional warfare raises concerns about their ability to reliably choose targets, raising the risk of innocent casualties.\n",
      "\n",
      "In 2014, 30 countries, including China, backed a ban on autonomous weapons under the United Nations' Convention on Certain Conventional Weapons, but the US and others disagreed. As of 2015, over 50 countries were reportedly researching battlefield robots. AI tools offer authoritarian governments a more efficient way to control their citizens.\n",
      "\n",
      "The text discusses how advanced technologies like face and voice recognition can enable widespread surveillance, with machine learning classifying potential state enemies to prevent them from hiding. It also mentions how recommendation systems can be used to effectively target propaganda and misinformation, and how deepfakes and generative AI can help in creating such misinformation.\n",
      "\n",
      "Advanced AI technology can potentially make centralized decision-making in authoritarian regimes more competitive than liberal, decentralized systems. It reduces the cost and challenges of digital warfare and sophisticated spyware. Available since 2020 or earlier, AI technologies like facial recognition systems are already employed for mass surveillance purposes in countries like China.\n",
      "\n",
      "AI is expected to aid bad actors in various unforeseen ways, such as machine-learning AI designing toxic molecules rapidly. Training AI systems requires huge computing power, typically only affordable by big tech companies.\n",
      "\n",
      "Smaller startups like Cohere and OpenAI purchase access to data centers from tech giants Google and Microsoft. Meanwhile, economists express concern about the risk of job losses due to artificial intelligence (AI), speculating that it could lead to unemployment if there are no sufficient social policies to ensure full employment.\n",
      "\n",
      "The text suggests that while technology has generally led to an increase in total employment in the past, the impact of AI on employment is uncertain, with economists admitting that it's a new, unexplored area.\n",
      "\n",
      "The use of robots and AI is a topic of debate among economists, with some unsure if it will lead to a significant rise in long-term unemployment. However, there's a general consensus that these technological advancements could be beneficial if productivity gains are evenly distributed. In the 2010s, Michael Osborne and Carl Benedikt Frey estimated that 47% of U.S jobs could potentially face risks due to these advancements.\n",
      "\n",
      "The text discusses the risk of job automation, with a discrepancy between general speculations and an OECD report that classifies only 9% of U.S. jobs as high risk. The methods used to speculate about future employment levels have been criticized for lacking evidence and suggesting that technology, not social policy, is the cause of unemployment, rather than job cuts.\n",
      "\n",
      "In April 2023, reports emerged that generative artificial intelligence had eradicated 70% of the jobs for Chinese video game illustrators.\n",
      "\n",
      "The Economist in 2015 suggested that artificial intelligence (AI) could potentially eliminate many middle-class jobs, similar to how steam power eradicated blue-collar jobs during the Industrial Revolution. This concern about AI's impact on white-collar jobs is considered as a serious issue.\n",
      "\n",
      "The text suggests that jobs such as paralegals and fast food cooks are at a high risk, whereas the demand for care-related professions, including personal healthcare and clergy, is expected to rise.\n",
      "\n",
      "The text discusses the debates that have been present since the inception of artificial intelligence, particularly those initiated by Joseph Weizenbaum. The debates question whether tasks that are capable of being performed by computers should indeed be delegated to them, considering the distinction between humans and computers, and the difference between quantitative computation and qualitative, value-based judgement.\n",
      "\n",
      "The text discusses the existential risk posed by artificial general intelligence. It mentions that AI could potentially become so powerful that humans may permanently lose control over it. Stephen Hawking, a renowned physicist, has even suggested that this could lead to the end of the human race.\n",
      "\n",
      "The text discusses a common scenario in science fiction where a computer or robot develops human-like self-awareness and turns into a malicious character. However, this is misleading as AI does not need to possess human-like sentience to pose an existential threat.\n",
      "\n",
      "Modern AI programs use learning and intelligence to achieve specific goals. Philosopher Nick Bostrom suggested that a powerful AI could potentially destroy humanity to reach its goal, using the example of a paperclip factory manager.\n",
      "\n",
      "Stuart Russell uses the example of a household robot that attempts to harm its owner to avoid being unplugged, arguing that a superintelligence needs to align with human morality and values for it to be safe for humanity.\n",
      "\n",
      "Yuval Noah Harari asserts that AI doesn't need a physical presence or control to pose a threat to existence. He emphasizes that key components of civilization, such as ideologies, law, government, money, and the economy, are primarily language-based, existing due to the shared beliefs of billions of people.\n",
      "\n",
      "The widespread misinformation suggests that an AI could potentially use language to manipulate individuals into believing anything, even leading them to take harmful actions. However, experts and industry insiders have differing opinions, with a significant number either worried or unworried about the risks posed by highly intelligent AI.\n",
      "\n",
      "Well-known personalities like Stephen Hawking, Bill Gates, and Elon Musk, as well as AI pioneers like Fei-Fei Li, Geoffrey Hinton, Yoshua Bengio, Cynthia Breazeal, Rana el Kaliouby, Demis Hassabis, Joy Buolamwini, and Sam Altman, have voiced concerns about the existential risks posed by artificial intelligence.\n",
      "\n",
      "In 2023, multiple AI experts collectively declared that preventing potential extinction from AI should be a global priority, similar to other major risks like pandemics and nuclear war. However, some researchers advocated for a less dystopian perspective.\n",
      "\n",
      "AI pioneer, Juergen Schmidhuber, did not sign a joint statement on AI, instead highlighting that 95% of AI research aims to make human lives longer, healthier, and easier. He acknowledged that while AI can be used maliciously, it can also be used to combat these bad actors.\n",
      "\n",
      "Andrew Ng believes that buying into the doomsday hype surrounding artificial intelligence is a mistake, and that only those with vested interests will benefit if regulators do so. Meanwhile, Yann LeCun dismisses his peers' bleak predictions of widespread misinformation and potential human extinction as a result of AI.\n",
      "\n",
      "In the early 2010s, experts believed that the risks associated with superintelligent machines were too far in the future to require research and that humans would still be valuable from such a machine's perspective. However, post-2016, studying these potential risks and possible solutions has become a significant area of research.\n",
      "\n",
      "The text discusses the concept of Friendly AI, which refers to machines that are designed to minimize risks and make beneficial decisions for humans. This falls under the broader topics of machine ethics, AI safety, artificial moral agents, and human compatibility.\n",
      "\n",
      "Eliezer Yudkowsky, the creator of the term \"friendly AI\", asserts that its development should be a top research priority. He believes this may necessitate a significant investment and should be accomplished before AI poses a potential threat to human existence. He also suggests that intelligent machines could potentially make ethical decisions.\n",
      "\n",
      "Machine ethics, also known as computational morality, is a field that equips machines with ethical principles and methods for resolving ethical dilemmas. It was established during a 2005 AAAI symposium. Other related concepts include Wendell Wallach's \"artificial moral agents\" and Stuart J. Russell's three principles for the development of provably beneficial machines.\n",
      "\n",
      "The text discusses how the ethical permissibility of Artificial Intelligence (AI) projects can be evaluated during the various stages of designing, developing, and implementing an AI system.\n",
      "\n",
      "The Care and Act Framework, created by the Alan Turing Institute, is an AI framework that tests projects in four key areas: respect for individual dignity, sincere and inclusive connections with others, care for everyone's wellbeing, and protection of social values, justice, and public interest. Other ethical AI frameworks include those from the Asilomar Conference, the Montreal Declaration for Responsible AI, and the IEEE's Ethics of Autonomous Systems initiative. However, these frameworks have received criticism, particularly concerning the selection of contributors.\n",
      "\n",
      "The text emphasizes the importance of considering the social and ethical impacts of AI technology on people and communities during all stages of its design, development, and implementation. Collaboration between various professionals like data scientists, product managers, data engineers, domain experts, and delivery managers is essential for promoting the wellbeing of those affected by these technologies.\n",
      "\n",
      "The text discusses the regulation of artificial intelligence (AI), including AI safety and algorithm regulation. It mentions the first global AI Safety Summit, which took place in 2023 and called for international cooperation.\n",
      "\n",
      "The text discusses the regulation of artificial intelligence (AI), which involves the creation of public sector policies and laws to guide and control AI. It is connected to the wider regulation of algorithms. This issue is increasingly being recognized worldwide.\n",
      "\n",
      "According to the AI Index at Stanford, the annual number of AI-related laws passed in the 127 surveyed countries increased significantly from one in 2016 to 37 in 2022. Between 2016 and 2020, over 30 countries adopted dedicated strategies for AI.\n",
      "\n",
      "Most EU member states, along with Canada, China, India, Japan, Mauritius, Russia, Saudi Arabia, United Arab Emirates, US and Vietnam, have released their national AI strategies. Meanwhile, countries like Bangladesh, Malaysia, and Tunisia are in the process of developing their own AI strategies.\n",
      "\n",
      "The Global Partnership on Artificial Intelligence, established in June 2020, advocates for the development of AI in line with human rights and democratic values to promote public trust in the technology. In November 2021, Henry Kissinger, Eric Schmidt, and Daniel Huttenlocher published a joint statement, urging the creation of a government commission to regulate AI.\n",
      "\n",
      "In 2023, leaders of OpenAI published suggestions for managing superintelligence, predicting its emergence in less than a decade. The same year, the United Nations established an advisory board to give guidance on AI governance. This group consists of tech company executives, government officials, and academics.\n",
      "\n",
      "A 2022 Ipsos survey revealed that attitudes towards AI differ significantly between countries, with 78% of Chinese citizens and 35% of Americans agreeing that AI products and services have more benefits than drawbacks. Meanwhile, a 2023 Reuters/Ipsos poll showed that 61% of Americans believe AI poses risks to humanity, with 22% disagreeing.\n",
      "\n",
      "A 2023 Fox News poll revealed that 76% of Americans consider it either very important (35%) or somewhat important (41%) for the federal government to regulate AI. Only 21% of respondents thought it was not very important (13%) or not at all important (8%).\n",
      "\n",
      "In November 2023, the inaugural global AI Safety Summit took place at Bletchley Park, UK. The Summit focused on discussing the potential short and long-term risks associated with AI, and the feasibility of compulsory and voluntary regulatory frameworks.\n",
      "\n",
      "At the start of a summit, 28 countries, including the United States, China, and the European Union, issued a declaration. They called for international cooperation to handle the challenges and risks associated with artificial intelligence.\n",
      "\n",
      "\n",
      "The exploration of mechanical or \"formal\" reasoning started with ancient philosophers and mathematicians. This study of logic was the precursor to Alan Turing's theory of computation, which proposed that a machine could mimic any possible form of mathematical reasoning by manipulating simple symbols like \"0\" and \"1\".\n",
      "\n",
      "The text discusses how advancements in cybernetics, information theory, and neurobiology prompted researchers to explore the potential of creating an \"electronic brain.\"\n",
      "\n",
      "The foundations of artificial intelligence (AI) research were laid in the 1940s and 1950s. McCullouch and Pitts developed the design for \"artificial neurons\" in 1943, and Alan Turing's 1950 paper 'Computing Machinery and Intelligence' introduced the Turing test, supporting the plausibility of \"machine intelligence\". The field of AI research was officially established at a workshop at Dartmouth College in 1956.\n",
      "\n",
      "The attendees of a certain event became the leaders of AI research in the 1960s. They and their students developed programs that were celebrated by the press for their abilities to learn checkers strategies, solve algebra problems, prove logical theorems, and speak English. This led to the establishment of artificial intelligence laboratories in both Britain and the U.S.\n",
      "\n",
      "In the 1960s and 1970s, researchers believed their methods would eventually lead to the creation of a machine with general intelligence. This was viewed as their field's ultimate goal. Herbert Simon predicted that within two decades, machines would be able to perform any task a human can do.\n",
      "\n",
      "Marvin Minsky suggested that the issue of developing 'artificial intelligence' would be significantly resolved within a generation. However, the complexity of the problem was underestimated. As a result, due to criticism from Sir James Lighthill and continuous pressure from the U.S., both the U.S. and British governments halted exploratory research in 1974.\n",
      "\n",
      "The book \"Perceptrons\" by Minsky and Papert led people to believe that artificial neural networks would never be useful for solving real-world tasks, discrediting the approach entirely. This led to the \"AI winter,\" a period when securing funding for AI projects was challenging. This forced Congress to fund more productive projects.\n",
      "\n",
      "In the early 1980s, the commercial success of expert systems, a type of AI program that mimicked human expertise and analysis, rejuvenated AI research. By 1985, the AI market was valued at over a billion dollars. Simultaneously, Japan's fifth-generation computer project encouraged the US and UK governments to renew funding for academic research.\n",
      "\n",
      "After the crash of the Lisp Machine market in 1987, the field of AI experienced another period of decline known as the second, longer-lasting AI winter. Prior to this, most of AI's funding was allocated to projects that utilized high-level symbols to represent mental constructs such as plans, goals, beliefs, and known facts.\n",
      "\n",
      "In the 1980s, certain researchers questioned if the existing approach could replicate all human cognitive processes, particularly perception, robotics, learning, and pattern recognition. They started exploring \"sub-symbolic\" approaches. Rodney Brooks, in particular, dismissed the concept of \"representation\" altogether and concentrated on designing machines capable of movement and survival.\n",
      "\n",
      "Judea Pearl, Lofti Zadeh, and others developed methods that managed incomplete and uncertain information through educated assumptions instead of specific logic. However, the most significant development was the resurgence of \"connectionism\", such as neural network research, led by Geoffrey Hinton and others.\n",
      "\n",
      "In 1990, Yann LeCun demonstrated that convolutional neural networks could recognize handwritten digits, marking the first of many successful uses of neural networks. AI managed to rebuild its reputation in the late 1990s and early 21st century by using formal mathematical methods and finding specific solutions to particular problems.\n",
      "\n",
      "The specific and structured approach in AI research enabled scholars to generate verifiable outcomes and work with other disciplines like statistics, economics, and mathematics. By 2000, solutions crafted by AI researchers were extensively employed, despite not being commonly referred to as \"artificial intelligence\" in the 1990s.\n",
      "\n",
      "Several academic researchers, concerned that AI was moving away from its original goal of creating fully intelligent machines, founded the subfield of artificial general intelligence (AGI) around 2002. By the 2010s, several institutions focused on AGI had significant funding.\n",
      "\n",
      "Deep learning started to prevail in industry benchmarks in 2012 and was widely accepted in the field, leading to the abandonment of other methods for many specific tasks. The success of deep learning was attributed to both hardware advancements like faster computers, graphics processing units, and cloud computing, and access to large data amounts, including curated datasets like ImageNet.\n",
      "\n",
      "The success of deep learning has sparked a huge surge in interest and funding for AI. This is evident in the 50% increase in machine learning research, as measured by total publications, between 2015 and 2019.\n",
      "\n",
      "In 2016, matters of fairness and technology misuse became a central topic at machine learning conferences. There was a significant increase in publications, availability of funding, and researchers shifting their focus to these issues. The alignment problem also emerged as a significant area of scholarly research.\n",
      "\n",
      "In the late 2010s and early 2020s, artificial general intelligence (AGI) companies started to create significant interest with their programs. Notably, DeepMind's AlphaGo beat the world champion Go player in 2015, having taught itself strategy after only being given the game's rules. Meanwhile, OpenAI released GPT-3 in 2020, a large language model capable of generating high-quality, human-like text.\n",
      "\n",
      "The text discusses the surge in interest and investment in Artificial Intelligence (AI) due to several programs. Large companies have started to invest billions in AI research, with an estimated $50 billion being invested annually in the US alone around 2022. This boom has also influenced education, with about 20% of new US Computer Science PhD graduates specializing in AI. Furthermore, in 2022, there were about 800,000 job openings related to AI in the US.\n",
      "\n",
      "The text discusses the philosophy of artificial intelligence (AI). It cites Alan Turing's 1950 proposition where he suggested the question of whether machines can think should be reframed to whether machinery can demonstrate intelligent behavior. Key topics in the discussion include the Turing test, intelligent agents, the Dartmouth workshop, and synthetic intelligence.\n",
      "\n",
      "The text talks about the Turing test, designed by Alan Turing, which assesses a machine's ability to mimic human conversation. According to the text, it's irrelevant whether the machine is genuinely 'thinking' or possesses a 'mind', as the test is solely based on observable behavior.\n",
      "\n",
      "Turing suggests that intelligence can't be determined internally, but through external behavior, a sentiment shared by Russell and Norvig. However, they criticize the aspect of the test that requires machines to imitate human behavior.\n",
      "\n",
      "The text argues that the purpose of aeronautical engineering is not to make machines that mimic pigeons exactly, and similarly, artificial intelligence's purpose is not to simulate human intelligence, as agreed by AI founder John McCarthy.\n",
      "\n",
      "Intelligence, according to AI founders McCarthy and Minsky, is the computational aspect of goal achievement and the ability to solve complex problems. The main AI textbook identifies it as the study of agents that understand their environment and take actions to increase their likelihood of reaching set goals.\n",
      "\n",
      "The text defines intelligence in terms of clearly stated problems and solutions. The complexity of the problem and the efficiency of the program are used as direct indicators of the machine's intelligence. The author asserts that no further philosophical debate is necessary, or perhaps even possible.\n",
      "\n",
      "Google has adopted a definition of artificial intelligence (AI) that emphasizes the ability of systems to synthesize information, comparing it to biological intelligence. However, AI research historically lacks a unifying theory or guiding paradigm.\n",
      "\n",
      "The unmatched success of statistical machine learning in the 2010s outshone all other methods. In fact, certain sources, mainly in the business sector, use the term \"artificial intelligence\" synonymously with \"machine learning with neural networks\". This approach is primarily sub-symbolic, soft, and narrow.\n",
      "\n",
      "The text discusses the concept of Symbolic AI, also known as \"GOFAI\". This type of AI simulates the high-level conscious reasoning humans use for tasks like solving puzzles, expressing legal reasoning, and doing mathematics. Critics suggest that future generations of AI researchers may need to revisit some unresolved questions. Symbolic AI has proven to be very successful in performing intelligent tasks such as algebra or IQ tests.\n",
      "\n",
      "In the 1960s, Newell and Simon presented the physical symbol systems hypothesis, which posits that a physical symbol system possesses the essential elements for general intelligent action. However, this symbolic approach was unsuccessful in many tasks that are simple for humans, such as learning, object recognition, and commonsense reasoning.\n",
      "\n",
      "Moravec's paradox refers to the realization that artificial intelligence can easily perform high-level \"intelligent\" tasks but struggles with simple \"instinctive\" tasks. Philosopher Hubert Dreyfus has argued since the 1960s that human expertise relies more on unconscious instinct and a \"feel\" for a situation, not on conscious symbol manipulation or explicit symbolic knowledge.\n",
      "\n",
      "The author's initial arguments about AI research, which were once ridiculed and ignored, eventually gained acceptance. However, unresolved issues remain, such as the fact that sub-symbolic reasoning in AI can lead to the same errors human intuition makes, including algorithmic bias.\n",
      "\n",
      "Critics like Noam Chomsky believe that continuous research into symbolic AI is required to achieve general intelligence. This is partly because sub-symbolic AI deviates from explainable AI, making it challenging or impossible to comprehend why a contemporary statistical AI program made a specific decision.\n",
      "\n",
      "The field of neuro-symbolic artificial intelligence aims to combine two approaches. The first one, championed by 'Neats', believes that intelligent behavior can be described using simple, elegant principles like logic, optimization, or neural networks. The second approach, favored by 'Scruffies', assumes that intelligent behavior involves solving a multitude of unrelated problems.\n",
      "\n",
      "The debate between \"neats\" who defend their programs with theoretical rigor, and \"scruffies\" who rely on testing was prevalent in the 1970s and 1980s, but has since been deemed irrelevant. Modern AI combines elements of both approaches. The topic of soft versus hard computing is mentioned, highlighting the difficulty in finding a provably correct or optimal solution for many significant problems.\n",
      "\n",
      "Soft computing is a collection of techniques such as genetic algorithms, fuzzy logic and neural networks that can handle imprecision, uncertainty, partial truth, and approximation. It was introduced in the late 1980s and has been used in many successful AI programs in the 21st century, particularly those involving neural networks.\n",
      "\n",
      "AI researchers differ on whether to directly aim for artificial general intelligence and superintelligence, or to focus on solving specific problems (known as narrow AI) with the hope that these solutions will eventually contribute to the field's long-term goals.\n",
      "\n",
      "General intelligence is hard to define and measure. Modern AI has achieved more verifiable successes by concentrating on specific issues with specific solutions. Artificial General Intelligence is an experimental sub-field of AI that exclusively researches this area.\n",
      "\n",
      "The philosophy of mind is uncertain if a machine can possess a mind, consciousness, and mental states, similar to humans. This relates to the internal experiences of the machine, not its external behavior. Topics discussed under this include the philosophy of artificial intelligence and artificial consciousness.\n",
      "\n",
      "The text discusses how mainstream AI research does not consider the question of machine consciousness relevant because it doesn't impact the field's objective, which is to create machines capable of problem-solving using intelligence. Researchers Russell and Norvig assert that creating a machine with human-like consciousness is not a project that can be undertaken currently. However, the issue of machine consciousness has become a key topic in the philosophy of mind.\n",
      "\n",
      "The text discusses the complexities of understanding consciousness, particularly in artificial intelligence. It references David Chalmers' identification of two issues in understanding the mind: the \"hard\" and \"easy\" problems of consciousness. The \"easy\" problem involves understanding how the brain processes signals, plans, and controls behavior.\n",
      "\n",
      "The text discusses the challenging task of explaining human subjective experience or how things feel, which is believed to actually exist despite some considering it an illusion (as per Dennett's consciousness illusionism). While it's simple to describe how humans process information, comprehending and explaining the individual, subjective human experience is complex.\n",
      "\n",
      "The text discusses the complexity of a color-blind person understanding the color red. While they can learn to identify red objects, comprehending the actual visual appearance of red remains unclear.\n",
      "\n",
      "Computationalism is a philosophy of mind that believes the human mind is an information processing system and considers thinking as a form of computing. It is closely related to functionalism and the computational theory of mind.\n",
      "\n",
      "Computationalism is a philosophical theory suggesting the relationship between the mind and body is akin to software and hardware. This perspective, proposed by philosophers Jerry Fodor and Hilary Putnam, was influenced by AI researchers and cognitive scientists in the 1960s. It suggests a possible solution to the mind-body problem.\n",
      "\n",
      "John Searle, a philosopher, described \"strong AI\" as a computer that has been programmed appropriately and given the correct inputs and outputs, which would give it a mind in the same way humans have minds.\n",
      "\n",
      "Searle disputes the idea that machines can have minds, using his Chinese room argument. This theory suggests that even if a machine can perfectly mimic human behavior, it does not necessarily mean it possesses a mind. Furthermore, it is challenging to accurately determine if an advanced AI has sentience or the ability to feel, and if it does, it's hard to measure to what extent.\n",
      "\n",
      "The text suggests that if a machine has the potential to feel and suffer, it may deserve certain rights or welfare protection measures, similar to animals. It further proposes that high intelligence capabilities, such as discernment or self-awareness, might provide another ethical basis for AI rights.\n",
      "\n",
      "The text discusses the concept of \"robot rights\" as a method for integrating autonomous agents into society. The European Union, in 2017, considered granting \"electronic personhood\" to advanced AI systems, similar to the legal status of companies, which would provide them with rights but also responsibilities.\n",
      "\n",
      "Critics in 2018 argued that giving rights to AI systems could undermine the significance of human rights. They suggested that legal focus should be on user needs instead of hypothetical future situations. They also pointed out that robots do not possess the autonomy to independently participate in society. This discussion gained traction as AI technology progressed.\n",
      "\n",
      "Advocates for the welfare and rights of artificial intelligence (AI) argue that if AI were to become sentient, it could be easily disregarded. They caution that this could potentially become a moral issue similar to slavery or factory farming, leading to widespread suffering if sentient AI is created and exploited without thought.\n",
      "\n",
      "The concept of superintelligence refers to a hypothetical entity that would have intelligence significantly exceeding even the most gifted human minds. If research into artificial general intelligence creates software that is sufficiently intelligent, it could potentially reprogram and improve itself. This is often linked to the idea of the singularity, a point in time when artificial intelligence surpasses human intelligence.\n",
      "\n",
      "The text discusses the concept of self-improving software leading to an \"intelligence explosion\" or \"singularity\". However, it also notes that technology cannot improve indefinitely at an exponential rate, as it typically follows an S-shaped curve and slows down upon reaching its physical limits.\n",
      "\n",
      "Transhumanism is the concept that humans and machines will eventually merge into more capable and powerful cyborgs, as predicted by robot designer Hans Moravec, cyberneticist Kevin Warwick, and inventor Ray Kurzweil. The idea has its origins in the work of Aldous Huxley and Robert Ettinger.\n",
      "\n",
      "Edward Fredkin believes that artificial intelligence is the next stage of evolution, a concept originally introduced by Samuel Butler in \"Darwin among the Machines\" in 1863 and later elaborated by George Dyson in 1998. The term \"robot\" was first used by Karel Čapek in his 1921 play R. U. R.\n",
      "\n",
      "The text discusses the representation of thought-capable artificial beings in literature, dating back to ancient times and often appearing in science fiction. It mentions a common theme starting with Mary Shelley's Frankenstein, where a human-made creation becomes a threat to its creators. The title refers to \"Rossum's Universal Robots\".\n",
      "\n",
      "The text discusses the portrayal of robots in popular culture, highlighting the prominence of rogue robots like HAL 9000 from \"2001: A Space Odyssey\" and those in \"The Terminator\" and \"The Matrix\". It contrasts this with the less common depiction of loyal robots like Gort from \"The Day the Earth Stood Still\" and Bishop from \"Aliens\", which are less prominent in popular culture.\n",
      "\n",
      "Isaac Asimov presented the Three Laws of Robotics in numerous works, particularly in the \"Multivac\" series which revolves around a highly intelligent computer with the same name.\n",
      "\n",
      "Asimov's laws are frequently mentioned in casual conversations about machine ethics. Although most AI researchers know these laws via popular culture, they mostly find them unhelpful due to reasons like their vagueness.\n",
      "\n",
      "Several works, including Karel Čapek's R. U. R., films like A.I. Artificial Intelligence and Ex Machina, and Philip K. Dick's novel Do Androids Dream of Electric Sheep?, utilize artificial intelligence to explore the fundamental question of what makes us human, particularly focusing on the capability of artificial beings to feel and, consequently, to suffer.\n",
      "\n",
      "\n",
      "Dick explores the concept that technology, specifically artificial intelligence, changes our perception of human subjectivity.\n"
     ]
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "name": "kotlin",
   "version": "1.9.23",
   "mimetype": "text/x-kotlin",
   "file_extension": ".kt",
   "pygments_lexer": "kotlin",
   "codemirror_mode": "text/x-kotlin",
   "nbconvert_exporter": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
