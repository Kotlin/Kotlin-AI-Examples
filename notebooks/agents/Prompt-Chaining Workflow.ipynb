{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Prompt Chaining Workflow\n",
    "\n",
    "In this notebook, we'll explore the prompt chaining workflow.\n",
    "Using Kotlin and Claude via the LangChain4j library,\n",
    "we'll implement a practical example that demonstrates how to break down complex tasks into manageable steps.\n",
    "\n",
    "## What is prompt chaining?\n",
    "\n",
    "Prompt chaining is a technique where we decompose a complex task into a sequence of simpler steps.\n",
    "Each step involves an LLM call that processes the output from the previous step.\n",
    "This creates a _\"chain\"_ of prompts that collectively solve the original problem.\n",
    "\n",
    "![Prompt Chaining Workflow Diagram](image/prompt_chaining.svg)\n",
    "\n",
    "### Key benefits:\n",
    "- By focusing on smaller tasks, improved accuracy\n",
    "- Each step is controlled and verified\n",
    "- Using different prompts is optimized for different tasks\n",
    "\n",
    "### When to use prompt chaining\n",
    "\n",
    "Common use cases include:\n",
    "\n",
    "- Content generation followed by translation\n",
    "- Creating outlines before drafting full documents\n",
    "- Data extraction and transformation processes\n",
    "\n",
    "## Setting up environment\n",
    "\n",
    "First, let's set up a Kotlin notebook with the necessary dependencies:"
   ]
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-11T21:48:44.069877Z",
     "start_time": "2025-05-11T21:48:43.106474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%useLatestDescriptors\n",
    "%use coroutines\n",
    "%use langchain4j(1.0.0-beta3, anthropic)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We'll need an API key for accessing Claude:"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T21:48:44.100358Z",
     "start_time": "2025-05-11T21:48:44.073812Z"
    }
   },
   "cell_type": "code",
   "source": "val apiKey = System.getenv(\"ANTHROPIC_API_KEY\")",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Creating the LLM interface\n",
    "\n",
    "Next, build a helper function to handle LLM calls:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T21:48:49.867603Z",
     "start_time": "2025-05-11T21:48:49.653724Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dev.langchain4j.data.message.SystemMessage.systemMessage\n",
    "import dev.langchain4j.data.message.UserMessage.userMessage\n",
    "\n",
    "suspend fun llmCall(\n",
    "    prompt: String,\n",
    "    systemPrompt: String? = null,\n",
    "    model: AnthropicChatModelName = AnthropicChatModelName.CLAUDE_3_7_SONNET_20250219\n",
    "): String {\n",
    "    val client = AnthropicChatModel.builder()\n",
    "        .apiKey(apiKey)\n",
    "        .modelName(model)\n",
    "        .maxTokens(4096)\n",
    "        .temperature(0.1)\n",
    "        .build()\n",
    "\n",
    "    return withContext(Dispatchers.IO) {\n",
    "        val response = client.chat {\n",
    "            systemPrompt?.let { messages += systemMessage(it) }\n",
    "            messages += userMessage(prompt)\n",
    "        }\n",
    "        response.aiMessage().text()\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Implementing the `chain` function\n",
    "\n",
    "The core of implementation is the `chain` function, which manages the flow of data our prompt sequence:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T21:48:51.193436Z",
     "start_time": "2025-05-11T21:48:51.107695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "suspend fun chain(input: String, prompts: List<String>): String {\n",
    "    var result = input\n",
    "    prompts.forEachIndexed { index, prompt ->\n",
    "        println(\"Step ${index + 1}\")\n",
    "        result = llmCall(\"$prompt\\nInput: $result\")\n",
    "        println(result)\n",
    "    }\n",
    "    return result\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This function:\n",
    "- Takes an initial input and a list of prompts\n",
    "- Iterates through each prompt in a sequence\n",
    "- Passes the result of each step as input to the next\n",
    "- Tracks progress through console output\n",
    "\n",
    "## Creating prompt sequence\n",
    "\n",
    "Now define the series of prompts that make up our chain.\n",
    "Each prompt handles a specific subtask:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T21:48:52.902515Z",
     "start_time": "2025-05-11T21:48:52.879801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val prompts = listOf(\n",
    "    // Step 1\n",
    "    \"\"\"\n",
    "    Extract only the numerical values and their associated metrics from the text.\n",
    "    Format each as 'value: metric' on a new line.\n",
    "    Example format:\n",
    "    92: customer satisfaction\n",
    "    45%: revenue growth\n",
    "    \"\"\",\n",
    "    // Step 2\n",
    "    \"\"\"\n",
    "    Convert all numerical values to percentages where possible.\n",
    "    If not a percentage or points, convert to decimal (e.g., 92 points -> 92%).\n",
    "    Keep one number per line.\n",
    "    Example format:\n",
    "    92%: customer satisfaction\n",
    "    45%: revenue growth\n",
    "    \"\"\",\n",
    "    // Step 3\n",
    "    \"\"\"\n",
    "    Sort all lines in descending order by numerical value.\n",
    "    Keep the format 'value: metric' on each line.\n",
    "    Example:\n",
    "    92%: customer satisfaction\n",
    "    87%: employee satisfaction\n",
    "    \"\"\",\n",
    "    // Step 4\n",
    "    \"\"\"\n",
    "    Format the sorted data as a markdown table with columns:\n",
    "    | Metric | Value |\n",
    "    |:--|--:|\n",
    "    | Customer Satisfaction | 92% |\n",
    "    \"\"\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Testing chain\n",
    "\n",
    "Let's test implementation on a sample quarterly report:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T21:48:54.455677Z",
     "start_time": "2025-05-11T21:48:54.431018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val report =\n",
    "    \"\"\"\n",
    "    Q3 Performance Summary:\n",
    "    Our customer satisfaction score rose to 92 points this quarter.\n",
    "    Revenue grew by 45% compared to last year.\n",
    "    Market share is now at 23% in our primary market.\n",
    "    Customer churn decreased to 5% from 8%.\n",
    "    New user acquisition cost is $43 per user.\n",
    "    Product adoption rate increased to 78%.\n",
    "    Employee satisfaction is at 87 points.\n",
    "    Operating margin improved to 34%.\n",
    "    \"\"\".trimIndent()"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Finally, execute the prompt chain"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T21:49:08.576050Z",
     "start_time": "2025-05-11T21:48:57.097290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "runBlocking {\n",
    "    println(\"Input text:\")\n",
    "    println(report)\n",
    "    val formattedResult = chain(report, prompts)\n",
    "    println(formattedResult)\n",
    "}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text:\n",
      "Q3 Performance Summary:\n",
      "Our customer satisfaction score rose to 92 points this quarter.\n",
      "Revenue grew by 45% compared to last year.\n",
      "Market share is now at 23% in our primary market.\n",
      "Customer churn decreased to 5% from 8%.\n",
      "New user acquisition cost is $43 per user.\n",
      "Product adoption rate increased to 78%.\n",
      "Employee satisfaction is at 87 points.\n",
      "Operating margin improved to 34%.\n",
      "Step 1\n",
      "92: customer satisfaction score\n",
      "45%: revenue growth\n",
      "23%: market share\n",
      "5%: customer churn\n",
      "$43: new user acquisition cost\n",
      "78%: product adoption rate\n",
      "87: employee satisfaction\n",
      "34%: operating margin\n",
      "Step 2\n",
      "92%: customer satisfaction score\n",
      "45%: revenue growth\n",
      "23%: market share\n",
      "5%: customer churn\n",
      "$43: new user acquisition cost\n",
      "78%: product adoption rate\n",
      "87%: employee satisfaction\n",
      "34%: operating margin\n",
      "Step 3\n",
      "92%: customer satisfaction score\n",
      "87%: employee satisfaction\n",
      "78%: product adoption rate\n",
      "45%: revenue growth\n",
      "34%: operating margin\n",
      "23%: market share\n",
      "$43: new user acquisition cost\n",
      "5%: customer churn\n",
      "Step 4\n",
      "| Metric | Value |\n",
      "|:--|--:|\n",
      "| Customer Satisfaction | 92% |\n",
      "| Employee Satisfaction | 87% |\n",
      "| Product Adoption Rate | 78% |\n",
      "| Revenue Growth | 45% |\n",
      "| Operating Margin | 34% |\n",
      "| Market Share | 23% |\n",
      "| Customer Churn | 5% |\n",
      "| New User Acquisition Cost | $43 |\n",
      "| Metric | Value |\n",
      "|:--|--:|\n",
      "| Customer Satisfaction | 92% |\n",
      "| Employee Satisfaction | 87% |\n",
      "| Product Adoption Rate | 78% |\n",
      "| Revenue Growth | 45% |\n",
      "| Operating Margin | 34% |\n",
      "| Market Share | 23% |\n",
      "| Customer Churn | 5% |\n",
      "| New User Acquisition Cost | $43 |\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "\n",
    "Prompt chaining offers a powerful and flexible approach to building AI agents.\n",
    "By breaking complex tasks into manageable steps,\n",
    "we can achieve higher accuracy and better control over the generation process.\n",
    "\n",
    "This pattern is particularly valuable when developing applications that require structured data transformation,\n",
    "multi-stage content generation, or any task that benefits from a divide-and-conquer approach."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "name": "kotlin",
   "version": "1.9.23",
   "mimetype": "text/x-kotlin",
   "file_extension": ".kt",
   "pygments_lexer": "kotlin",
   "codemirror_mode": "text/x-kotlin",
   "nbconvert_exporter": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
