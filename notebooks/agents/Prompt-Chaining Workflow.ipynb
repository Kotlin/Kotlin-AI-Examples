{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-02T12:02:01.036226Z",
     "start_time": "2025-04-02T12:01:55.176209Z"
    }
   },
   "source": [
    "%useLatestDescriptors\n",
    "%use coroutines\n",
    "\n",
    "@file:DependsOn(\"dev.langchain4j:langchain4j:1.0.0-beta2\")\n",
    "@file:DependsOn(\"dev.langchain4j:langchain4j-anthropic:1.0.0-beta2\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "![](image/prompt_chaining.svg)\n",
    "\n",
    "\n",
    "<img src=\"image/prompt_chaining.svg\" width=\"800\" height=\"400\" align=\"center\" alt=\"Prompt Chaining Workflow\">\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T13:05:48.437462Z",
     "start_time": "2025-04-02T13:05:48.400400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "HTML (\n",
    "    \"\"\"\n",
    "    <div id=\"mermaid-diagram\"></div>\n",
    "\n",
    "    <script type=\"module\">\n",
    "      import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10.6.1/dist/mermaid.esm.min.mjs';\n",
    "\n",
    "      mermaid.initialize({\n",
    "        startOnLoad: false,\n",
    "        theme: 'neutral',\n",
    "        securityLevel: 'loose'\n",
    "      });\n",
    "\n",
    "      const diagram = `\n",
    "        flowchart LR\n",
    "          In([In]) --> LLM1(LLM Call 1)\n",
    "          LLM1 -->|Output 1| Gate1{Gate 1}\n",
    "          Gate1 -- Pass --> LLM2[LLM Call 2]\n",
    "          Gate1 -. Fail .-> Exit([Exit])\n",
    "          LLM2 -->|Output 2| LLM3(LLM Call 3)\n",
    "          LLM3 --> Out([Out])\n",
    "\n",
    "          style In fill:#fbf1ee,stroke:#e0b2a0,color:#c2522e\n",
    "          style Out fill:#fbf1ee,stroke:#e0b2a0,color:#c2522e\n",
    "          style Exit fill:#fbf1ee,stroke:#e0b2a0,color:#c2522e\n",
    "          style Gate1 fill:#f3f2fa,stroke:#a29ac3,color:#695fb6\n",
    "          style LLM1 fill:#eff5ea,stroke:#b1d398,color:#5b9c36\n",
    "          style LLM2 fill:#eff5ea,stroke:#b1d398,color:#5b9c36\n",
    "          style LLM3 fill:#eff5ea,stroke:#b1d398,color:#5b9c36\n",
    "      `;\n",
    "\n",
    "      setTimeout(() => {\n",
    "        mermaid.render('mermaid-render', diagram)\n",
    "          .then(({ svg }) => {\n",
    "            document.getElementById('mermaid-diagram').innerHTML = svg;\n",
    "          })\n",
    "          .catch(err => {\n",
    "            console.error(\"Mermaid rendering failed:\", err);\n",
    "            document.getElementById('mermaid-diagram').innerHTML =\n",
    "              '<pre style=\"color:red\">Error rendering Mermaid diagram: ' + err.message + '</pre>';\n",
    "          });\n",
    "      }, 500);\n",
    "    </script>\n",
    "    \"\"\"\n",
    ")"
   ],
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div id=\"mermaid-diagram\"></div>\n",
       "\n",
       "    <script type=\"module\">\n",
       "      import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10.6.1/dist/mermaid.esm.min.mjs';\n",
       "\n",
       "      mermaid.initialize({\n",
       "        startOnLoad: false,\n",
       "        theme: 'neutral',\n",
       "        securityLevel: 'loose'\n",
       "      });\n",
       "\n",
       "      const diagram = `\n",
       "        flowchart LR\n",
       "          In([In]) --> LLM1(LLM Call 1)\n",
       "          LLM1 -->|Output 1| Gate1{Gate 1}\n",
       "          Gate1 -- Pass --> LLM2[LLM Call 2]\n",
       "          Gate1 -. Fail .-> Exit([Exit])\n",
       "          LLM2 -->|Output 2| LLM3(LLM Call 3)\n",
       "          LLM3 --> Out([Out])\n",
       "\n",
       "          style In fill:#fbf1ee,stroke:#e0b2a0,color:#c2522e\n",
       "          style Out fill:#fbf1ee,stroke:#e0b2a0,color:#c2522e\n",
       "          style Exit fill:#fbf1ee,stroke:#e0b2a0,color:#c2522e\n",
       "          style Gate1 fill:#f3f2fa,stroke:#a29ac3,color:#695fb6\n",
       "          style LLM1 fill:#eff5ea,stroke:#b1d398,color:#5b9c36\n",
       "          style LLM2 fill:#eff5ea,stroke:#b1d398,color:#5b9c36\n",
       "          style LLM3 fill:#eff5ea,stroke:#b1d398,color:#5b9c36\n",
       "      `;\n",
       "\n",
       "      setTimeout(() => {\n",
       "        mermaid.render('mermaid-render', diagram)\n",
       "          .then(({ svg }) => {\n",
       "            document.getElementById('mermaid-diagram').innerHTML = svg;\n",
       "          })\n",
       "          .catch(err => {\n",
       "            console.error(\"Mermaid rendering failed:\", err);\n",
       "            document.getElementById('mermaid-diagram').innerHTML =\n",
       "              '<pre style=\"color:red\">Error rendering Mermaid diagram: ' + err.message + '</pre>';\n",
       "          });\n",
       "      }, 500);\n",
       "    </script>\n",
       "    "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T12:02:01.106636Z",
     "start_time": "2025-04-02T12:02:01.042304Z"
    }
   },
   "cell_type": "code",
   "source": "val apiKey = System.getenv(\"ANTHROPIC_API_KEY\")",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T12:02:01.642865Z",
     "start_time": "2025-04-02T12:02:01.111382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dev.langchain4j.data.message.SystemMessage.systemMessage\n",
    "import dev.langchain4j.data.message.UserMessage.userMessage\n",
    "import dev.langchain4j.model.anthropic.AnthropicChatModel\n",
    "import dev.langchain4j.model.anthropic.AnthropicChatModelName\n",
    "import dev.langchain4j.model.chat.chat\n",
    "\n",
    "suspend fun llmCall(\n",
    "    prompt: String,\n",
    "    systemPrompt: String? = null,\n",
    "    model: AnthropicChatModelName = AnthropicChatModelName.CLAUDE_3_7_SONNET_20250219\n",
    "): String {\n",
    "    val client = AnthropicChatModel.builder()\n",
    "        .apiKey(apiKey)\n",
    "        .modelName(model)\n",
    "        .maxTokens(4096)\n",
    "        .temperature(0.1)\n",
    "        .build()\n",
    "\n",
    "    return withContext(Dispatchers.IO) {\n",
    "        val response = client.chat {\n",
    "            systemPrompt?.let { messages += systemMessage(it) }\n",
    "            messages += userMessage(prompt)\n",
    "        }\n",
    "        response.aiMessage().text()\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T12:02:01.704844Z",
     "start_time": "2025-04-02T12:02:01.655380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val prompts = listOf(\n",
    "                                // Step 1\n",
    "    \"\"\"\n",
    "    Extract only the numerical values and their associated metrics from the text.\n",
    "    Format each as 'value: metric' on a new line.\n",
    "    Example format:\n",
    "    92: customer satisfaction\n",
    "    45%: revenue growth\n",
    "    \"\"\",\n",
    "                                // Step 2\n",
    "    \"\"\"\n",
    "    Convert all numerical values to percentages where possible.\n",
    "    If not a percentage or points, convert to decimal (e.g., 92 points -> 92%).\n",
    "    Keep one number per line.\n",
    "    Example format:\n",
    "    92%: customer satisfaction\n",
    "    45%: revenue growth\n",
    "    \"\"\",\n",
    "                                // Step 3\n",
    "    \"\"\"\n",
    "    Sort all lines in descending order by numerical value.\n",
    "    Keep the format 'value: metric' on each line.\n",
    "    Example:\n",
    "    92%: customer satisfaction\n",
    "    87%: employee satisfaction\n",
    "    \"\"\",\n",
    "                                // Step 4\n",
    "    \"\"\"\n",
    "    Format the sorted data as a markdown table with columns:\n",
    "    | Metric | Value |\n",
    "    |:--|--:|\n",
    "    | Customer Satisfaction | 92% |\n",
    "    \"\"\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T12:02:01.758821Z",
     "start_time": "2025-04-02T12:02:01.709271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val report =\n",
    "    \"\"\"\n",
    "    Q3 Performance Summary:\n",
    "    Our customer satisfaction score rose to 92 points this quarter.\n",
    "    Revenue grew by 45% compared to last year.\n",
    "    Market share is now at 23% in our primary market.\n",
    "    Customer churn decreased to 5% from 8%.\n",
    "    New user acquisition cost is $43 per user.\n",
    "    Product adoption rate increased to 78%.\n",
    "    Employee satisfaction is at 87 points.\n",
    "    Operating margin improved to 34%.\n",
    "    \"\"\".trimIndent()"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T12:02:01.942368Z",
     "start_time": "2025-04-02T12:02:01.772388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "suspend fun chain(input: String, prompts: List<String>): String {\n",
    "    var result = input\n",
    "    prompts.forEachIndexed { index, prompt ->\n",
    "        println(\"Step ${index + 1}\")\n",
    "        result = llmCall(\"$prompt\\nInput: $result\")\n",
    "        println(result)\n",
    "    }\n",
    "    return result\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T12:02:08.889936Z",
     "start_time": "2025-04-02T12:02:01.948257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "runBlocking {\n",
    "    println(\"Input text:\")\n",
    "    println(report)\n",
    "    val formattedResult = chain(report, prompts)\n",
    "    println(formattedResult)\n",
    "}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text:\n",
      "Q3 Performance Summary:\n",
      "Our customer satisfaction score rose to 92 points this quarter.\n",
      "Revenue grew by 45% compared to last year.\n",
      "Market share is now at 23% in our primary market.\n",
      "Customer churn decreased to 5% from 8%.\n",
      "New user acquisition cost is $43 per user.\n",
      "Product adoption rate increased to 78%.\n",
      "Employee satisfaction is at 87 points.\n",
      "Operating margin improved to 34%.\n",
      "Step 1\n",
      "92: customer satisfaction score\n",
      "45%: revenue growth\n",
      "23%: market share\n",
      "5%: customer churn\n",
      "$43: new user acquisition cost\n",
      "78%: product adoption rate\n",
      "87: employee satisfaction\n",
      "34%: operating margin\n",
      "Step 2\n",
      "92%: customer satisfaction score\n",
      "45%: revenue growth\n",
      "23%: market share\n",
      "5%: customer churn\n",
      "$43: new user acquisition cost\n",
      "78%: product adoption rate\n",
      "87%: employee satisfaction\n",
      "34%: operating margin\n",
      "Step 3\n",
      "92%: customer satisfaction score\n",
      "87%: employee satisfaction\n",
      "78%: product adoption rate\n",
      "45%: revenue growth\n",
      "34%: operating margin\n",
      "23%: market share\n",
      "5%: customer churn\n",
      "$43: new user acquisition cost\n",
      "Step 4\n",
      "| Metric | Value |\n",
      "|:--|--:|\n",
      "| Customer Satisfaction | 92% |\n",
      "| Employee Satisfaction | 87% |\n",
      "| Product Adoption Rate | 78% |\n",
      "| Revenue Growth | 45% |\n",
      "| Operating Margin | 34% |\n",
      "| Market Share | 23% |\n",
      "| Customer Churn | 5% |\n",
      "| New User Acquisition Cost | $43 |\n",
      "| Metric | Value |\n",
      "|:--|--:|\n",
      "| Customer Satisfaction | 92% |\n",
      "| Employee Satisfaction | 87% |\n",
      "| Product Adoption Rate | 78% |\n",
      "| Revenue Growth | 45% |\n",
      "| Operating Margin | 34% |\n",
      "| Market Share | 23% |\n",
      "| Customer Churn | 5% |\n",
      "| New User Acquisition Cost | $43 |\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "name": "kotlin",
   "version": "1.9.23",
   "mimetype": "text/x-kotlin",
   "file_extension": ".kt",
   "pygments_lexer": "kotlin",
   "codemirror_mode": "text/x-kotlin",
   "nbconvert_exporter": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
